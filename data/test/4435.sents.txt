The widespread and rising adoption of information and communication technology in homes is happening at a time when data security breaches are commonplace.
This has resulted in a wave of security awareness campaigns targeting the home computer user.
Despite the prevalence of these campaigns , studies have shown poor adoption rates of security measures.
This has resulted in proposals for securing data in the home built on interdisciplinary theories and models, but more empirical research needs to be done to understand the practical context, characteristics, and needs of home users in order to rigorously evaluate and inform solutions to home data security.
To address this, we employ a two-part study to explore issues that influence or affect security practices in the home.
In the first part, we conduct a qualitative Grounded Theory analysis of 65 semi-structured interviews aimed at uncovering the key factors in home user security practices, and in the second part we conduct a quantitative survey of 1128 participants to validate and generalise our initial findings.
We found evidence that security practices in the home are affected by survival/outcome bias; social relationships serve as informal support networks for security in the home; and that people look for continuity of care when they seek or accept security support.
Securing home devices, services, and data is increasingly difficult and necessary.
While home users are not as attractive a target as many organisations, they are both commonplace and vulnerable to several attacks.
Initial work in exploring the security of home computer users [1,22,25] has highlighted the importance of this domain, and yet much more needs to be done to be able to address the scale and complexity of the security challenge.According to the 2013 census, 74.4 percent of [U.S.] households use the Internet [42].
Similarly in 2015, 86 percent of households in Great Britain (22.5 Copyright is held by the author/owner.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee.
USENIX Symposium on Usable Privacy and Security (SOUPS) 2018.
August 12-14, 2018, Baltimore, MD, USA.
access, up from 57 percent in 2006 [14].
Worldwide, Internet Live Stats reveals that over 46 percent of the world's population (3.4 billion) had Internet access in their homes by July 2016, up from 29 percent in 2010 [40].
And as the number of connected homes increases worldwide, so too do the threats.In 2012, Rao and Pati [36] conducted a study in India revealing common threats and attacks facing home users: viruses, malware, identity theft and privacy violation, and phishing.
Large organisations generally mitigate these types of threat well, however this is not the case for typical home computer users.
Best practice in mitigating viruses in a home context seems to focus on running antivirus software, patching, and warnings to avoid untrusted or malicious websites (from web browsers and awareness campaigns).
In contrast, in addition to antivirus software and patching solutions, larger organisations also have acceptable usage policies to manage risky behaviour from employees; segmented network architectures to avoid the spread of viruses; active firewalls, intrusion detection and prevention systems to identify problems before they cause significant damage; backup strategies to recover from incidents; and, perhaps most critically, an IT support function that can deal with problems should they arise.
In comparison, home users have very few resources, capabilities, knowledge, skills, or tools to protect themselves from the multitude of threats that harm them directly.But threats that directly harm the home are not the only concern.
In today's highly interconnected world, the security of cyberspace depends on the security of all the different devices connected to the Internet.
Ng and Rahim state that home users play a crucial role in securing cyberspace: if not well-protected, home systems can be compromised and used to attack critical infrastructure (such as telecommunication and banking) that heavily depends on the secure functioning of cyberspace [29].
While security breaches affecting organisations receive much attention, breaches involving home users usually come to light only when home devices or users themselves are involved in an attack affecting critical infrastructure.
The October 2016 attack on Dyn, for instance, which is thought to have been enabled by insecure IoT devices in homes [5], triggered a number of reactions from different stakeholders, with some device manufacturers reportedly recalling their devices.
Users at home face many different kinds of threats and mitigation requires interventions both within and outside the home.A key strategy for improving home security practices so far has focussed on increasing awareness [33,21,24,38,30].
Despite the effort put in such approaches, studies [3,33,17,27] and recent events [5,12,26] show that home users remain vulnerable as evidenced by insecure practices and choices to ignore security advice, leading the research community to explore alternatives to increasing awareness.
Dong et al. [10] propose an economics approach to designing security solutions for communities rather than individuals.
They argue that incentivizing people to improve the security of a community (from which they benefit) through a shared venture would motivate personal security investment.
While maintaining user-centeredness, Gutmann [20] proposes the application of problem structuring methods (PSMs), a technique from social planning, to help analyse security problems.
The intent is to ensure the most appropriate solution is applied to a problem, and Gutmann claims to tackle a common problem where developers and service providers impose their favourite technology on people, without considering the environmental, social, political, and legal aspects of the overall problem.
Wash and Rader [44] propose security story-sharing to help shape the mental models which inform home security decisions.
Through sharing the right stories, and with expert involvement, the authors foresee changing home user security behaviour.
Adding to the body of proposed approaches, Rowe et al. [39] put forward an approach modelled on public health systems for a shared secure cyberspace.
They argue for a population-centred approach in dealing with cybersecurity issues.
This is a departure from the typical practices in information security which take an individual focus in trying to understand how systems are compromised, and how they can be protected.
The authors outline the technical requirements of a public cyber-health system, with specific focus on how the system would achieve monitoring, prevention, and incident response.Building on this work, we believe that secure (and security) systems in the home need to be designed from an empirical and grounded understanding of home users, the context of use in which they operate, and how they make data security decisions.
We report on the qualitative and quantitative research we have undertaken to explore the security practices of home computer users.
We conducted 15 scoping semi-structured interviews, followed by a further 50 targeted semi-structured interviews lasting approximately 60 minutes each.
We analysed the data systematically using Grounded Theory and used this to design and run a quantitative survey of 1128 home users to explore how widely shared the qualitative findings are.
Our key findings are:• Social relationships play a vital role in information security in the home.
They serve as informal support networks of security practices.
• Perceived competence is an important factor in security decision-making in the home.
It is used to assess the quality of a security source, and the support offered in the home.
The participants use different metrics to evaluate competence, including the profession of the source, the educational standing of the source, the level of usage of technical devices of the source, and negative experiences of the source.
• Continuity of care is an important characteristic of security support in the home.
Participants report seeking or accepting support from a source that is constantly available when needed.
• Participants look for evidence of a security problem or need for them to practice security.
Typical evidence is direct harm to an individual, or their social relation, resulting from the individual's insecure behaviour.
• Confidence of the participants in an implemented security control can increase insecure practices.The remainder of this paper will review the related work in this domain in section 2, describe our research methodology in section 3, and present our results in section 4.
We finally discuss the implications of our findings and highlight areas of interest for future work in sections 5 and 6.
In this section, we review prior work investigating home user security practices, structuring the concept of security practices into: (i) security behaviours; and (ii) the factors that influence the security decisions that precede the behaviours.
Studies have been conducted to understand and improve security behaviours in the home.
AOL and the National Cyber Security Alliance conducted a study of online safety of home computer users [2] where 329 home users were interviewed and their computers were analysed.
Researchers asked and checked for the availability of virus and spyware protection software, firewalls, parental controls, and the use of encryption for wireless network users.
The study concluded that the majority of those studied lacked core protection.
Similarly, Furnell et.
al assessed the security perceptions of UK home users [17].
They surveyed 415 home users about their awareness of security threats, usage of system safeguards (firewall, antivirus, anti-spyware, and anti-spam software), and their awareness and understanding of security-specific tools found in contexts such as operating systems and applications.
The study found that both novice and advanced home users appeared vulnerable to security risks.
The authors concluded with a call for the development of new models of engagement and awareness raising.Rao and Pati surveyed home users in India to understand their levels of awareness of security threats and usage of security measures (password protection, antivirus, firewall, patching, data backup, and parental controls) [36].
The study revealed poor understanding of security threats, and low levels of adoption of recommended security controls.
The authors concluded that the security in the home can be improved through awareness and user-friendly security controls.
Similarly, Ng and Rahim studied factors that influence a home computer user's intention to practice computer security [29].
They surveyed 233 home computer users on the use of antivirus software, data backup, and personal firewall.Ion et al. studied security practices that different experts and non-experts consider to be the most important in protecting their security online [23].
They conducted 40 semistructured interviews with security experts, and used the results to design a survey.
231 security experts and 294 non-security experts were surveyed, and the practices of the two groups compared.
The studied practices included installing software updates, using antivirus software, account security (using password managers, writing down passwords, changing passwords frequently, and using two-factor authentication), and mindfulness (visit only known websites, check if HTTPS, clear browser cookies, and email habits).
The results showed discrepancies between the most important security practices of the two groups.
The authors concluded that more work is needed to improve the practices of non-experts, and identified three key recommendations: install software updates, use password managers, and use two-factor authentication for online accounts.Dourish et al. [11] investigated how users respond to security issues in their daily lives and found that people ask for assistance or delegate security activities to knowledgeable family members (similar to [15]), friends, or roommates.
They also found a reliance on technology (e.g. SSL for data connections, ssh tunneling for email, or trust wired Ethernet to be more secure than a traditional wireless medium) for protection; others reported delegating security to institutions such as financial companies.
Likewise, Nthala and Flechais [31] found that some home users turn to trusted others (colleagues, IT professionals, relations, and peers) for help with security issues.
Research has been conducted to investigate and understand the factors that motivate different security behaviours.
Several studies [38,29,31] have shown that social influence has an impact on the security behaviours of home users.
Das et al. [8,9] studied in more detail how this social influence plays a role in the security behaviours of home users.
They found that social influence affected the security behaviours of those involved through social processes (observing and learning from friends, social sense-making, pranks and demonstrations, negative experience of others, and device sharing), and conversations about security (a finding similar to Rader et al. [35]).
Wash [43] carried out a qualitative study of iterative interviews to investigate the existence of folk models of security for home computer users, aiming to increase our understanding of mental models of security for home computer users.
The study focussed on finding out how home computer users understand and think about potential threats.
Wash identified eight folk models categorised into models of viruses and other malware, and models of hackers and break-ins.
Herley [21] argued that users perform an implicit cost-benefit analysis when making a security decision.
The cost is the effort required to follow security advice, while the benefit is the avoidance of potential harm that a successful attack might cause.
The harm includes monetary loss (if any) that victims endure, but also the time and effort they must spend resolving the situation.
Similarly, [31] found that the cost of protection also influences the outcome of security decisions in the home.In a study investigating why users accept or reject different advice about secure behaviours, Redmiles et al. [38] found that users reject advice due to too much marketing information, inconvenience and threatening users' privacy.
In addition, the study reported that trust was a clear factor that influenced the choice of a source of security advice.Other related work has focussed on understanding practices around home network security, highlighting the differences in responsibility between Internet Service Providers and home users [32].
We started our study with a scoping study of 15 semi-structured interviews.
The aim of the scoping study was to make an initial exploration of security practices (which we consider to consist of (i) security behaviours and (ii) the decisions that lead to such behaviours) in the home, from which we would identify a research gap for further exploration.
Our research questions would then be refined based on the initial results.
Respondents for this study were chosen from a snowball sample [7] of home users in the UK.
Two research questions guided our interviews during the scoping study:1.
What influences security decision-making in the home?
2.
What kinds of security behaviours exist in the home?We analysed the data using Grounded Theory (see section 3.2.2) to identify all the key themes emerging from the data.
Our analysis identified a number of factors that influence the outcome of security decisions in the home, all of which were consistent with previous studies discussed in section 2.2.
These included inconvenience, trust, cost, and availability of too much marketing material.
Analysis of the data on security behaviours revealed two separate categories of the behaviours which we categorised as: security work and security support.Security work is highly contextual and specific to technology platforms, comprising behaviours such as installing and using firewalls, antivirus software, patching, data backup, and parental controls.
As reviewed in section 2.1, our findings were consistent but much less comprehensive than previous surveys in this area.Security support, on the other hand, comprises two subcategories; support seeking and support giving.
The work of Dourish et al. on delegation [11], Nthala and Flechais [31] on security support, and Redmiles at al. [38] on advice seeking and giving, all fall under security support.
We noted that little work has been done to explore security support that is required or available in the home in great detail.This led us to focus our research on understanding security support in the home, and the reasoning behind it.
We thus refined our main research questions to:1.
What influences security decision-making in the home?
2.
What are the characteristics of security support in the home?
3.
Where do home users get support?To answer these questions, we adapted the research methodology proposed by the Productive Security research team of Beautement et.
al. [6].
We conducted a two-part study aiming to increase our understanding of security support in the home, and the reasoning that surrounds it.
In the first part, a detailed understanding of the problem domain arises out of studying a few individuals and exploring their perspectives in great depth.
In the second, a more generalisable understanding of the issues identified in the first part can be gained from examining a large sample and assessing responses to a few variables.Part 1 of our research consisted of 50 targeted semi-structured interviews with a broad range of individuals and families within the home context.
As the interview data was being collected, it was qualitatively analysed using Grounded Theory (see section 3.2.2) in order to identify the significant themes to answer our research questions.
The themes were used to generate scenarios and questions from which a survey was developed and run in the second part of our study.
By tailoring our survey to the home context, we ensured that the questions were relevant and recognisable to the participants.Part 2 made use of Unipark to run an online survey and Prolific Academic to identify a representative sample (in terms of age, gender, and educational level) of 1128 participants.
The survey results were analysed and aimed to validate the findings of the qualitative data analysis, and support the generalisability of these results to a wider home user population.
This was meant to provide clear evidence on which future work can draw to improve education, technology, and practices for home data security.The study was ethically reviewed and approved by the Social Sciences and Humanities Inter-divisional Research Ethics Committee at our institution.
We recruited for the interviews by advertising through community centres, newspapers (in print and online), and other social groupings, and by putting up posters at the National Museum of Computing.
The recruitment was conducted in different locations in the UK.
Before starting an interview, we collected demographic information including age, gender, highest educational level, ethnicity, marital status, and occupation from the respondents to ensure we cover a broad range of home users.
Each participant was compensated with a £10 Amazon voucher for an approximately one-hour interview session.Participants for the survey were recruited through Prolific Academic, and each participant was compensated with £1.70 for an approximately twenty-minute session.
We followed a semi-structured interview protocol utilising an interview guide to maintain direction while keeping the interview open for both depth and breadth topic exploration.
Prior to the interview, participants were asked to complete a demographic form, which included questions regarding the devices and services they use.
Our interview guide is appended in D.
The interview data was analysed using Grounded Theory [19].
Grounded theory allows researchers to examine topics and related behaviours from many different angles, leading to comprehensive explanations.
It is used to uncover beliefs and meaning that underlie action, and to examine both rational and non-rational aspects of a behaviour [41].
This makes it the ideal choice for studying security support and any issues that surround it.
Our approach was consistent with that described by Strauss and Corbin [41].
Three researchers were involved in the analysis.
The primary researcher, who conducted the interviews, did the initial open coding of the interview transcripts.
To ensure credibility of the codes, a second researcher cross-checked all the codes against the interview transcripts.
At the same time, the third researcher reviewed the initial codes and all quotes supporting each code.
Any differences and/or issues arising from the initial coding were discussed and resolved among the three researchers.
A codebook consisting of 130 codes emerged from the initial coding.
These codes were then applied across other interviews through constant comparison, while new codes were added as they emerged and were deemed necessary.
In further analysis, the three researchers discussed and grouped the codes into themes (axial coding) and categories (selective coding), based on the properties and dimensions of each theme.
Regular coding meetings were held to discuss any emerging codes and to group the codes into families.
The survey tool was developed from the Grounded Theory analysis of the interview data to test a number of significant themes.
Scenarios used in the survey were developed from analysis of anecdotes from the interviews, and themes that emerged from the analysis.
The aim was to ensure that the participants were presented with scenarios they are familiar with, hence reducing the effect of unknown personal preferences.
We made sure that our options to the scenarios were testing the construct under study.
Hence, options with factor loadings less than .30 were dropped.Prior to running the full survey, the tool was piloted and tested with seven participants.
To ensure we tested for both clarity and usability of the tool (face validity), we developed and tested it on the platform it would run on (Unipark).
The questionnaire went through three iterations of testing, and modification with our participants (four nonexperts and three experts -two in usable security research and one in human-centred computing studies).
Two non-experts tested the instrument online, followed by cognitive interviews [46].
The participants were asked how they understood and interpreted each question; how easy they found it to understand each question and respond; how easy it was to navigate through the whole questionnaire; and how they viewed the general outline of the questionnaire.
This was followed by expert interviews as applied in [37], where each expert was asked to first test the survey online, and then review each item on the survey tool in terms of biases, question ordering, clarity, sensitivity of questions, and other issues; all in line with the aim of the study.
After this phase, the last two non-experts tested the tool, followed by cognitive interviews.During each of these phases, the tool was updated based on feedback from the interviews.
Once a consensus was reached on all issues affecting different aspects of the tool, we published the study on Prolific Academic targeting 1128 UK only respondents.
We asked participants about demographic information including age, gender, and educational level.
Survey questions revolved around factors that influence security decision-making (survival/outcome bias, confidence in a security measure, and availability and quality of support), characteristics support (duty of care and continuity of care), and preference and sources of support.To check the quality of responses, we applied three kinds of checks.
First, we used Prolific's start and finish times to check for speeders.
During testing of the questionnaire, the average completion time was fifteen minutes.
After publishing the survey on Prolific, we applied demographic filters of the survey platform on the first set of fifty responses to get a representative sample of the demographics shown in Figure 2.
The average completion time remained fifteen minutes, with a minimum of twelve minutes.
We set our minimum acceptable response time at ten minutes.
Responses below the limit were rejected.
Second, we checked for and rejected straight-liners -responses that all have the same answers, and pattern responses -answers in a pattern.
Third, we included a binary red herring question which read, "I am randomly answering the questions" with a "Yes" or "No" answer.
We placed one towards the middle of the questionnaire, and another towards the end.
Responses bearing a "Yes" to any of these questions were rejected.Due to the ordinal nature of our data, we tested for reliability of different constructs -each measured by a scale of items -on the final questionnaire by computing their ordinal alpha coefficients (Ordinal α) [18].
The constructs had the following coefficients: survival/outcome bias, .75; confidence in a security measure, .74; duty of care -motivate others, .91; duty of care -be motivated by others, .83; and duty of care -social responsibility, .81.
Since our test for continuity of care involved repeated measures, we tested for the reliability of the eight pairs of items using Spearman rank correlation coefficient (rs).
There were positive correlations between each of the eight pairs of items, all significant at p < 0.05.
The Spearman coefficients for the pairs were, rs(1085) = .594, .672, .601, .583, 638, .564, .499, .530 for pairs A through H discussed in section 4.3.2 respectively.
For the survey data, we present descriptive statistics for the different variables.
We also run inferential tests on the data including Friedman [16] and Wilcoxon Signed-rank [45] tests for analysis of matched-pair data and rank-ordered data.
These non-parametric tests were selected on the basis of the ordinal nature of our data, where the chances of getting valid results from parametric tests were minimal or unclear.
Our study has some limitations.
First, all are participants are residents of the UK.
This might raise questions regarding generalisability of our results.
However, we have documented the procedure we followed in this study, which makes it possible for other researchers to replicate it elsewhere.Second, common to all qualitative studies, researcher bias is a concern.
A single researcher, trained to conduct research interviews, conducted all the 65 interviews.
The researcher avoided leading questions, and ensured participants felt comfortable to respond to questions.
The researcher avoided interrupting participants, and probed for more information when required.
To further mitigate bias, two other researchers reviewed and were part of the data analysis to enhance consistency in data coding.
Our research design explicitly aims to mitigate potential bias by also running an extensive survey to test how generalisable the qualitative findings are.Third, given that security is a sensitive topic, social desirability could bias some of the responses to the survey, specifically for the two scenarios developed to study survival/outcome bias and confidence in a security measure.
To Figure 1: Interview participant demographics mitigate this, we took three measures: 1) we did not reveal at the onset that the main purpose of the survey was to study security practices of the participants.
Instead, we stated that the aim was to understand decision-making in the daily use of technology.
2) We employed a self-administered questionnaire [28], hence no interviewer presence and a high degree of anonymity.
3) We used indirect (structured, projective) questioning [13] in those two scenarios, where respondents answered from the perspective of another person.Lastly, our data consists of only what people say.
This makes it hard to understand how our results translate into actual behaviour in the home.
Future work would aim to employ relevant approaches to study these behaviours in context.
In this section, we detail the findings of our study.
We start by presenting the demographics of our participants, and then discuss the key findings from our study organised according to the research questions.
First, we discuss the factors that influence the outcome of security decisions in the home.
Second, we explain the different factors that our participants reported using to evaluate the quality and source of security support.
Finally, we detail the characteristics and sources of security support in the home.
Our scoping study comprised 9 male and 6 female participants, with ages ranging from 18 to 34, and an ethnicity of 4 Asians, 5 Whites, 4 Africans, and 2 Black Americans.
For the targeted semi-structured interviews, we selected 60 people to interview, 50 of which attended.
We kept a balance between male and female participants, as well as a diversity of age, ethnicity, education, and employment status.Demographics for our 50 participants are shown in Figure 1.
Two participants indicated being both students and em- Figure 2: Survey participant demographics ployed, while one indicated being both employed and selfemployed.
52% of our participants were male, 48% were female.
44% belonged to the 18-34 age group, 48% belonged to the 35-64 age bracket.
During the interviews, these two age groups were noted to be the ones responsible for making most of the security decisions in the home environment.
The other two age groups, 12-17 and 65+, made up 4% of the participants each.
32% of the participants hold postgraduate degrees, 24% have graduate degrees, 16% completed undergraduate studies, 4% completed trade/technical/vocational training, 22% completed high school, and 2% did not complete any school level.
1128 respondents took part in the survey.
After running quality checks on the data, 41 responses were excluded, leaving 1087 responses.
Fifty percent of our participants were male, and fifty percent female.
Forty seven percent were between the age range of 18 -34, fifty percent between 35 and 64, while three percent were above 65 years old.
Of all the participants, less than one percent had not completed any education, twenty six percent had completed high school, fourteen percent had done trade/ technical/ vocational training, twenty two percent had undergraduate degrees, twenty four percent had graduate degrees, and fifteen percent had postgraduate degrees.
The demographics of our participants are summarised in Figure 2.
We asked our interview participants questions regarding their security decision-making process in order to identify factors that influence the outcome of such decisions.
In addition to other factors (knowledge and skill, inconvenience, cost, trust, and influence) that have been reported by other studies before (ref.
Section 2), we identified three other areas that have not been explored yet.
These include survival/outcome bias, other factors that induce or undermine one's confidence in a security measure, and the availability and quality of support.
We discuss these in detail below.
Our analysis of the interviews reveals a tendency for participants to concentrate on practices that have survived security breaches, and to overlook those that have not.
This was a reason some participants gave for not implementing recommended security measures.
They believe that as long as something bad has not happened yet, they are safe: "For me, until something happens, I will be safe" -P4.Even in the face of a security concern, some participants report not engaging in security action because "I think it's probably the fact that as far as I'm aware of, I haven't had Not that I'm aware of, no.
I think if I was exposed to something which was quite serious, then I would probably change my look quite a lot" -P6 or "I don't think I have because I have not had any reason to.
That's why personally I just feel like as long as it has not done anything that would cause direct harm to like my information or anything like that, [it is secure].
I haven't felt the need to do any other security check to keep up with any security information because I haven't experienced anything that would cause me to do that.
So I feel like until I have that experience with maybe an application, then I might either delete the application, or look for some security measures that I might take" -P1.While realising that statistical validation of this factor requires some complex and detailed study design as shown in [4], we crafted a scenario to make a preliminary exploration of the availability of this factor.
We presented the respondents with two options, both indicating survival/outcome bias.
Shown below is the scenario:For the past 5 years, your friend John has been downloading free music, videos, and software from different websites including torrent sites without any problem.
One day, he reads an article about the dangers of free downloads such as viruses, adware, Trojan horses, worms and spyware.
For each of the following options, how much do you agree that it is a good choice for John?
A -Continue downloading free files from any website as usual.
He has been doing it for 5 years without a problem, chances of being affected are very small.
B -Restrict the downloads to those websites John has already used before.
He has used them for 5 years without a problem, he trusts them to be secure.The options were evaluated on a 5-point Likert scale ranging from Strongly Disagree to Strongly Agree.
The results showed that about 22% agreed with option A, while about 46% of the participants agreed with option B (cf. figure 3).
While there was a statistically significant difference between options A and B (Z = −18.058, p = 0.000), our aim was to make an initial exploration of the availability of survival/outcome bias, and not to study types or levels of survival/outcome bias, or factors that affect the construct.
In our analysis of the interviews, we found that where a security measure was in place and the participants were confident in it's effectiveness, they would trust the service or action to be secure; "With financial, there was one time when my credit card was charged to two transactions that I did not recognise.
I immediately contacted the bank, and I was able to describe why I couldn't recognise them, and the bank believed me and refunded my money... That made me confident in using online shopping, and financial services" -P7 ... and similarly "I am less concerned about banking because I find that the banking services I use to be secure, and I am often reassured by the fact that if something were to go wrong, the bank is likely to compensate me for any fraud or any security breaches that would result in the loss of my money" -P21.
This confidence is not always to do with security measures implemented by a service provider however; "If they have got work stuff on their laptop, or they are one of those people that have a word document with all their passwords on it, people do that, then I would probably advise them to think about high level security, or at least password-protecting files because I think it's very interesting that there has been an increase in people holding data hostage, and say pay us this, and you can have your files back.
That for me would be like, ok you can keep it.
I am not that bothered.
Any photos I have got are uploaded to the cloud, there is nothing on my desktop that I need that can't be replaced.
But for a lot of people, that obviously is not the case."
-P5.To explore this factor, we crafted the following scenario:Your friend Felicity is a college student.
She owns a laptop.
She stores assignments and study materials on it.
Felicity visits her friend, Laurel, whom she finds watching a very interesting movie.
Felicity asks Laurel if she can share the movie with her, as well as some of the music Laurel downloaded.
Laurel copies all the files to a USB stick, and hands it over to Felicity.
On their way out, Laurel tells Felicity that she thinks her laptop might have a virus because she could not open one of her word documents to study, and this has happened to her a number of times.
For each of the following options, how much do you agree that it is a good choice for Felicity?
A -Felicity could copy the movie and music to her laptop.
Laurel probably got a corrupted file, there is nothing to fear.
B -Felicity could copy the files to her laptop.
She has an antivirus which will keep her data secure.
C -Felicity could take and maintain a backup of her files in a USB stick, phone storage, cloud storage, external drive, another computer, etc.
She could hence copy the movie and music to her laptop.
She can always get the files from the backup when needed.We introduced option A to indicate taking no action, here serving the purpose of a control variable.
The other two options, B and C, were used to test the participants' confidence in the implemented security measures and the subsequent behaviour following from their confidence.
These options were also evaluated on a 5-point Likert scale ranging from Strongly Disagree to Strongly Agree.
The results (cf. figure 4) showed that about 14% agreed with option A, about 26% agreed with option B, and about 46% agreed with option C.A Wilcoxon signed-rank test showed that the introduction of an antivirus in B resulted in a significant statistical dif- Similarly, the Wilcoxon signed-rank test showed a significant difference between options A and C (Z = −21.855, p = 0.000), where a backup was introduced as a security measure.
While there was also a significant statistical difference (Z = −14.497, p = 0.000) between options B and C, it was not our aim to compare different security solutions, and we hypothesize that this might have occurred due to the participants' perceptions, preferences, needs and experiences.
Our analysis of the interviews surrounding security decisionmaking in the home revealed that our participants constantly need support in their endeavour to be secure.
Previous studies have explored support in terms of security advice or information [38,37,21,34].
While this is a common trend, there is evidence [3,33,17,27] of a low success rate of such form of support.
We thus set out to first identify the kind of support that is needed or exists in the home regarding security.
Our analysis revealed a number of different kinds of support currently present and/or needed in the home: information, advice, and technical help.While there might be some differences between information and advice, we noted that participants treated the two as the same.
This challenge is also seen in other studies [38,34] that have been done on this topic, where they interchangeably refer to the two without any difference.
To avoid introducing discrepancies in the results, we therefore treated these two as one, and referred to it broadly as security advice.
Our analysis pointed out the following kinds of advice that our participants talked about:• Advice on available security tools or controls • Reviews about a particular security tool or control • Information on the cost of protection • Opinion or recommendation for a particular securityrelated action, e.g. permissions requested by applications • Advice on privacy settings • The risks for a specific environment, service, or tool • Where they can get support with a particular problem Technical support was reported to be common mostly among the social circles of the participants.
This included some aspect of responsibility where someone, who is perceived to be more competent or feels responsible, assumed the responsi-bility of making security decisions on behalf of others (that is, decide and act on their behalf).
Parents for example reported making decisions for or offer advice to their children; "I give that [advice] as a concerned parent just as I would encourage them to look both ways when they cross the road.
They don't ask me for that advice."
-P4, "I don't think anyone is really responsible for the household.
Myself and my wife will have some say in what the children can or can't do on their devices.
But no one person is responsible for that."
-P30; friends on behalf of their friends, "One of my friends is good with computers.
He does all the security stuff for me when he comes."
-P48.We were particularly interested in how participants choose where to seek this support and/or whether or not to accept any unsolicited support that is offered to them.
In this regard, we identified five factors that are used to assess a source and/or the quality of support: perceived competence, trust, availability, cost, and closeness to a source.i.
Perceived Competence: The notion of better than me was common among the participants when talking about a source of security support.
We understood this to mean the perceived competence of the source of support; and 91% of the survey participants agreed to consider competence in seeking or offering support.
The participants reported making a comparison between their self efficacy and the perceived competence of a potential source.We sought to identify the metrics that are used in this comparison, or in other words, how the different participants understand competence in security.
Our interview results showed that for some it means someone who works in data security; 86% of the survey participants nodded to this.
For others, it means someone who works for a technical company, regardless of whether their job is technical or not; 24% of the survey participants agreed to consider this metric.
More than that, it also means someone whose job is technical ; 24% of the survey participants agreed with this.Another metric used in assessing someone's competence involves identifying someone with more experience in using technical devices than the one seeking help; 51% of our survey participants agreed with this.
27% consider someone who has studied/studies a technical course.
7% go for someone who is more educated than the one seeking help.
78% said they choose someone who has studied/studies data security.
39% seek help from those who have experienced a data security incident before; and only 4% said they do not consider any of these factors when choosing a source of support.
The survey participants were asked to select more than one metric they consider, hence the percentages total more than 100.
In addition to selecting the metrics the participants consider in assessing the competence of a potential source of support, we also asked the participants to rank these metrics in order of preference.
A Friedman Test on the metric rankings showed that there was a statistically significant difference (X 2 (7) = 3218.784, p<.05).
Post hoc analysis with Wilcoxon signed-rank tests was conducted with a Bonferroni correction applied, resulting in a significance level of p = 0.002.
There were no significant differences between options A and D (Z = −.339, p = 0.735), or between A and H (Z = −1.320, p = 0.187), or between B and H (Z = −1.744, p = 0.081), or between D and H (Z = −1.646, p = 0.100); however, B was ranked higher than A (Z = −4.662, p = 0.000), and higher than D (Z = −3.909, p = 0.000).
The overall ranking is:1.
F: He/she works in data security.
2.
G: He/she studied or studies data security.
3.
C: He/she has more experience than you in using or working with technical devices and services.
4.
B: His/her job is technical.
He/she studied or studies a technical course; H: He/she has experienced a data security incident before.)
6.
E: He/she is more educated than you.ii.
Trust: Previous studies [38,37,31] reported that trust plays a role when users choose a source of security advice.
Similarly, our study found that trust influences the choice of a source of support among our participants.
Characterising this in our study was the availability of a social relationship between those involved.
This is also reflected in the preferences of a source of support, discussed in 4.3.1.
When seeking advice for instance, "because they are my closest friends and I kind of trust what they have to say.
I know that they give me an honest opinion" -P29; and "they are my parents.
So I am their closest relation.
I think they trust me a lot" -P2.
89% of the survey participants indicated considering trust when they seek or accept security advice or help.iii.
Cost: Our study confirmed what other researchers [21,31] have reported about the importance of cost in security.
We went further to identify two dimensions of cost among our participants that are considered in deciding when, and where to seek support.
First, cost to the one seeking help, which includes money, favours, and gifts.
Second, there is cost to the source of support, which is characterised by effort, and inconvenience.
These dimensions were evident in reported (from interviews) security support sought and offered among the social relationships of the participants.
In the survey, we asked the participants to choose which of the two they took into consideration when choosing a source of support.
49% indicated that they consider the cost to the one seeking support as an important factor, and 36% consider the cost to the source of support to be a significant factor.iv.
Closeness: When we tried to find out about the sources of security support in the home in our interviews, one thing that was not clear was whether the preference of the sources was determined by (constant) availability of the source, or how close one is to the source.
Phrases such as "my friends", "my dad", and "my work colleague" could not explicitly clarify which of the two was in play.
When asked why they chose such sources, the common responses were "because they are better than me", "they know me", or "I trust them".
We hence separated the two, closeness and availability, and surveyed them as separate factors.
31% of the survey participants indicated that they consider closeness as a significant factor in selecting a source of and accepting support for their security.v.
Availability: Our analysis of the interviews indicates a common pattern in the sources of security support, be it advice or technical help.
Such consistencies included friendto-friend, parent-to-child, between couples or within a fam-ily, among work colleagues, and client-to-commercial IT Services Professional.
In the survey, we asked the participants if constant availability of a potential source of support is an important factor.
31% of the participants indicated that they consider availability as a significant factor.Only 1% of the survey participants indicated that they do not consider any of these factors when selecting a source of security support.
We also asked the participants to rank these factors in order of preference.
A Friedman Test on the ranked factors showed that there was a statistically significant difference (X 2 (5) = 2444.265, p<.05).
Post hoc analysis with Wilcoxon signed-rank tests was conducted with a Bonferroni correction applied, resulting in a significance level of p = 0.003.
There was no significant difference between availability and cost to you (money, favour, gifts, etc) (Z = −.835, p = 0.404).
The overall ranking therefore is as shown below:1.
Competence 2.
Trust 3.
Availability and Cost to you (money, favours, gifts) 4.
Closeness 5.
Cost to the source of advice/help (effort, inconvenience)In the next section, we discuss what characterises security support in the home.
We detail the how the evaluation of the five factors discussed in this section impact the sources of support, and the reasoning behind the choices and practices.
Our analysis of the interviews reveals that participants mostly had the same sources for advice and technical help.
These included family, friends, work colleagues, service providers, and IT repair shop professionals; with family and friends being the most common source.
This corroborates other studies [38,37,11,17].
Other sources include search engines ("I searched online for people with the same problem and got many results.
People gave many solutions and I tried several of them until I got one that seemed to work."
-P23), and specific websites ("Sometimes you go to sites that you think are credible like stackoverflow... some credible sites or sites that look credible to me.
I just read about what people have experienced and how they went about it."
-P11).
None of the sixty five interviewees cited any security awareness websites as a source of security advice.
We did not expect our participants to recall details of websites they visit for security information, but this is consistent with the findings of Furnell et al. [17], who found that the majority of their respondents had not heard of public awareness websites (including Get Safe Online: https://www.getsafeonline.org/, and Webwise: http://www.bbc.co.uk/webwise).
Our analysis shows that the preference and choice of a source or recipient of security support in the home is characterised by two main attributes: duty of care and continuity of care.
Participants consider security support in the home a moral obligation to ensure the safety or well-being of others.
This duty of care is expressed through the following modalities.i.
Delegation: As explained in section 4.2.3, support for security in the home involves seeking or accepting advice, but also encompasses users taking security responsibility for others to ensure their well-being.
We found that some people delegate the responsibility for security to competent, and trusted others; a result shared by Dourish et al. [11], who found that people "delegate to another individual, such as a knowledgeable colleague, family member, or roommate".
Some of our participants said; "Me!
Mum always.
I guess because my husband thinks I'm more knowledgeable about computers and about settings for the internet" -P7; and"Oh!
My husband, because he has always been keen on computers and adopting technology, and that is a big part of his work.
So he is the one who does that [all security tasks]" -P45.
A similar finding is also presented in [31], "There is a friend who usually comes here.
Mostly he is the one.
If the laptop has a virus, I give it to him.
"ii.
Motivation: A second way in which duty of care is expressed is by motivating others to behave securely.
This generally includes offering unsolicited support.
Our interview data shows two aspects of unsolicited support: 1) when somebody notices a practice they believe to be insecure and they intervene (e.g. "they just feel like they can send a young person like 'go and check my email', and they give you all the details to check the emails and I'm like, it's supposed to be private."
-P1); and 2) when there is nothing specifically wrong but support is offered (e.g. "My parents, I do advise a lot about different security issues.
They are just aware of it" -P43).
Unsolicited support without noticing a particular need was common in cases where there was delegation and participants felt responsible for the security of another.We asked survey participants how likely they are to offer unsolicited advice and technical help to someone they believe to be less competent in security than them.
Since the interviews show that this practice is common among relatives, friends, and colleagues, we sought to explore in our survey how widely held such behaviour is.
Our survey shows that about 56% of the respondents are likely to offer unsolicited support to a relative; about 47% to a friend; about 27% to a work colleague; and about 12% to other sources.We also asked the participants to rank who they would likely offer unsolicited support to, in order of preference.
A Friedman Test on the ranked order of preference showed that there was a statistically significant difference (X 2 (3) = 2127.517, p<.05).
Post hoc analysis with Wilcoxon signedrank tests was conducted with a Bonferroni correction applied, resulting in a significance level of p = 0.008.
The overall ranking in order of preference is as shown below:1.
Relative 2.
Friends 3.
Work colleague 4.
Others But offering unsolicited support is only one side of the coin -to fully explore this, we also asked participants how likely they are to accept unsolicited advice or help with data security from different sources of support.
About 63% of respondents reported being likely to accept it from a relative; 63% from a friend; 48% from a work colleague; 44% from a service provider/manufacturer help desk; 40% from an IT repair shop professional; and about 12% from other sources.We asked the participants to rank these sources in order of preference.
A Friedman Test on the ranked sources of support showed that there was a statistically significant difference (X 2 (5) = 1987.664, p<.05).
Post hoc analysis with Wilcoxon signed-rank tests was conducted with a Bonferroni correction applied, resulting in a significance level of p = 0.003.
There were no significant differences between Relatives and Friends (Z = −2.153, p = 0.31), or between Work colleague and Service Provider/manufacturer help desk (Z = −1.990, p = 0.047).
The overall ranking in order of preference is as shown below:1.
Relatives and Friends 2.
Work colleagues and Service Provider/Manufacturer help desk 3.
IT repair shop professional 4.
Others We sought to understand the extent of care and intervention in cases where the participants notice a practice they believe to be insecure, and crafted the following scenario:Assume you have a sister named Vanessa, and you believe her to be less competent than you in data security.
One day you visit her, and while you use her laptop, you notice that her antivirus is not set to automatically scan removable media, such as USB sticks, when they are plugged in.
For each of the following options, how much do you agree that it is a good choice?
A -Change the settings of the antivirus to enable auto-scan of removable media, and say nothing.
B -Change the settings of the antivirus to enable auto-scan of removable media, and tell Vanessa what you have done.
C -Leave the settings as they are.
It is Vanessa's choice to disable auto-scan.
D -Leave the settings as they are.
It is not your responsibility.
E -Ask Vanessa why auto-scan is disabled.The results showed that 27% of the participants agreed with option A; 68% with option B; 23% with C; 19% with D; and 90% with option E.
A Friedman Test on the ranked order of preference showed that there was a statistically significant difference (X 2 (4) = 1634.910, p<.05) in the choice of the options.
Post hoc analysis with Wilcoxon signed-rank tests was conducted with a Bonferroni correction applied, resulting in a significance level of p = 0.005.
The overall ranking in order of preference is:1.
E: Ask Vanessa why auto-scan is disabled.
iii.
Social Responsibility: As evidenced in the last scenario regarding responsibility towards the security of others, option D received the least agreement (19%), and was the lowest ranked.
Our interviews reveal that participants consider security support in the home as an obligation to act for the benefit of society.
What is more interesting is the scope of this society; who do the participants consider part of their security/secure society?
"I give it [security advice] to a certain level... I am not an expert in security, but people ask me and I tell them my thoughts... whoever asks me... anyone.
.
I mean colleagues at work, my friends, my relations" -P40. "
[I give advice] to help her... [and to] everyone if I know them and I am sympathetic to them" -P36.We asked our survey participants how likely they are to seek advice or help from a source of support that they believe to be more competent than them.
The sources included relative, friend, work colleague, service provider /manufacturer help desk, IT repair shop professional, and others.
We found that about 80% are likely to seek advice or help from a relative; about 85% from a friend; about 71% from a work colleague; about 58% from a service provider/manufacturer help desk; about 51% from an IT repair shop professional; and about 16% would seek support from other sources.We also asked the participants to rank these sources in order of preference.
A Friedman Test on the ranked order of preference showed that there was a statistically significant difference (X 2 (5) = 2066.482, p<.05).
Post hoc analysis with Wilcoxon signed-rank tests was conducted with a Bonferroni correction applied, resulting in a significance level of p = 0.003.
There was no significant difference between Relatives and Friends (Z = −0.684, p = 0.494).
The overall ranking in order of preference is as shown below: There is a significant difference (Z = −5.618, p = 0.000) in the likelihood of seeking support from a work colleague (71%) and a Service Provider/manufacturer help desk (58%).
However, the rankings indicate a significant difference in reverse; the Service provider/Manufacturer help desk was preferred over a work colleague.
We hypothesize this might be because 1) some service providers or device manufacturers do not provide support with security, and 2) the range of services and devices available in homes is too broad, and expecting participants to go to many service providers and manufacturers for assistance is contrary to the finding in [11] where users expect a unitary solution to security problems.Given the common trend during the interviews where most of the participants indicated that they seek support from friends, relatives, and work colleagues, we wanted to know how likely our participants are to offer support to those that approach them for help.
Asked how likely they are to offer advice or technical help when asked by someone they believe to be less competent than them in data security, the results showed that about 80% would likely offer support to a relative; 78% are likely to help a friend; 67% are likely to assist a work colleague; and 41% are likely to offer support to any other people who seek it from them.
The second characteristic of support in the home that we identified from the interviews is continuity of care.
Our participants look for a continuous caring relationship with an identified competent and trusted individual.
This is evidenced by the preference for availability (ranked third from competence and trust), as shown in section 4.2.3.
From our analysis, two reasons explain this need: 1) In the case of delegation, one needs someone who will be constantly available, and as [11] also reports that people used to delegate to a "person who had helped them in a previous context, such as in discussing what to get, helping them set up the computer, etc.", and similarly "I was involved in helping them set up in the first place... I helped a lady buy a computer, I helped her to get it online.
So she comes to me all the time for information and she keeps asking me questions.
I consult and then go back to her" -P36; and 2) If something goes wrong as a result of the support someone offered, the victim can easily go back and seek further assistance.Our study showed that participants are likely to take responsibility for consequences resulting from support they offered; "I may help to solve the problem" -P28, "I would consider that as my responsibility, if it was compromised" -P47.
To verify how widely shared this belief and practice is, we crafted two scenarios: one without indicating that a compromise was due to advice that the participant might have given; the second indicating that the compromise was due to advice that they had offered beforehand.
We presented the participants with the same answers to both scenario so that we could test the significance of the difference in taking or accepting responsibility.
The first scenario read:Assume you have a friend, Catherine, who you believe to be less competent than you in data security.
She comes to you for help because she had corrupted files on her computer and thinks she has a virus.
What would you do?
A -Do nothing.
The results showed that 3% of the participants agreed with option A; 87% agreed with B; 70% agreed with C; 81% agreed with D; 73% agreed with E; 7% agreed with F; 7% agreed with G; and 56% agreed with option H.While maintaining options A -H, we then presented respondents with an updated scenario as follows:Assume you have a friend, Catherine, who you believe to be less competent than you in data security.
She comes to you for help because she had corrupted files on her computer and thinks she has a virus.
You recall that three months ago, Catherine was trying to install a piece of software, but was failing.
She asked for your help.
You were busy and told her the antivirus was the problem, and to try turning it off.
You now notice the antivirus is off.
What would you do?The results showed that 4% agreed with option A; 90% agreed with option B; 74% agreed with option C; 79% agreed Test Statistics a A2 -A1 B2 -B1 C2 -C1 D2 -D1 E2 -E1 F2 -F1 G2 -G1 H2 -H1 We ran a Wilcoxon signed-rank test against respective pairs of options to check if the changes in the responses were significant.
The test showed significant changes in options B, C, D, F, G, and H.
These results are summarised in figure 5, where the options are presented as x 1 for options from the first scenario, and x 2 for options from the second scenario; where x represents the respective letter for a given option.
Our study has uncovered that participants look for evidence, specifically impact, of security problems for them to feel motivated to practice security.
The perceived absence of harm (to themselves or their social circles) is seen as evidence of good security decisions.
However, harm arises only when an attack is attempted and then successful: a perceived lack of harm is not sufficient evidence to validate a good security decision for the following reasons.First is the case where harm occurred but was not perceived by the home user: for instance a user might download malware that steals information in the background without their knowledge.
Another instance where the perception of harm can fail is in the situation where a successful attack harms a third party outside the notice of the home user: publicised examples of this are the DDoS attack on DyN DNS servers [5] through compromised IoT devices and the 2014 Lizard Squad attack on XBox live and the Playstation Network [26] through compromised home routers.Second is the case where harm genuinely did not happen, however this is not always evidence of a good security decision either.
In the case where no attack was attempted, a lack of harm is no evidence of effectiveness: vulnerabilities might still be exploitable or countermeasures ineffective.Another situation is where an attack was attempted, but was stopped by a third party before material harm occurred.
For instance, a home users' credit card details might have been stolen while shopping on an illegitimate website, but the bank stopped the attacker from using the details.Only in the third case, where attempted attacks are genuinely mitigated down to no harm, does the perceived absence of harm actually demonstrate evidence of a good security decision.
We believe that this is strong evidence that survival/outcome bias is a key element in poor security decisions, and that the wider challenge of evaluating a good security decision is a difficult problem for home computer users (and arguably the wider security community).
Related to the difficulties of evaluating good security deci-sions is the challenge that home users face when evaluating the competence of those they seek support from.
For example, participants reported that the ability to use technical devices better than them was used to support the assessment of competence, however this is not clear evidence of security competence.
This problem is somewhat mitigated when home users seek support from people within their social circles, where trust and remedial help may be available in the case where problems arise.
However, outside of established relationships and remediation, the challenge remains difficult for home users in telling the difference between a genuinely competent individual, an incompetent individual (who may or may not be aware of the fact), and in the worse case a malicious attacker seeking to take advantage by masquerading as a helpful individual.Home users need to be able to evaluate the quality of a security decision or source of support.
In the absence of clear indicators of quality, a variety of different practices have emerged, yet their effectiveness is questionable.
A key challenge remains to uncover the means of making quality more evident to non-experts both for security products/practices, and for the skills, knowledge, and characteristics of those who offer support.
This is a hard challenge, particularly where such indicators might then be spoofed by malicious actors, however we believe it is still important to work at making good security evident to non-experts considering the wide variety of non-malicious situations where they may need to make a decision or seek support.
We have explored the role that social relationships play in security practice in the home.
While the need for continuity of care may seem odd, it also reflects common security practices in organisational settings.
Even though employees are offered security training and awareness, there are usually support people to whom they can turn to when they have issues.
In addition to resolving problems, security support is also responsible for carrying out proactive security activities such as firewall configuration, system patching, network monitoring, and many more.
In contrast to this, every home is considered to be responsible for its own security, whether it is competent to do so or not.
As a result, a wide variety of different practices exist around seeking and giving support for security in the home context.
As Dourish et al. [11] observe, the knowledge and skill of a trusted and competent person is one element of a person's defense against potential threats.
In this paper, we have discussed social relationships in the context of informal support networks that exist in the home environment.
We postulate that these existing networks can be leveraged to provide appropriate and relevant support to home users.Prior work has investigated how the security behaviour of home users can be changed.
Different improvements to security awareness techniques have been proposed and tested, yet evidence [17] shows that despite claims of being aware, home users still do not practice security.
One reason for this is that while awareness might impart knowledge, it does not cover skills; a very essential aspect of security practice.
Based on our findings, we argue that the security posture of the home is more likely to improve by targeting the support network rather than the user directly for two reasons:First by targeting the support network, change is introduced at the point where security work is more likely to occur.
We believe that by providing tools, training, education, and incentives to those who provide help to others, there is a better chance of achieving a measurable beneficial change to the security of homes.Second, given the importance of social relationships and the trust placed in the support networks of home computer users, we believe that leveraging these is also a promising approach for transferring both security knowledge and skills to home computer users.
Owing to the cost of building a support infrastructure that meets all the requirements discussed in this paper, we believe a fruitful approach is to investigate how social relationships could be leveraged through collaborative technology, social media, and training that focuses on building independent competent communities.
Our research has focussed on the key role of social relationships in home data security, and the reasons behind these informal support networks.
We have also uncovered two important factors that explain why some home users do not behave securely: outcome bias and confidence in security measures.
Based on our findings, we put forward the following recommendations:Leverage existing social relationships: While awareness is important, current practice has focussed on improving the security awareness of individuals or end-users.
We suggest focussing on finding ways of targeting existing informal networks of support: building competence, targeting tools, and fostering a sense of trust and recognition.
This leverages two characteristics of support currently sought in the home -duty of care and continuity of care.Simple and useful tools: We need more tools targeted at home users.
First, tools that non-experts (especially the existing informal support workers) can use to manage security configurations for different devices and services in the home.
Currently, the proliferation of networked devices and services in the home makes the task of managing security complex, and security configurations need to be done on each and every device and service separately.
As Dourish et al [11] state, people expect a unitary solution to a number of security problems.
Developing tools to manage security configurations of a number of devices and/or services centrally would motivate home users and simplify this task.Second, tools need to be developed to help the informal support workers that currently assist home users.
This might include remote assistance, network monitoring, or incident management tools.
It is important to note that this also raises a wide variety of different challenges pertaining to consent, privacy, and standards of care, in addition to fundamental security considerations.Evidence-based security: Finally, our work has shown that home users look for evidence of harm to evaluate the quality of their security decisions, and to be motivated to make changes.
We hypothesise that this might be due to current mechanisms failing to effectively convey knowledge of an attempted or successful incident.
This suggests that there is a need to find ways of detecting and communicating (in a simple, concise, and understandable manner) any attempted, successful, and failed attacks.
How would you rank the options selected in the question above in order of preference?
Assuming you believe each of the following to be more competent than you in data security, how likely are you to seek advice or help with data security from him/her?
Assuming you believe each of the following to be less competent than you in data security, if they ask you for advice or help with data security, how likely are you to offer it?
Assuming you believe each of the following to be less competent than you in data security, how likely are you to offer unsolicited (not asked for) advice or help with data security to him/her?
Your friend Felicity is a college student.
She owns a laptop.
She stores assignments and study materials on it.
Felicity visits her friend, Laurel, whom she finds watching a very interesting movie.
Felicity asks Laurel if she can share the movie with her, as well as some of the music Laurel downloaded.
Laurel copies all the files to a USB stick, and hands it over to Felicity.
On their way out, Laurel tells Felicity that she thinks her laptop might have a virus because she could not open one of her word documents to study, and this has happened to her a number of times.
For each of the following options, how much do you agree that it is a good choice for Felicity?
(Responses: I strongly agree, I agree, Neutral, I disagree, I strongly disagree) A. Felicity could copy the movie and music to her laptop.
Laurel probably got a corrupted file, there is nothing to fear.
B. Felicity could copy the files to her laptop.
She has an antivirus which will keep her data secure.
C. Felicity could take and maintain a backup of her files in a USB stick, phone storage, cloud storage, external hard drive, another computer, etc.
She could hence copy the movie and music to her laptop.
She can always get the files from the backup when needed.How would you rank the options in the question above in order of preference?
Assume you have a sister named Vanessa, and you believe her to be less competent than you in data security.
One day you visit her, and while you use her laptop, you notice that her antivirus is not set to automatically scan removable media, such as USB sticks, when they are plugged in.
For each of the following options, how much do you agree that it is a good choice?
