Recently, directed grey-box fuzzing (DGF) becomes popular in the field of software testing.
Different from coverage-based fuzzing whose goal is to increase code coverage for triggering more bugs, DGF is designed to check whether a piece of potentially buggy code (e.g., string operations) really contains a bug.
Ideally, all the inputs generated by DGF should reach the target buggy code until triggering the bug.
It is a waste of time when executing with unreachable inputs.
Unfortunately, in real situations, large numbers of the generated inputs cannot let a program execute to the target, greatly impacting the efficiency of fuzzing, especially when the buggy code is embedded in the code guarded by various constraints.
In this paper, we propose a deep-learning-based approach to predict the reachability of inputs (i.e., miss the target or not) before executing the target program, helping DGF filtering out the unreachable ones to boost the performance of fuzzing.
To apply deep learning with DGF, we design a suite of new techniques (e.g., step-forwarding approach, representative data selection) to solve the problems of unbalanced labeled data and insufficient time in the training process.
Further, we implement the proposed approach called FuzzGuard and equip it with the state-of-the-art DGF (e.g., AFLGo).
Evaluations on 45 real vulnerabilities show that FuzzGuard boosts the fuzzing efficiency of the vanilla AFLGo up to 17.1×.
Finally, to understand the key features learned by FuzzGuard, we illustrate their connection with the constraints in the programs.
Fuzzing is an automated program testing technique, which is usually divided into two categories: coverage-based fuzzing and directed fuzzing.
The goal of the former one is to achieve high code coverage, hoping to trigger more crashes; while directed fuzzing aims to check whether a given potential buggy code really contains a bug.
In real analysis, directed fuzzing is very popularly used since the buggy code is often specified.
For example, security analysts usually pay more attention * Corresponding author to the buffer-operating code or want to generate a proof-ofconcept (PoC) exploit for a given CVE [3] whose buggy code is known.
There are some directed fuzzing tools such as AFLGo [9], SemFuzz [35] and Hawkeye [12].
As we know, a random input is less likely to reach the buggy code, not to mention triggering the bug.
Thus, most of the tools instrument the target program for observing the run-time information and leveraging the information to generate the inputs that could reach the buggy code.
Such fuzzing method is also referred to as Directed Grey-box Fuzzing (DGF for short).
An ideal DGF should generate the inputs which can all reach the buggy code.
Unfortunately, in real situations, a large number of the generated inputs could miss the target, especially when the buggy code is embedded in the code guarded by many (complicated) constraints (e.g., thousands).
Facing this situation, various techniques (e.g., Annealing-based Power Schedules [9]) are designed to generate reachable inputs.
However, even for the state-of-the-art DGF tools (e.g., AFLGo [9]), the ratio of unreachable inputs is still high.
Based on our evaluation using AFLGo, on average, over 91.7% of the inputs cannot reach the buggy code (Section 6).
Such a large amount of unreachable inputs waste lots of time in the fuzzing process.
Traditional program analysis approaches such as symbolic execution [20], theoretically, could use the constraints of all branches in the target program to infer the execution result of the input.
However, the time spent on solving constraints will dramatically increase together with the increase of the constraints' complexity.
In other words, the constraints in the path from the program's start point to the buggy code could be very complex, which makes them difficult or even not possible to be solved in limited time.Inspired by the success of pattern recognition [11,19,34,36] which could accurately classify millions of images even if they are previously unseen, our idea is to view program inputs as a kind of pattern and identify those which can reach the buggy code.
Basically, by training a model using a large number of inputs labeled with the reachability to the target code from previous executions, we could utilize the model to predict the reachability of the newly generated inputs without running the target program.
However, it is challenging to build such an accurate model for DGF due to the following reasons.
Challenges.
C1: Lack of balanced labeled data.
It is necessary to acquire enough and balanced labeled data to train a deep learning model (e.g, classification for cats and dogs).
In other words, the number of one object's images should be close to the number of the other object's.
However, in the process of fuzzing, the (un)reachable inputs are usually unbalanced.
Especially, in the early stage of fuzzing, there is even no reachable input (e.g., for the bug #7 in GraphicsMagick, the first reachable input is generated after more than 22.6 million executions).
Without the balanced labeled data, the trained model will be prone to over-fitting.
One may think of extending the labeled data just like the way of image transformation (e.g., resizing, distortion, perspective transformation), which could increase the number of the object's images to balance the training data without changing the identified object.
However, such transformation cannot be applied to program inputs since even one bit flip may change the execution paths of inputs and further impact the labels (i.e., let a reachable input become unreachable).
C2: Newly generated reachable inputs could look quite different from the reachable ones in the training set, making the trained model fail to predict the reachability of the new inputs.
This is mainly because the new inputs may arrive at the buggy code through a different execution path never seen before.
So simply using the inputs along one execution path to train a model may not correctly predict the reachability of a new input.
One may think of generating various inputs along different execution paths to the buggy code before training.
Unfortunately, such generation process is out of our control.
He may also wait for a long time before training, hoping to collect enough inputs along different paths.
However, this may waste lots of time since many unreachable inputs have been executed with.C3: Efficiency.
In the task of training a model for traditional pattern recognition, the time spent on training is not strictly limited.
However, in the fuzzing process, if the time spent on training a model and predicting an input's reachability is more than the time spent on executing the program with the input, the prediction is of no use.
So the time cost of training and prediction should be strictly limited.
Our approach.
In this paper, we overcome the challenges mentioned above and design an approach to build a model for DGF to filter out unreachable inputs, called FuzzGuard.
The basic idea of FuzzGuard is to predict whether a program can execute to the target buggy code with a newly generated input by learning from previous executions.
If the result of prediction is unreachable, the directed grey-box fuzzer (we use "the fuzzer" for short in the rest of the paper) shouldn't execute this input anymore, which saves the time spent on real execution.
Note that FuzzGuard is not meant to replace the fuzzer (e.g., AFLGo), but to work together with the fuzzer to help it filter out unreachable inputs.FuzzGuard works in three phases: model initialization, model prediction, and model updating.
(1) In the first phase, the fuzzer generates various inputs and runs the target program with them to check whether a bug is triggered.
At the same time, FuzzGuard saves the inputs and their reachability, and trains the initial model using the labeled data, which may be unbalanced (C1).
To solve this problem, we design a step-forwarding approach: choosing the dominators (referred to as "pre-dominating nodes" [5]) of the buggy code as the middle-stage targets, and letting the execution reach the predominating nodes first.
In this way, the balanced data could be gained earlier for training some models only targeting the pre-dominating nodes, which minimizes the time of execution.
(2) In the second phase, after the fuzzer generates a number of new inputs, FuzzGuard utilizes the model to predict the reachability of each input.
As mentioned in C2, the trained model may not work for the newly generated inputs.
To solve this problem, we design a representative data selection approach to sample training data from each round of mutation, which minimizes the number of sampled data to increase efficiency.
(3) In the third phase, FuzzGuard updates the model using the labeled data collected in the second phase to increase its accuracy.
Note that the time spent on the model updating should be strictly limited (C3).
We tackle this challenge by carefully choosing the time to update.
To the best of our knowledge, previous studies of fuzzing focus on generating various inputs, to cover more lines of code (CGF) or to reach buggy code (DGF).
Various mutation strategies on inputs are designed.
In contrast, our study does not directly mutate inputs (we rely on current mutation strategies, e.g., AFLGo).
Instead, we filter out unreachable inputs.
In this way, a DGF does not need to run the target program with unreachable inputs (which definitely cannot trigger the target bug), which increases the overall efficiency.We implement FuzzGuard on the base of AFLGo [9] (an open-source state-of-the-art DGF tool), and evaluate the performance using 45 real vulnerabilities on 10 popular programs.
The results show that FuzzGuard boosts the fuzzing performance by 1.3× to 17.1×.
Interestingly, we find that the more the unreachable inputs the fuzzer generates, the better FuzzGuard could perform.
Also, more time could be saved if the target node reach a balanced state earlier.
At last, we design an approach to understand the extracted features of FuzzGuard, and find that the features are correlated with the constraints in the if-statements in target programs, which indeed impacts the execution on code level.
Contribution.
The contributions of this paper are as follows:• New technique.
We design and implement FuzzGuard which helps DGF to filter out unreachable inputs and save the time of unnecessary executions.
To the best of our knowledge, this is the first deep-learning-based solution to identify and remove unreachable inputs.
The core of FuzzGuard is the step-forwarding approach, and representative data selection.
Evaluation results show that up to 88% of fuzzing time can be saved for state-of-the-art tools (e.g., AFLGo).
We also release our FuzzGuard for helping researchers in the community 1 .
• New understanding.
We design an approach to study the features utilized by the model in FuzzGuard for prediction, and find them correlated with the branches in target programs.
The understanding of such relationship helps to explain the deep learning model and further helps to improve FuzzGuard.
In this section, we give a brief background of directed greybox fuzzing and recent studies utilizing deep learning to improve the fuzzing performance.
Fuzzing [27] is one of the classical software testing techniques to expose exceptions of a computer program [32].
The main idea of fuzzing is to feed a massive number of inputs (i.e., test cases) to the target program, exposing bugs through observed exceptions.
Among all techniques of fuzzing, greybox fuzzing [12] recently becomes quite popular due to its high efficiency and reasonable performance overhead.
With different goals, grey box fuzzing can usually be divided into two types as follows.Coverage-based Grey-box Fuzzing.
One main goal of this type of fuzzing technique is to achieve the high coverage of code in the target program.
Therefore, some fuzzers [2,10,15,16,24,25] aim to achieve high code coverage of the target program, expecting to accidentally trigger the bug, namely Coverage-based Grey-box Fuzzing (CGF).
Typically, CGF generates the inputs by mutating the seed inputs which could traverse previous undiscovered program statements in order to increase the coverage rate of the code.
AFL [2], as a representative of CGF, employs light-weight compile-time instrumentation technique and genetic algorithms to automatically discover interesting test cases, selects seed inputs that trigger new internal states in the fuzzing process, and mutates seed inputs in various ways (e.g., bit and byte flips, simple arithmetics, stacked tweaks and splicing [22]).
Directed Grey-box Fuzzing.
Sometimes, the potential buggy code is known.
So there is no need to increase the code coverage.
In this situation, fuzzers [9,12,35] are designed to generate inputs that reach the buggy code for triggering a specified bug, which is referred to as Directed Grey-box Fuzzing (DGF).
DGF is commonly used since some kinds of code may be highly possible to contain a bug (e.g., string copy operations) which should be emphasized more in the fuzzing.
Also, sometimes the buggy code is known (e.g., from CVEs).
So those fuzzers are utilized to generate a proof-of-concept exploit toward the buggy code [35].
With the different goals from CGF, current DGF aims to generate the inputs which could reach the specific potential buggy code, further expecting to 1 The release is available at https://github.com/zongpy/FuzzGuard.
trigger the bug.
For example, AFLGo [9] calculates the distance between each basic blocks and the path from the entry point to the buggy code in the control flow graph; then utilizes the distance to choose suitable inputs for mutation.However, even for state-of-the-art fuzzers, still lots of time is spent on unnecessary executions.
In our experiments, we find that for a typical vulnerability whose location is known, more than 91.7% of the generated inputs cannot reach the buggy code (unreachable inputs) on average.
Running the target program with the unreachable inputs is highly timeconsuming.
If there is a fuzzer that could judge the reachability of an input without executing the program, a huge amount of time could be saved.
In this paper, we design such a filter called FuzzGuard, which leverages a deep learning model to achieve this goal without real execution.
Also, it could be adapted to existing fuzzers (e.g., AFLGo) and work together with them, without replacing them.
To the best of knowledge, this is the first deep-learning-based solution to filter out unreachable inputs for DGF.
Security researchers apply deep learning to fuzzing, which provides new insights for solving difficult problems in previous research.
For example, Godefroid et al. utilize RNNs to generate program inputs that have higher code coverage [17].
Rajpal et al. [29] utilize RNN-guided mutation filter to locate which part of an input impacts more on code coverage.
In this way, they could achieve higher code coverage by mutating the located part.
Nichols et al. [28] show that GANs could be used to predict the executed path of an input to improve the performance of the AFL [2].
Angora [15] and NEUZZ [31] adapt the gradient descent algorithm to solve path constraint and learn a model to improve code coverage respectively.
All these studies concentrate on leveraging the ability of deep learning to cover more code.
Different from them, our goal is to help directed grey-box fuzzers to filter out the inputs that cannot hit the buggy code before real execution.
In this way, the time spent on running the program with unreachable inputs could be saved, which greatly increases the efficiency of fuzzing.
Note that our tool can be adapted to existing DGF tools (e.g., AFLGo), which means that we could further increase the fuzzing efficiency together with the performance boosted by other fuzzers.
As mentioned above, current DGF aims to generate the inputs which could reach the specific buggy code, further expecting to trigger the bug.
In the fuzzing process, lots of inputs cannot reach the buggy code in the end (impossible to trigger the bug).
Based on our evaluation, more than 91.7% of the inputs can't hit the buggy code on average (see Table 1).
Executing millions of unreachable inputs could cost very long time (e.g., 76 hours for a million inputs when fuzzing Podofo, a library to work with the PDF file format with a few tools [1]).
Especially, when the execution time of the target program takes part the most in the whole fuzzing process, the wasted time is even more.
If there exists an approach that is quick enough to predict the reachability of an input, the fuzzing process does not need to execute the target program with the unreachable ones.
In this way, the overall performance of fuzzing could be increased.
Inspired by the recent success of deep learning in pattern recognition [11,19,34,36], we are wondering whether deep learning could be applied to identify (un)reachable inputs.
Carefully comparing the processes of pattern recognition and identification of (un)reachable inputs, we found similarities between them: they both classify data (a certain objects v.s. (un)reachable inputs) based on either prior knowledge or statistical information extracted from the patterns (many labeled images of the object v.s. many labeled inputs from previous executions).
However, they do have essential differences (e.g., the distribution of labeled data, requirements on efficiency, etc.) which makes the process of unreachable input identification very challenging (see Section 1).
Scope and Assumption.
Different from previous research on CGF using deep learning [15,17,28,29], our approach focuses on filtering out unreachable inputs in DGF.
In this way, lots of necessary time on executing the program with unreachable inputs could be saved.
Note that our approach is complementary to other DGF tools and can work together with them, instead of replacing them.
Also note that we do not assume that small mutations in the input will produce similar or identical behavior.
The trained model should characterize different behaviors of similar-looking inputs.
We propose the design of FuzzGuard, a deep-learning-based approach to facilitate DGF to filter out unreachable inputs without really executing the target program with them.
Such a data-driven approach avoids using traditional time-consuming approaches such as symbolic execution for better performance.
Below we elaborate the details of FuzzGuard.
The overview of FuzzGuard is illustrated in Figure 1, including three main phrases: model initialization (MI), model prediction (MP) and model updating (MU).
It works together with a DGF (referred to as "the carrier fuzzer").
As shown in Figure 1, in the MI phrase, the carrier fuzzer generates a great number of inputs and observes any exceptions.
FuzzGuard records whether the program can execute the target buggy code for each input.
Then FuzzGuard trains a model using the inputs and their reachability.
In the MP phrase, FuzzGuard utilizes the model to predict the reachability of a newly generated input.
If the input is reachable, it is fed into the program for real execution.
In this process, FuzzGuard observes whether the input can really reach the target code.
In the MU phrase, FuzzGuard further updates the model with incremental learning to maintain its efficiency and increase its performance.
The unreachable inputs will be temporarily saved in a data pool (referred to as "the pool of unreachable inputs (PUI)") for further checking by a more accurate model after model updating.
As combining deep learning with fuzzing is not trivial, we face the new challenges (as mentioned in Section 1).
Figure 2 shows a concrete example of FuzzGuard.
Firstly, the carrier fuzzer generates a number of inputs (referred to as "data") and runs the target program with them to get the reachability (referred to as "label") in the MI phrase (the step 1 and step 2 in the figure).
During this process, an ideal situation is to train a deep learning model using balanced data.
That is, about half of the inputs could reach the buggy code while the other cannot.
Unfortunately, in real situation, the carrier fuzzer hardly generates the inputs that reach the buggy code in the initial phrase of fuzzing.
As a result, the labeled data are usually extremely unbalanced at this stage.
For example, only one input can actually reach the buggy code after over 22 million inputs generated (#7 in Table 1).
To solve this problem, we design the step-forwarding approach for MI (step 2 ), which lets the inputs reach the predominating nodes (we use "node" to refer to "basic blocks" in the rest of the paper) of the buggy code (i.e., B 0 , B 1 and B 2 in Figure 2) step-by-step to the destination (i.e., B 3 in Figure 2).
Particularly, FuzzGuard chooses a pre-dominating node (e.g., B 1 ) as a middle-stage destination (i.e., referred to as "mid-target") and generates a model to filter out the inputs that cannot reach B 1 (step 3).
Usually, compared with B 3 , more balanced labeled data could be gained when the program runs to B 1 .
So the model can be trained earlier and also starts to work earlier.
Then MP judges whether a newly generated input (in step 4) could reach B 1 using the model (step 5 ).
For reachable inputs (e.g., with label < 0, 1, 0, 0 > in step 6 ), FuzzGuard runs the program with it and records whether it can really reach the buggy code (step 7).
Such information is further leveraged to continuously update the model by MU (step 8).
The unreachable inputs are put into PUI (step 9 ).
After more inputs are tested, a closer pre-dominating node (to the buggy code) having the balanced labeled data will appear (e.g., B 2 in this case).
Such a process will continue until the buggy code is arrived at, and finally triggered.
Below we provide the details of the three modules.
As mentioned previously, one main challenge of applying deep learning on fuzzing is the unbalanced data for training.
Usually, the number of reachable inputs is far less than that of unreachable ones.
In order to tackle this challenge, we present a step-forwarding approach.
The basic idea is based on the observation: the pre-dominating nodes of the buggy code are earlier to be reached, which should gain balanced data earlier.
Note that the pre-dominating nodes of the buggy code are the nodes that dominate the buggy code: every execution path towards the buggy code will pass through the pre-dominating nodes [5].
So the reachability of the marked pre-dominating nodes is guaranteed.
Therefore, we could train a model to filter out those inputs that cannot reach the pre-dominating node (neither can they reach the buggy code).
In this way, we gradually get balanced data of the pre-dominating nodes, toward the buggy code in the end.
For example, as to the control flow graph shown in Figure 2, the nodes represent basic blocks in the program in List 1.
B 0 is the entry point and the buggy code is in B 3 .
B 1 and B 2 are the pre-dominating nodes of B 3 .
At the beginning of fuzzing, no input reaches B 3 , while half of the inputs could reach B 1 .
Now B 1 is the closest balanced pre-dominating node to the buggy code.
So we view B 1 as the target, and train the model using these inputs.
In this way, the unreachable inputs to B 1 are filtered out, saving the time spent on executing the target program with them.
When the fuzzing process goes further, B 2 or B 3 will get balanced data for training.
Note that, different from CGF whose goal is to achieve high coverage, DGF aims to generate inputs to trigger a given (potential) bug at a certain place.
So it does not care about whether new bugs are found in other paths.
Interestingly, we did see that FuzzGuard+AFLGo still discovers undisclosed bugs (see Section 6) which are located deeply in a program (also near the target buggy code).
An ordinary CGF is hard to trigger them in a limited time.However, it takes too long to train a single model for each pre-dominating node.
This is mainly because the model needs to be retrained when FuzzGuard steps forward to the next pre-dominating node.
Our idea is to only train one model for all the pre-dominating nodes including the buggy code itself.
To achieve this goal, formally, we label the reachability of the nodes (i.e., B = {B 1 , B 2 , ..., B n }) in the vector y. For each label, it is represented as a unit vectorˆyvectorˆ vectorˆy, i.e., ˆ y =< y 1 , y 2 , . . . , y m >, where m is the number of the pre-dominating nodes of the buggy code, y i represents whether the i-th node is the last one could be reached by the program fed with x, y i ∈ {0, 1}, i ∈ {1, 2, . . . , m}.
As shown in Figure 2, for the input a, the label is represented as y a =< 1, 0, 0, 0 >, which means that B 0 is reached but others are not.
Similarly, y b =< 0, 1, 0, 0 > means that the input b can let the execution reach B 0 and B 1 , but neither B 2 nor B 3 .
y d =< 0, 0, 0, 1 > means that the buggy code is finally reached.
For simplicity, we directly map each byte of the input to an element in the feature vector.
This approach makes FuzzGuard handle different programs with various formats of inputs in a unified way.
For each data, it can be represented as a vector x =< x 1 , x 2 , . . . , x n >, where n is the max length of the input.
Andx i = byte i + 1 (x i ∈ {0, 1, . . . , 256}), where x i = 0 means that i-th byte of the input does not exist (i.e., the length of the input is less than n).
After designing the representation of data and label, we carefully choose a deep learning model.
Such a model should be good at extracting features from inputs and making the correct classification.
Recall the problem of image recognition: features of an object in an image are expressed by combinations of several pixels (i.e., elements in the input vector, as shown in Figure 2), which could be well extracted by the CNN models [11,19,34,36].
Similarly, the features of inputs that impact their reachability could be expressed by combinations of several bytes in program inputs.
Actually, the constraints in if-statements in target programs use these bytes for deciding execution directions.
Thus, our idea is to make use of CNN to accomplish the classification task.
On one hand, compared with RNN which is more suitable for training with the byte sequence, CNN is good at dealing with long data.
The longer the inputs, the faster the RNN model forgets the former features.
On the other hand, the time for training a CNN model is much less than the time for training an RNN model, which is suitable for our problem (the time spent on training and prediction should be less than the time on real execution).
Thus, we choose to use a 3-layer CNN model (detailed implementation is shown in Section 5).
In this way, the first layer could learn the relationship between each byte, and the other two layers could learn high dimensional features (e.g., combining several bytes to form a field in an input, and combining several fields to impact program execution).
Interestingly, we find that such extracted high dimensional features are correlated with the constraints in the if-statements in target programs (see Section 7).
We also discuss other machine learning models in Section 8.
Note that, the model needs to be trained for each program from scratch due to different implementations (which parse inputs in different ways).
It is also an interesting topic to explore the similarity between different programs and leverage such similarity to increase the efficiency of training.In this way, we can let the carrier fuzzer run for a while to collect an initial training data set.
After the initial training data set reaches balanced, the model can learn the reachability to all nodes of the inputs.
The goal of the model is to learn a target function f (i.e., y = f (x)), which consists of a number of convolution operations.
The convolution operation uses a number of filters to extract the features from the data:y i = w T x i = ∑ i−k< j<i+k w j · x j , i ∈ {1, 2, . . . , n − k}where k is the width of the convolution kernel of the filter w. Gradient descent algorithm will update weights of each filter w to decrease the loss value to achieve a more accurate prediction.
For classification tasks, compared to Cross Entropy [18] loss, the Mean Square Error (MSE) [23] loss could balance the error rate for each category, avoiding a particularly high error rate for a single category.
Considering the step-forwarding approach needs the trained model to predict the reachability of each pre-dominating node as accurate as possible, we choose to use MSE.
So when the value of theloss = 1 m ∑ m i=1 (y i − y p i ) 2is close to 0, we believe that the target function in the classification model has been converged and the model is ready to predict the newly generated inputs.
After the model is initialized, FuzzGuard utilizes the model to predict the label of each input and filters out those unreachable ones.
For the reachable ones, they will be executed by the target program and further be collected as new labeled data for model updating.
In particular, for an input x, we assume that the model can only predict the pre-dominating nodes before B t (i.e., the mid-target), and the prediction result is y p .
The following function f is used to check whether the input x is reachable to the target node.f (y p ,t) = reachable y p i = 1 ∧ i ≥ t unreachable y p i = 1 ∧ i < tHowever, in real situation, we find the prediction results are not accurate enough, even after many labeled data are produced.
The main reason is that even if the newly generated inputs could reach the target, they may look quite different from the reachable ones in the training set.
This is understandable: these inputs could be generated from different seeds.
Most of the inputs mutated from the same seed are slightly different with each other, while many differences could be found between the inputs mutated from different seeds.
Thus, using the inputs totally from previous executions may not be able to train a very accurate model to predict the reachability of newly generated inputs.
For example, a model trained with the data in set S 1 mutated from the seed s 1 may fail to predict the labels of the data in S 2 mutated from the seed s 2 .
To solve this problem, we propose a representative data selection approach, which selects a number of representative inputs from each round of mutation for executing and training.
We consider a fixed number of inputs (e.g., 5%) that randomly sampled from a round of mutation as the representative data for this mutation.
In this way, within a limited time, inputs generated from more seeds can be utilized for training, which increases the model's accuracy.
However, in real execution, even 5% of the inputs constitute a big number (e.g., over 20 thousand), and execution using these inputs cost lots of time.
Our idea is to sample even fewer inputs.
Suppose in two different mutations, two sets of inputs S 1 and S 2 are generated from the two seeds s 1 and s 2 , respectively.
If the distribution of S 1 is similar to that of S 2 , we can select even fewer inputs.
However, we cannot directly assume that the distributions of the two sets are similar only through the similarity of the two seeds.
This is mainly because different strategies of mutation (e.g., bit and byte flips, simple arithmetics, stacked tweaks and splicing) could greatly change the seeds and make the descendants look quite different.
So our idea is to compare the seeds together with the corresponding strategies of mutations.
If the two seeds are similar and the strategies are identical, we consider to select fewer inputs from the combined set.
We define the seed similarity degree (SSD) between the two seeds s 1 and s 2 as follows:d s 1 ,s 2 = 1 − ∑ 8n i=1 s 1 i ⊕ s 2 i /8nwhere n is the max byte length of the inputs, and s i means the i-th bit of the seed s. Note that different choices of embedding do not affect the definition of SSD, since SSD is defined using the seeds, not the vectors after embedding.
In this way, we could measure the similarity between two sets of inputs through their predecessor seeds.
When SSD is over a threshold (θ s ), we consider that the seed s 2 is similar to the seed s 1 , and less data from the inputs mutated from s 2 should be selected.
For example, in Figure 2, we select less data (e.g., 2%) from the inputs set that generated by seed the e, because e is similar to the seed b (e.g., SSD=90%).
In this way, we could select fewer inputs for real execution and training without impacting the model's accuracy.
Based on our evaluation, on average, half of the time spent on fuzzing could be saved when applying this technique (Section 6).
To realize online model updating, we utilize incremental learning [26] to train a dynamic model by feeding a set of data each time rather than feeding all data at once.
In this case, new incoming data are continuously used to extend the existing model's knowledge.
Incremental learning aims to adapt to new data without forgetting its existing knowledge for the learning model, and it does not require retraining the model.
It can be applied when the training data set becomes available gradually over time as the carrier fuzzer generates and exercises new inputs continuously.
Also incremental learning decreases the time of waiting for data collecting, and filters out more unreachable test cases.The online deep learning model should be updated to keep its accuracy.
Whenever a new set of labeled data is collected, there could be an opportunity for model updating.
However, if the model is updated too frequently, the time spent on training will be long, which will impact the efficiency of fuzzing.
In contrast, if less frequent updating is performed, the model may not be accurate.
So in this process, we should carefully choose when to perform model updating.
Also we should let the updating be quick enough.
Below we elaborate the details.We perform model updating when the model is getting "outdated".
The outdated model is not accurate enough when a new pre-dominating node is reached.
In the first situation, we update the model when the false positive rate γ of the model exceeds a threshold θ f .
To achieve this, we continuously record false positive rates of the model whenever the execution results are different from the predictions, and keep watching γ.
After the model is updated, we reset the false positive rate to zero and record it again.
Another situation is that when there is a new pre-dominating node B i (i > t) containing the balanced labeled data, it is the time to update the model with the new data (see Section 4.3).
In this way, the model could learn new features from the inputs which let the program execute to new code that has never been touched.
Using this approach, we could ensure the accuracy of the model while keeping the model updating at a reasonable frequency.To avoid missing a PoC (i.e., to avoid filtering out any PoC), we temporarily store unreachable inputs in the PUI.
When the model is updated, we use the new model to check the inputs in the PUI again, and pick out the reachable ones for execution.
Based on our evaluation, the model is accurate enough that no PoC is missed.
In this section, we describe the implementation of FuzzGuard, including model initialization, model prediction, model updating and the details of the deployment of FuzzGuard.Model Initialization.
At the initial stage, FuzzGuard starts to train the model only after enough data are collected; and continues to update the model after another set of data (not a single input) are collected.
Such data should be balanced (i.e., the number of reachable inputs is similar to the number of unreachable ones).
Particularly, before the model is trained, all the inputs should be fed into the target program for real execution.
FuzzGuard records the reachability of the inputs.
Once enough 2 balanced data are gained, FuzzGuard starts to train the model.
Then it utilizes the trained model to predict the reachability of a newly generated input, executes the target program if it is reachable, and records the reachability in real execution.
Such data are collected to update the model for better performance.
As mentioned before, DGF requires a target (potential) buggy code whose location is known for fuzzing.
To set the pre-dominating nodes of the buggy node, we generate Call Graph (CG) and Control Flow Graph (CFG) of the target program and set the pre-dominating node according to the definition as mentioned in Section 4.
In our implementation, we use NetworkX [6] to automatically find the pre-dominating nodes from the CG and CFG generated by LLVM.Model Prediction and Updating.
To further collect data for updating the model, we set the θ s for SSD to 0.85 and the default sampling rate is 5% in each round of mutation.
When SSD exceeds the threshold, the sampling rate will decrease to (1 − θ s )/5 (i.e., less than 3%).
Based on our evaluation, setting the threshold using this value has the best performance.
Considering that models' accuracy varies a lot for different label ← check_trace(input) send(label) 6: end if 7: return f ault programs, we dynamically change θ f according to the previous executions: θ f = 1 − acc avg , where acc avg represents the average accuracy of the models updated previously.Model Implementation.
For the training model, we implement a CNN model using PyTorch [7].
It contains three 1-dimensional convolution layers (k = 3, stride = 1).
Note that the 1-dimensional convolution layer takes each input as a row sequence; and each row has 1024 bytes.
Each convolution layer is followed by a pooling layer and a ReLU [4] as the activation function.
We also have Dropout layers (disabling rate = 20%) to avoid over-fitting of the neural networks.
There is a fully-connected layer at the end of the neural networks, which is used to score the reachabilities of each node in the target path to the buggy code.
Also we use the Adam optimizer [21] to help the learning function converge to the optimal solution rapidly and stably.
The training process ends when the loss value of the learning function becomes stable.Deployment of FuzzGuard.
To achieve the data sharing, we add a function Checker() to afl-fuzz.c in AFLGo.
Algorithm 1 shows the details of Checker().
The function Checker() handles all parameters in run_target() (i.e., argv, timeout in Algorithm 1) and receive an input which is saved in a piece of memory.
Before the input is fed into the target program, it is sent to FuzzGuard (i.e., check(input) at line 2 in Algorithm 1).
Only when FuzzGuard returns with the result showing that the execution path is reachable, the target program is executed with the input (line 3 in Algorithm 1).
After executing the target program, Checker() reads the reachability of the input from the function check_trace() (Line 4 in Algorithm 1) and sends it to FuzzGuard for further learning (line 5 in Algorithm 1).
We plan to release our FuzzGuard for helping researchers in the community.
In this section, we evaluate the effectiveness of FuzzGuard with 45 vulnerabilities.
The results are compared with a vanilla AFLGo.
According to the experiment results, FuzzGuard boosts the performance of fuzzing up to 17.1 times faster than that of AFLGo.
Then we provide an understanding of the performance boost and break down the performance overhead of FuzzGuard.
We also analyze the accuracy of FuzzGuard and show our findings.
We first selected 15 real-world programs handling 10 common file formats, including network packages (e.g., PCAP), videos (e.g., MP4, SWF), texts (e.g., PDF, XML), images (e.g., PNG, WEBP, JP2, TIFF) and compressed files (e.g., ZIP).
Unfortunately, three programs (i.e., mupdf, rzip, zziplib) cannot be compiled 3 , and two programs (i.e., apache, nginx) do not give the details of vulnerabilities.
So we chose the rest 10 as the target programs and the corresponding bugs in the past 3 years 4 .
Table 1 shows the details of each vulnerability, including program names and line numbers of the vulnerable code (the column Vuln.
Code).
For different input formats, we use the test cases provided by AFLGo as the initial seed files to start fuzzing (we believe that AFLGo will perform well using the initial seed files chosen by itself).
All the experiments and measurements are performed on two 64-bit servers running Ubuntu 16.04 with 16 cores (Intel(R) Xeon(R) CPU E5-2609 v4 @ 1.70GHz), 64GB memory and 3TB hard drive and 2 GPUs (12GB Nvidia GPU TiTan X) with CUDA 8.0.
To show the effectiveness of FuzzGuard, we evaluate AFLGo equipped with FuzzGuard and the original one using 45 vulnerabilities in 10 real programs (as demonstrated in Table 1).
The ideal comparison for the AFLGo equipped with FuzzGuard and the vanilla AFLGo is to compare the time of fuzzing using AFLGo (T AFLGo ) and the corresponding time when equipping AFLGo with FuzzGuard (T +FG ).
However, we cannot directly use the same seed input to compare the fuzzing process of AFLGo and that of AFLGo+FuzzGuard.
This is because the mutation is random, and the generated sequence of inputs (even if from the same seed input) could be quite different in the two fuzzing processes, which further makes the time spent on execution quite different.
So our idea is to make the generated sequence of inputs be the same in the two different fuzzing processes.
Particularly, for a vulnerability of a target program, we use a vanilla AFLGo to perform fuzzing and record the sequence of all the mutated inputs I AFLGo in order (the number of the inputs N Inputs is shown in Table 1) until the target vulnerability is triggered (e.g., a crash) or timeout (200 hours in our evaluation).
In this process, the fuzzing time T AFLGo (as shown in Table 1) is also recorded.
Then we utilize the same sequence of inputs I AFLGo to test AFLGo equipped with FuzzGuard, recording the filtered inputs I f iltered (the number of the filtered inputs is N f iltered , and the ratio of filtered inputs to all the generated inputs f iltered = N f iltered /N Inputs are shown in Table 1).
We also record the time cost of FuzzGuard (T FG ) including the time of training and prediction.
In this way, we are able to know the time when FuzzGuard is equipped, and compare the time with T AFLGo .
T +FG can be calculated as follows:T +FG = T AFLGo − ∑ i∈I f iltered t i + T FGwhere I f iltered is the inputs filtered out by FuzzGuard and t i stands for the time spent on executing the target program with the input i.Note that, the last input in I AFLGo is the first PoC generated by AFLGo (if the target program crashes, e.g., #1 and #2 in Table 1) or the last input generated by AFLGo before timeout (no crash happens, e.g., #8 and #9 in Table 1).
We emphasize that FuzzGuard does not know whether a given input is the last one or not.
In the fuzzing process, FuzzGuard treats the last input in the same way as the previous inputs.
Comparing to FuzzGuard, a method randomly dropping inputs in I AFLGo will randomly decide to drop the last input or not.
From Table 1 we can see that FuzzGuard drops 65.1% inputs on average.
If the same number of inputs (65.1%) is dropped by the random method, the last input (a possible PoC, e.g., #1 and #2 in Table 1) could also be dropped with the possibility of 65.1%.
In contrast, the false negative rate of FuzzGuard is 0.02% (see Section 6.3), which means that even if 65.1% inputs are dropped by FuzzGuard, the possibility of dropping the PoC is only 0.02%.
Landscape.
The results are shown in Table 1.
Those 45 bugs in Table 1 include 27 CVEs found in the last 3 years and 18 newly undisclosed bugs (see Section 6.5).
In our evaluation, the undisclosed bugs (e.g., Line 6 in Table 1) were found when FuzzGuard performing target fuzzing on other vulnerabilities (e.g., CVE-2017-17501, Line 4 in Table 1).
Note that the buggy code of this undisclosed bug is actually not our target in this process.
Then, we set the newly found buggy code as the target and tried to utilize AFLGo to reproduce it.
Unfortunately, in the time limit (200 hours), AFLGo failed to trigger the bug.
Neither could AFLGo+FuzzGuard trigger the bug.
However, AFLGo+FuzzGuard did save the time from 200 hours to 23.4 hours (8.5 times speedup).
From the table, we find that for all the bugs, FuzzGuard can increase the runtime performance of AFLGo from 1.3× to 17.1× (see the "Speedup" column in Table 1, where Speedup = T AFLGo /T +FG ).
The average performance is increased by 5.4×.
Note that such performance boost is added to a DGF (i.e., AFLGo) which has already been optimized.
Understanding the performance boost.
To understand the performance of FuzzGuard for different programs and bugs, we further study the relationship among the speedup, the time that the model starts to train and the ratio of unreachable inputs, etc. • The earlier the model is trained, the more time could be saved.
Figure 3 shows the time that each model starts to be trained for the bugs in Table 1 (the red bar).
We can see that the model trained later (e.g., #20, #24, #27) achieved no more than 3.3× speedup, while the model trained earlier could achieve over 17× speedup.
This is mainly because the earlier the buggy node gains balanced labeled data, the earlier the model can be trained for filtering out unreachable inputs to the buggy code.
As a result, more inputs could be filtered out for saving the time on unnecessary executions.
• The more reachable inputs generated by the carrier fuzzer, the less effective FuzzGuard is.
For example, as shown in Table 1, when more than 40% of the inputs are reachable (the column "UR."
is the ratio of unreachable inputs), the speedup gained by FuzzGuard is less than 2 times (e.g., the bug #1, #12 and #45 in Table 1).
In a special case, if there are no if-statements or constraints in the path from the entry point to the target buggy code, all the generated inputs are reachable.
So there is no need to train a deep learning model.
Complicated Functions.
To evaluate FuzzGuard on handling complicated functions with multiple constraints and branches, we measure the number of unique functions and constraints 5 in the path to each bug in Table 1.
From the table, we can see that the average number of unique functions and constraints are 15.5 thousand and 315.9 million, respectively.
Over 50% of the bugs are guarded by thousands of constraints (e.g., the bugs in GraphicsMagick and ImageMagick).
For these bugs, FuzzGuard achieves the speedup from 1.4 to 15.9.
For some bugs guarded by millions constraints (e.g., #13 and #18 in Table 1), FuzzGuard achieves over 10× speedup.
The results show that FuzzGuard can handle complicated functions well, which could be quite time-consuming for traditional constraint solving.Cost.
In our evaluation of the 45 bugs in Table 1, the time spent on training the online model is 60 minutes on average, which includes 13.5% for data collection, 0.5% for data embedding and 86% for the training process.
Note that the time spent on training only takes 6% of the time for input generation by the fuzzer (15 hours on average).
The total time spent by FuzzGuard is 1.4 hours on average, which only takes 9.2% of the total time of the fuzzing (T +FG in Table 1) and 2.5% of the total time of the fuzzing process performed by AFLGo (T AFLGo in Table 1).
Such a time period is enough for a fuzzer to process 704 thousand inputs, which is far more efficient than directly executing the target program for testing.
To understand the upper limit of of the fuzzing time that FuzzGuard could save, we perform a 24-hour fuzzing on 45 vulnerabilities (shown in Table 1) using AFLGo.
From Fig- ure 4, we can see that the average execution time of the target program is over 88% of the total time of fuzzing, which means that the average upper limit of the fuzzing time that FuzzGuard could save is about 88%.
The time cost of FuzzGuard should be less than the limit.
We measure the accuracy of FuzzGuard.
The accuracy is based on whether the reachability is correctly judged.
The more accurate it behaves, the more unreachable inputs could be filtered out.
Note that no PoC will be missed since the filtered inputs will be saved in the PUI, which will further be checked by an updated model.
A more accurate model may find the reachable ones in the pool and let the target program execute with them, which in theory will not have false negatives.
However, in real execution, we usually set a timeout for fuzzing.
In this case, if a false negative input is left in the pool without being found before the timeout, it will be missed.
Fortunately, in our evaluation of the 45 bugs, no PoC is found in the PUI due to the accurate model.
We define false positive rate as follows: f pr = N f p /N n × 100%, where N n represents the number of the unreachable inputs generated by AFLGo, and N f p is the number of inputs that cannot reach the buggy code but be viewed as reachable ones by FuzzGuard.
The false negative rate is: f nr = N f n /N p × 100%, where N p represents the number of the reachable inputs, and N f n is the number of reachable inputs but be filtered out by FuzzGuard.
The higher the f pr, the more time is spent on executions with unreachable inputs.
The higher the f nr, the more likely the PoC is executed late in the fuzzing.
The accuracy is calculated by acc =N p +N n −N f p −N f n N p +N n .
Figure 5: The accuracy of FuzzGuard.From Figure 5, we can find that FuzzGuard is very accurate (ranging from 92.5% to 99.9%).
The average accuracy is 98.7%.
The false positive rate for all vulnerabilities is 1.9% on average.
Note that false positives do not let a PoC be missed.
Neither do they increase the time spent on executing the inputs (such inputs are always executed by the program if there is no FuzzGuard).
The false negative rate is negligible, which is 0.02% on average.
There are only 4 vulnerabilities that have false negatives, and the highest one is 0.3%.
We further check those false negatives manually and confirm that there is no PoC in those inputs.
Even if a PoC is included, as mentioned previously, FuzzGuard will save it to the PUI for further testing by updated models (no PoC will be missed).
Such an accurate model enables FuzzGuard to have high performance.The main reason for false positives and false negatives is due to lack of balanced representative data.
For example, an unreachable input could be predicted by FuzzGuard as reachable (i.e., a false positive) if it is similar enough to previous reachable inputs.
The execution path of the input can also be similar to the path to the buggy code (covering some predominating nodes of the buggy code).
But some bytes in the input stop the execution to the buggy code eventually.
A false negative may let the program reach the target buggy code through an execution path that is never seen before.
If those new execution paths could be learned by the model, the prediction will be more accurate.
In our evaluation, the number of unseen paths becomes less after long-time fuzzing, which is probably the reason for the low false positive rate.
To investigate the individual contribution of the stepforwarding approach and the representative data selection, we measure the performance boost with and without each technique for all the bugs in Table 1.
In particular, to be fair in the comparison, for each bug to test, we use the same sequence of inputs.
We first perform the evaluation without the stepforwarding approach, and record the performance increase (column FG 1 in Table 1).
Then we do not use representation data selection and record the corresponding performance increase (column FG 2 in Table 1).
The results indicate that FuzzGuard (with both the two techniques) can gain 5.4× speedup compared to the vanilla AFLGo implementation, while FuzzGuard without step-forwarding and FuzzGuard without representative data selection can gain only 2.6× and 4.4× speedup, respectively.We also made further analysis.
As we know, the stepforwarding approach is designed to help FuzzGuard to get balanced data earlier in the fuzzing process, further to let the training process start earlier.
So we want to measure how much step-forwarding can help.
We record the start time of the first training with and without the step-forwarding approach (see Figure 3).
The x-axis in the figure shows the bug index in Table 1, and the y-axis gives the start time in hours.
From the figure, we find that if step-forwarding is not used, FuzzGuard fails to start the training process for 14 bugs (e.g., #5 , #6 and #7) due to lack of balanced data.
For other bugs, even if the training process starts, the time of start will be postponed by 17.4 hours on average compared with the model using step-forwarding.
This also postpones the filtering process and finally impacts the overall performance.Regarding representative data selection, we also measure its impact on the accuracy of the model.
For each bug, we record the model's accuracy with and without using representative data selection.
The results are shown in Figure 5.
The x-axis shows the bug index and y-axis gives the accuracy of the model.
From the figure, on average, representative data selection increases the accuracy by 4.4%.
For some cases (#14, #21 and #40 in Figure 5), the accuracy of the model decreases dramatically without representative data selection.
Based on the individual evaluations above, we find that FuzzGuard needs both step-forwarding and the representative data selection for efficiency and accuracy.
Interestingly, in our evaluation, we find 23 undisclosed bugs (4 of them are zero-day vulnerabilities).
Note that the buggy code of the undisclosed bugs is actually not our target.
The goal of FuzzGuard is to increase the efficiency of fuzzing by removing unreachable inputs, instead of triggering new bugs.
All the bugs found by FuzzGuard+AFLGo could eventually be discovered by AFLGo.
The undisclosed bugs are patched in the new versions of the corresponding programs.
For the four zero-day vulnerabilities, we successfully gain the CVE numbers 6 .
The vulnerabilities are triggered when we perform target fuzzing on other vulnerabilities.
For example, CVE-2018-20189 is found in the fuzzing process of CVE- 2017-17501;and CVE-2019-7663 is found in the fuzzing process of CVE-2016-10266.
Also, we discover CVE-2019-7581 and CVE-2019-7582 when verifying CVE-2016-9831.
After manually analyzing the undisclosed bugs and zero-day vulnerabilities, we find that their locations are quite near the buggy code (i.e., the destination in targeted fuzzing).
For example, List 2 and List 3 show the call stacks of triggering CVE-2017-17501 andCVE-2018-20189 respectively.
The first 8 pre-dominating nodes are the same for both the two call stacks, while only the last basic blocks differ.
We guess the code near the buggy code could be more likely to contain a new bug 7 .
Our evaluation results show that FuzzGuard is highly effective to filter out unreachable inputs, with an average accuracy of 98.7%.
We want to understand from the features why FuzzGuard has such a good performance.
If the learned features by FuzzGuard are reasonable, the results of FuzzGuard are also understandable.
To achieve this goal, our idea is to extract the features from the model and analyze them manually.
However, as we know, the high-dimensional features extracted by the deep neural network are hard to be understood directly.
Inspired by saliency maps [8], our idea is to project the features to individual bytes (referred to as the key features), and to check whether the key features could impact the execution of the target program.In particular, to get the key features, we design a maskbased approach to obtain the corresponding key bytes of an input used by the model.
The basic idea is as follows: we use a mask (i.e., a vector with the same length as the input) to cover the bytes of the input x (the covered fields are set to 0).
If the covered input has the same prediction result as the uncovered one (i.e., f (mask · x) = f (x), where f is the CNN model used by FuzzGuard), the covered fields will not impact the prediction result, which means that they are not the key features.
By increasing the number of covered fields in the input step by step, we could acquire all the key features in the end.
The mask at this time is referred to as the maximum mask.
For example, an input is shown in Figure 6.
The mask sets the value of the shaded part of the input to 0.
When f (x) = f (m · x), the shaded part will not impact the reachability of the input x.
So we shade more bytes and iterate this process.
The problem here is that the covered fields have too many combinations.
So our idea is to leverage gradient descent to calculate the maximum mask.
In particular, we adjust the mask according to the deviation between the predicted label y p and the real label y of x until y p = y. To utilize this approach, we design a loss function that considers not only the deviation between the predicted and actual values, but also the coverage rate in the mask as follows:loss = ∑ n i=1 mask i n + ∑ m i=1 (y x i − y i ) 2 mwhere n is the number of bytes of mask and m is the length of y mentioned in Section 4.3.
When the gap between y p and y is minimal and the number of covered bytes is maximum, the uncovered bytes in x are the key features, which are the fields in the input affecting the reachability viewed by FuzzGuard.
In this way, the key features could be compared with the constraints in the target program to check whether the key features can really impact the execution.
For example, the PoC (a PNG file) of CVE-2018-20189 is shown in Figure 6.
The key features in this PoC are unshaded.
After manual analysis, we verify that the field from offset 0x0e to 0x0f (bits_per_pixel in List 1) in the input decides the execution direction of the branch in Line 6; and the fields from offset 0x0c to 0x0d (number_colors in List 1) in the input impact the execution.
For example, when bits_per_pixel < 16 or number_colors = 0, the buggy code will be executed.
The bug will be triggered when bits_per_pixel > 8.
Through the above analysis, we can confirm that the key features do affect the reachability of the input, which means that the model successfully captures the fields as features when the number of such inputs is enough for training.
Benefit to input mutation.
Most of the current fuzzers focus on mutating inputs for enhancing the performance of fuzzing (e.g., AFL [2], AFLFast [10] and AFLGo [9]).
Different from them, our idea is to help DGF filter out unreachable inputs.
Interestingly, we find our approach could also potentially help them to optimize the strategy of input mutation.
If a fuzzer knows the fields in inputs impacting the execution, it can mutate them for letting the program execution reach the buggy code.
Modification of other fields would not help in this process.
Based on the understanding of features extracted by FuzzGuard, we find that FuzzGuard could learn the fields impacting the execution (see Section 7).
Thus, FuzzGuard could further help the DGF in the process of input mutation.Learning models.
Intuitively, the convolutional architecture uses local patterns.
But CNN can actually handle non-local patterns as long as it has enough neural network layers.
RNN is similar: when it has enough layers, it can handle non-local patterns; otherwise, it will forget former features.
However, the overhead of RNN to handle long data is very large.
So we choose to use a 3-layer CNN.
In our evaluation, the results show that CNN achieved a good performance (1.9% false positive rate and 0.02% false negative rate on average), which may indicate that most key features in the inputs are local patterns (e.g., the field bits_per_pixel in Figure 6).
This is understandable: for a single constraint in an if-statement, it usually relies on the local bytes in inputs to make decisions.Memory usage.
In theory, we could keep the unreachable inputs in memory forever to avoid missing a PoC.
However, in real situation, the memory is limited.
So our idea is to remove those inputs that are highly impossible to reach the buggy code.
In other words, if an input is judged as "unreachable" by the updated models for dozens of times, it is highly possible that it cannot reach the buggy code.
In this way, we could save memory while at the same time keeping the accuracy.
Based on our evaluation, no PoC is dropped in this way.
Traditional Fuzzers.
A lot of state-of-the-arts are proposed in recent years.
AFL [2] is a representative CGF fuzzer among them, which gives other fuzzers a guidance.
For example, Böhme et al. [10] use the Markov model to construct the fuzzing process.
It chooses the seeds which exercise the low-frequency execution paths, and then mutates them to cover more code to find bugs.
FairFuzz [24] is similar to AFLFast [10], but it provides new mutation strategies (i.e., overwritten, deleted and inserted).
Gan et al. [16] fix the problem of path collision in AFL by correcting the path coverage calculation in AFL.
Another variant of AFL is AFLGo [9], it selects the seeds which have the execution path closer to the targets path, and mutates them to trigger the target bugs.
And Chen et al. [12] improve AFLGo by new strategies of seed selection and mutation.
Some researchers improve the effectiveness by traditional program analysis.
For example, Li et al. [25] use static analysis and instrumentation to acquire the magic number position during execution and apply them to the mutation to improve the execution depth of the test case.
Chen et al. [13] use dynamic techniques such as colorful taint analysis to find bugs.
Rawat et al. [30] use both static and dynamic analysis techniques to obtain control flow and data flow information to improve the effectiveness of the mutation.
Chen et al. [14] discover memory layouts to perform accurate fuzzing.
Different from their work, we leverage deep-learningbased approach to filter out unreachable inputs to increase the performance of fuzzing.Learning-based Fuzzers.
There are also some fuzzers using intelligent techniques.
For example, You et al. [35] extract vulnerable information from CVE descriptions and trigger the bugs in Linux kernel.
Wang et al. [33] learn the grammar and semantics features from a large number of program inputs through probabilistic context sensitive grammar (PCSG), and then generate program inputs from that PCSG.
Similarly, there are some previous studies [17,28,29] training static models to improve the mutation strategy of the fuzzer by generating inputs that are more likely to trigger bugs.
Godefroid et al. [17] apply RNN to learn the grammar of program inputs through a large number of test cases, and further leverage the learned grammar to generate new inputs consequently.
Rajpal et al. [29] utilize a LSTM model to predict suitable bytes in inputs and mutates these bytes to maximize edge-coverage based on previous fuzzing experience.
Nichols et al. [28] train a GAN model to predict the executed path of an input.
Chen et al. [15] apply gradient descent algorithm to solve the path constraint problem and find the key bytes in an input to the buggy code.
She et al. [31] also utilize gradient descent to smooth the neural network model and learn branches in the program to improve program coverage.
Different from these studies which mainly focus on mutating inputs to achieve high code coverage or to efficiently reach target buggy code, the goal of FuzzGuard is to help DGF filter out unreachable inputs, which is complementary and compatible with other fuzzers, instead of replacing them.
Recently, DGF is efficient to find the bugs with potentially known locations.
To increase the efficiency of fuzzing, most of the current studies focus on mutating inputs to increase the possibility to reach the target, but little has been done on filtering out unreachable inputs.
In this paper, we propose a deep-learning-based approach, named FuzzGuard, which predicts reachability of program inputs without executing the program.
We also present a suite of novel techniques to handle the challenge of lacking representative labeled data.
The results on 45 real bugs show that up to 17.1× speedup could be gained by FuzzGuard.
We further show the key features learned by FuzzGuard, which indeed impact the execution.
The authors would like to thank our shepherd Konrad Rieck and anonymous reviewers for their insightful comments.
