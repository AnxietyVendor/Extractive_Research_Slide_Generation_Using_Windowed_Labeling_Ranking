Fuzzing is one of the most effective approaches for identifying security vulnerabilities.
As a state-of-the-art coverage-based greybox fuzzer, AFL is a highly effective and widely used technique.
However, AFL allocates excessive energy (i.e., the number of test cases generated by the seed) to seeds that exercise the high-frequency paths and can not adaptively adjust the energy allocation, thus wasting a significant amount of energy.
Moreover, the current Markov model for model-ing coverage-based greybox fuzzing is not profound enough.
This paper presents a variant of the Adversarial Multi-Armed Bandit model for modeling AFL's power schedule process.
We first explain the challenges in AFL's scheduling algorithm by using the reward probability that generates a test case for discovering a new path.
Moreover, we illustrated the three states of the seeds set and developed a unique adaptive scheduling algorithm as well as a probability-based search strategy.
These approaches are implemented on top of AFL in an adaptive energy-saving greybox fuzzer called EcoFuzz.
EcoFuzz is examined against other six AFL-type tools on 14 real-world subjects over 490 CPU days.
According to the results, EcoFuzz could attain 214% of the path coverage of AFL with reducing 32% test cases generation of that of AFL.
Besides, EcoFuzz identified 12 vulnerabilities in GNU Binu-tils and other software.
We also extended EcoFuzz to test some IoT devices and found a new vulnerability in the SNMP component.
Fuzzing is an automated software testing method that is popular and effective for detecting vulnerabilities in software, which was first devised by Barton Miller in 1989 [23,32].
Since then, fuzzing has been developed rapidly [22].
As one of the most effective techniques, Coverage-based Greybox Fuzzing (CGF) has attracted several researchers' attention [6].
Combined with genetic algorithms, CGF obtains the path coverage generated by the instrumentation tools and uses it to select good seeds.
This technique helps the fuzzing to proceed in a direction that constantly improves the coverage, and more coverage being achieved leads to more bugs for triggering [9].
As Miller's report, a 1% increase in code coverage increases the percentage of bugs found by 0.92% [24].
One of the most popular and widely-adopted CGF is American Fuzzy Lop (AFL) [40].
AFL is an efficient method for file application fuzzing and has identified numerous high-impact vulnerabilities [39].
However, when AFL was used to fuzz real-world programs, it displayed certain shortcomings.
The main challenge is that the majority of the test cases exercise the same few paths, thus causing a significant amount of energy wasted on the high-frequency paths [6].
Especially in the later stages of fuzzing, the seeds that exercise high-frequency paths can no longer help in improving the discovery of new paths.
However, AFL's constant power schedule is unable to allocate energy to the seeds reasonably.
Typically, AFL assigns too much energy to the seeds exercising high-frequency paths.
Such problems reflect the insufficient performance of AFL's schedule algorithm.
More importantly, the schedule algorithm of AFL is not built on a scientific theoretical model.
Some methods and techniques have been proposed to increase the performance of scheduling algorithms.
AFLFast modeled the transition probability of mutating a seed for generating a test case exercising another path with the transition probability in a Markov chain [6].
Then, AFLFast implemented a monotonous power schedule to assign energy [6].
This can rapidly approach the minimum energy required for discovering a new path.
However, AFLFast cannot flexibly adjust the allocation strategy according to the fuzz process, thereby increasing the average energy cost of discovering a new path.
Besides, though AFLFast proposed the transition probability in fuzzing and determined the method for assigning energy as per the transition probability [6], it was unable to provide a detailed analysis of the transition probability.
It is not possible to calculate the transition probability from a discovered path to an undiscovered path.
In fact, in this con-text, selecting the next seed and assigning energy to the seed is the classic "exploration vs. exploitation" trade-off problem from game theory, not a simple probability problem.This paper proposes a variant of the Adversarial MultiArmed Bandit (VAMAB) model to model CGF.
We modeled each seed as a "bandit" of VAMAB, which is a classical concept from MAB, and explained the trade-off between exploration and exploitation in CGF as per the VAMAB model.
Moreover, the Markov chain was used for understanding the details from a probabilistic perspective.
As opposed to AFLFast [6], our model's perspective for regarding the process of power schedules is derived from game theory, which helps in better understanding the challenges in schedule algorithm compared to the Markov chain.
Further, an adaptive average-cost-based power schedule algorithm as well as a self-transition-based probability estimation method were developed according to the VAMAB model and were implemented on AFL in a tool named EcoFuzz, which is an adaptive energy-saving greybox fuzzer.
Compared to AFL's constant schedule and AFLFast's monotonous schedule, EcoFuzz implements an adaptive schedule that can effectively reduce energy wastage, which maximizes the path coverage in the finite times of executions.
EcoFuzz is particularly well-suited in situations that have limited performance, such as fuzzing the IoT devices and fuzzing the binary programs via QEMU.
In this paper, EcoFuzz was evaluated with six state-of-the-art AFL-type fuzzers such as AFLFast, FairFuzz and MOPT on 14 real-world software [6,17,21].
We also compared EcoFuzz with other four tools like Angora on LAVA-M [10,12].
The following are the contributions made in this paper.
• An Variant of the Adversarial Multi-Armed Bandit (VAMAB).
We proposed a VAMAB model to model the CGF, as well as proposed the reward probability which is the probability of the seed to discover new paths.
We presented the variations of reward probability in detail and introduced the attenuation of this probability.
Further, we explained AFL's challenges, classified CGF into three states, and put forth strategies that could enhance AFL's performance in each state.
• Self-transition-based Probability Estimation Method (SPEM).
We designed a method to estimate the reward probability for selecting seeds in the exploitation state.
This method is more accurate than AFL's search strategy for selecting the next seed with a high reward probability.
• Adaptive Average-Cost-based Power Schedule (AAPS).
We recommended an adaptive power schedule that assigns energy to each seed by utilizing the average-cost as the baseline, and then monotonously increases the energy.
Compared to AFLFast, AAPS can adjust the next energy allocation by assessing previous allocations.
• Tool.
We implement our approaches on AFL, an adaptive energy-saving fuzzer named EcoFuzz.
EcoFuzz was then assessed as per 14 real-world software and LAVA-M compared to certain state-of-the-art tools.
Results showed that EcoFuzz could find more paths compared to other AFL-type fuzzers with the same number of executions.
Moreover, EcoFuzz detected more bugs than others on LAVA-M, and found 12 vulnerabilities in some software, obtaining 2 CVEs.
EcoFuzz was also adopted for testing the SNMP component and found a vulnerability.
We have published EcoFuzz on Github (https: //github.com/MoonLight-SteinsGate/EcoFuzz).
As a state-of-the-art CGF, AFL is favored by numerous researchers [6,13,17,43].
AFL uses lightweight instrumentation to capture basic block transitions and determine a unique identifier for the path exercised by a test case, and employs genetic algorithms to discover test cases that are likely to trigger new paths [42].
Its efficiency is affected by some factors.
Search strategy for seeds.
AFL keeps a seed queue, dequeues seeds one by one, and fuzzes them.
AFL marks some seeds as favored seeds and gives these seeds preference over the non-favored ones [26].
In detail, AFL determines a seed as a favored seed according to the fav factor calculated by the seed's execution time and length.Mutation strategies and power schedules.
AFL has two categories of mutation strategies, which are deterministic and indeterministic [42].
The deterministic strategies operate at every bit/byte of each input.
And they are only used when it is the first time for fuzzing the seed.
In deterministic strategies, AFL assigns energy to the seed according to its length.After implementing deterministic strategies, AFL effectuates the indeterministic strategies, including havoc and splice.
In this stage, AFL mutates the seed by randomly selecting a sequence of mutation operators and applies them to random locations in the seed file.
AFL assigns energy to the seed according to its score, which is based on coverage (prioritize inputs that cover more of the program), execution time (prioritize inputs that execute faster), and discovery time (prioritize inputs discovered later) [15].
Particularly, if the test case exercises a new path, AFL will double the assigned energy.Numerous researchers prefer AFL as its high speed of mutation and execution.
AFL also supports source code instrumentation as well as binary instrumentation via QEMU [4], thus making AFL easy to start.
However, its performance can be further enhanced.
AFL is unable to adjust its energy allocation adaptively and constantly assigns more than the minimum energy required to discover a new path on some seeds, resulting in significant energy wastage [6].
Additionally, AFL has a simple search strategy that is inefficient, leading to AFL taking more turns to select valuable seeds.
Finally, the deterministic strategies are also not as effective as random strategies [41].
Böhme et al.[6] modeled CGF as a systematic exploration of the state space of a Markov chain.
More importantly, they proposed the transition probability in CGF and modeled it as that in the Markov chain [25].
A Markov chain is a stochastic process that transitions from one state to another.
Formally, a Markov chain refers to a sequence of random variables {X 0 , X 1 , ..., X n } where X i denotes the state of the process at time i.
The value of X i is taken from a set of states S = {1, 2, ..., N} for some N ∈ N. Further, the transition probability p i j indicates the chain's state transition probability from state i at time t to state j at time t + 1, which is signified as the conditional probability,p i j = P(X t+1 = j|X t = i)(1)Particularly, if the transition probability p i j depends only on the state i and j, and not on the time t, the Markov chain is called time-homogeneous.
To model CGF as a timehomogeneous Markov chain, Böhme et al. defined the Markov chain's state space as the discovered paths and their immediate neighbors [6].
That is, given a set of seeds T , S + indicates the set of discovered paths that are exercised by T while S − is the set of undiscovered paths [6] that are exercised by inputs generated by randomly mutating any seed from T .
The set of states S is defined asS = S + ∪ S − (2)The transition probability is defined as follows.
For path i ∈ S + , p i j is the probability of generating a test case exercising the path j through the mutation of the seeds t i ∈ T that exercises the path i.
According to this model, Böhme et al. [6] proposed that a more efficient CGF can discover an undiscovered state in a low-density region while assigning the least amount of total energy.
That is, defining E[X i j ] is the expectation of the minimum energy that should be assigned to seed t i ∈ T for discovering the new state j, CGF must choose t i for fuzzing such that ∃ j ∈ S − where the probability of executing path j is low and E[X i j ] is minimal.
Moreover, the energy assigned to t i should be E[X i j ], which is deduced as 1/p i j in [6].
Unfortunately, when fuzzing real-world programs, it is impossible to calculate the transition probability of discovering a new path from the current seed precisely, and thus, a completely accurate approach cannot be determined for selecting the next seed and assigning energy to it.
However, there is a seed t i ∈ T that has the highest probability of finding a new path.
AFLFast [6] recommended selecting the next favored seed that is chosen from the queue with the smallest number of times and that exercises a path with the least amount of fuzz.
However, the efficiency of this search strategy depends on the information about all seeds.
If there is a queue of seeds Q where some seeds from Q have been fuzzed while others are not, there may be more accurate recognition for seeds that have been fuzzed than those that have not.
For choosing the next seed t i where the probability of executing path i is the minimum, it is necessary to conduct an examination for fuzzing seeds that have not been fuzzed, which is a classic "exploration vs. exploitation" trade-off problem.
The Multi-Armed Bandit problem is important as one of the simplest non-trivial problems wherein the conflict between exploitation and exploration [7,35].
This problem resulted from the slot machine with multiple arms.
In this case, the player plays one of the arms and obtains a reward.
The player's main goal is maximizing the rewards in finite trials [35].
Formally, as shown in Fig. 1, there are N parallel arms, indexed i ∈ K = {1, 2, ..., N}, and each time only a single arm is allowed to be selected to play.
The state of arm i at time t is denoted as x i (t), while the expectation of reward of the arm i at time t is R i (x i (t)) [35].
However, there is no indication about the reward expectations related to each arm.
Thus, the problem is how to allocate the trials over arms sequentially in time to maximize the expected total reward.
It should be noted that an increasing number of trails being allocated to an arm i will lead to more accurate information being deduced regarding the reward expectation of i, which is the process of exploration.
If all the reward expectations of all arms are known, then we only select those arms with the highest expectation to gain the highest reward, which is the process of exploitation.
Therefore, our goal is achieved by having a trade-off between exploration (trying out some arms) and exploitation (choosing an arm with the highest reward).
Exploitation helps maximize the expected rewards for a single step, whereas the combination of exploration and exploitation helps achieve higher rewards in the long run [26].
In the classic MAB problem, there are two assumptions that the distribution of rewards for each arm is time-invariant, and the number of arms is constant.
Thus, solutions concerning the MAB problem have almost relied on these assumptions [2].
However, these assumptions limit the MAB model's applicability.
For modeling CGF as the MAB-type model, it is natural to regard an arm as a seed.
However, during fuzzing, the number of seeds (i.e., arms) is increasing and the probability of finding a new path (i.e., reward probability) is decreasing, which are not constant.
Particularly, Auer et al. proposed the MAB problem variant that includes no-statistical assumptions about generating rewards as the Adversarial Multi-Armed Bandit (AMAB) problem [3].
We consider modeling CGF by the variant of the AMAB model, not the MAB model.
In this section, we model the process of searching seeds and assigning energy as a variant of the AMAB problem, thus enabling exposing the essence of the CGF.
Moreover, we explain the exploration and exploitation during fuzzing according to this model, and point out certain challenges in enhancing AFL.
In this subsection, we define some assumptions and terms, then build our VAMAB model.
Assuming that we are fuzzing program A, several assumptions are stated below.Assumption 3.1 The number of total paths and unique crashes that can be executed of program A are finite, denoted as n p and n c , respectively.This assumption helps to consider the mathematical model in the finite state space, which could simplify the problem.
The program A is stateless.
That is, the path of each execution depends only on the input generated by fuzzer.This assumption ensures that the reward probability is independent in VAMAB model, only determined by the seed.The following are some important definitions.Definition 3.1 The set of total paths of program A is signified as S = {1, 2, ..., n p } and the corresponding seeds set is denoted as T = {t 1 ,t 2 , ...,t n p }.
Definition 3.2 We followed the definitions of transition probability p i j and the minimum energy E[X i j ] in [6].
p i j is the probability of generating a test case exercising path j from the seed t i .
E[X i j ] is the expectation of minimum energy (i.e., the number of test cases generated by t i ) of this process, deduced as 1/p i j in [6].
Definition 3.3 Based on Definition 3.2, we define the transition frequency f i j as the frequency of path transition from path i to path j, asf i j = f i ( j) s(i)(3)f i ( j) indicates the number of test cases exercising path j generated by seed t i .
Particularly, f ii is defined as the selftransition frequency.
s(i) is the number of trials conducted to seed t i , satisfyings(i) = n p ∑ j=1 f i ( j)(4)Definition 3.4 We define the probability of mutating t i for generating inputs executing other paths as p i * , deduced asp i * = 1 − p ii = n p ∑ j=1 p i j − p ii = n p ∑ j=1, j =i p i j(5)Providing the queue with n seeds is T n , |T n | = n, 1 ≤ n < n p , some of the seeds in T n that have been fuzzed are denoted as T + n and the others are marked as T − n .
Additionally, the number of trials being conducted thus far is m.When fuzzing the program A, the aim might be maximizing the number of discovered crashes and paths of A as well as assuming them as the arms in the MAB model.
However, Woo et al. [36] pointed out that focusing on one seed may trigger the same crashes, thus impacting the selection in exploitation.
Thus, our model regards the seeds as the arms and aims to maximize path coverage in finite trials.
Therefore, we define the reward of each trial as generating an input that triggers new path.
Each trial to play an arm i denotes mutating a corresponding seed t i and executing the generated test case.
Now we have conducted the trials for m times.
∀t i ∈ T n , we denote earn a reward in next trial as,R i (m + 1, T n ) = 1 (6)The probability of the arm i to earn a reward (i.e., discovering a new path) in this trial is deduced asP(R i (m + 1, T n ) = 1) = n p ∑ j=n+1 p i j = 1 − n ∑ j=1 p i j(7)We define this probability as the reward probability.
According to Equation (7), we can deduce that: (1) the reward probability P(R i (m + 1, T n ) = 1) depends only on the seed t i and the seeds set T n of discovered paths, and is not related to the number of trials being conducted (i.e., m).
Thus, the reward probability is simplified as P R i,n ; (2) with a rise in the number of discovered seeds n, there is a decrease in the number of undiscovered paths (n p − n) which leads to a reduction in the probability of arm i to find new paths.
These are following the general results in most evaluation that as more paths are found, the discovery of new paths decelerates monotonically [6].
Therefore, it is evident that the distribution of the reward of each arm is not invariant.
Actually, the probability decreases once a reward is gained in some trials.
This is called probability attenuation.
As a result, the process of fuzzing is not modeled as the classic MAB model, which is closer to the AMAB model.
Moreover, according to the mechanism of CGF, once a reward is earned, it leads to a new and interesting path.
New seed will also be added into the queue of seeds, with the seeds set T n transferring into T n+1 and the number of arms increasing to n + 1, as shown in Fig. 2.
Based on these differences, this problem is defined as a VAMAB.As opposed to the traditional MAB model, the number of arms of the VAMAB model will increase, and the reward probability will decrease if rewards are earned until all paths of program A are found.
Therefore, before discovering all paths, there is always a trade-off between exploration (fuzzing seeds that have been not fuzzed) and exploitation (selecting the fuzzed seeds to get more rewards).
Seed-1 Seed-3 Seed-2 Seed-N …… Seed-1 Seed-3 Seed-2 Seed-N …… R1 R2 R1 R2 R3?
??
Providing we could calculate the reward probability of seeds after conducting some trials on them, for the seeds set T n , we can determine the reward probability P R i,n of the seed t i from T + n , which is the set of fuzzed seeds.
Then we can calculate the minimum energy the seed requires to find new paths following Definition 3.2.
For gaining more rewards in a short period, it may be better to select the seeds from T + n with the highest reward probability, as "exploitation".
In contrast, focusing on the unfuzzed seeds in T − n and allocating them enough energy can help to calculate their reward probability.
Seeds with higher reward probability may be found from T − n compared to those from T + n , as "exploration".
Thus, based on the level of testing on the seeds, as shown in Fig. 3, the states of T n were classified into three categories:(1) Initial State.
The initial state refers to the first stage of the fuzzing process, where all seeds are unfuzzed.
After beginning the fuzzing of the seeds, the initial state transitions to the exploration or exploitation state, as indicated by Curve 1 and Curve 2 in Fig. 3.
(2) Exploration State.
In this state, some seeds in T n are fuzzed, while some are not.
Therefore, energy should be assigned to the seeds that have not been fuzzed to earn rewards and estimate their reward probability.
After For these three states, it is necessary to implement different strategies to maximize rewards.
As previously discussed, it is risky to focus only on exploitation and skip exploration.
Therefore, we considered the strategy of testing each seed in the initial and exploration stage and selecting the high-quality seeds with high reward probabilities in the exploitation stage.
Although we have proposed how to improve the efficiency of the scheduling algorithm, some challenges persisted.The first challenge is how to determine the reward probability of each seed to select the next seed in the exploitation stage.
Given t i ∈ T n , its reward probability P R i,n is certain.
According to Equation (7), the reward probability depends on transition probability.
In [6], Böhme et al. calculated the transition probability between seeds in an example.
However, determining the transition probability p i j relies on the path constraints of path i and j, which can only be inferred through manual analysis with source code, not accessed by CGF.
Therefore, we could not accurately calculate the reward probability of seeds despite conducting several trials on the seeds.
We can only estimate it.
A common method is to estimate the transition probability through transition frequency.
That is, for p i j , it is possible to approximate it as f i j for 1 ≤ i, j ≤ n. However, based on Equation (3), (4) and (7), we may estimate the reward probability P R i,n asP R i,n ≈ 1 − n ∑ j=1 f i j = 1 − n ∑ j=1 f i ( j) s(i) = 0 (8)This is useless for CGF to select seeds.
Consequently, it is important to find other criteria or parameters for approximating the reward probability to select the seeds to fuzz.
The second challenge pertains to how to assign suitable energy to each arm to balance the trade-off between exploration and exploitation.
Especially in the exploration stage, assigning too much energy to an unfuzzed seed in T − n is very risky.
Researchers proposed some algorithms for resolving the problem of trade-off in the Adversarial MAB problem (e.g., Exp3) [3].
However, this algorithm is based on the assumption that the number of arms is constant.
Our model differs from the traditional AMAB problem on the variability of the number of arms.
Therefore, some current algorithms are not suitable for our model.
Therefore, to maximize the path coverage, we need to establish efficient mechanisms, which use existing information to estimate the reward probability of each seed for searching seeds in the exploitation stage and allocate appropriate energy to seeds for reducing energy waste.
In this section, we implemented a prototype tool called EcoFuzz.
We introduce the framework and algorithm of EcoFuzz firstly.
After that, we detail the search strategy and energy schedule algorithm implemented in EcoFuzz.
EcoFuzz is based on AFL 2.52b, which follows the framework and most of the mechanisms of AFL, including the feedbackdriven coverage and crash-filter mechanisms.
Based on these, we developed a scheduling algorithm called AAPS and a search strategy called SPEM.
The state determination mechanism was added.
EcoFuzz is based on the VAMAB model to determine which state the seeds queue stays at.
Moreover, EcoFuzz runs without the deterministic strategies, while our algorithm eliminated the mechanism in AFL that doubling energy when a new path is found.
Fig. 4 presents an overview of EcoFuzz.
Further details are given in Algorithm 1.
The three states of EcoFuzz are introduced below:Initial State.
EcoFuzz only stays at this state before fuzzing.
In this state, EcoFuzz chooses the first seed to fuzz.
Then, EcoFuzz turns to the exploration or exploitation state.Exploration State.
In this state, EcoFuzz selects the next seed based on the index order of the seeds which are not fuzzed, without skipping the seeds that are not preferred, and assigns energy by AAPS.
If all seeds in the queue have been fuzzed, EcoFuzz transfers into the exploitation state.Exploitation State.
In this state, as all seeds have been fuzzed, EcoFuzz implements SPEM for estimating the reward probability of all seeds and prioritizes the seeds with high reward probability for testing.
Each seed is selected at most once until all seeds have been selected or a new path is found.
If all seeds have been selected in this state, EcoFuzz will reselect the seeds until finding paths.
After a new path is found, EcoFuzz transfers from exploitation to exploration.
Require: Initial Seeds Set S total_ f uzz = 0 Additionally, according to [11], we add a static analysis module for extracting some magic bytes to a dictionary for certain programs.
In detail, the static analysis module extracts some hardcode and magic bytes in the target binary by searching from its disassembly information, which is efficient and uncomplicated.rate = 1 Q = S repeat queued_path = |Q| average_cost = CalculateCost(total_ f uzz, queued_path) state = StateDetermine(Q) if state == Exploitation then s = ChooseNextBySPEM(Q) else s = ChooseNext(Q) end if Energy = In Section 3, we introduced the reward probability of each seed and proved that it is not possible to determine the reward probability accurately.
Fortunately, our model aims to select the seeds with high reward probability in the exploitation state.
Therefore, there is a greater focus on the magnitude relationship but not on the specific value of the reward probability.
From Equation (5) (7), we can deduce thatP R i,n = p i * − n ∑ j=1, j =i p i j(9)For i ∈ {1, 2, ..., n}, the probability p i * is constant and n ∑ j=1, j =i p i j depends only on the set T n .
Based on the discussion in Section 3.3, we considered using (1 − f ii ) as an approximate estimation of p i * .
However, for n ∑ j=1, j =i p i j , as it is the reason for probability attenuation, the earlier the seed is discovered, the more its reward probability attenuates.
Hence, the index of the seed was used to illustrate the probability attenuation qualitatively.
Following is the estimation method:P R i,n ≈ 1 − f ii √ i (10)According to Equation (10), our method prefers to select the seeds with lower self-transition frequency and larger index.
However, the estimation method is only used to qualitatively estimate the magnitude relationship of the reward probability between the seeds.
Thus, we could not calculate the minimum energy of the selected seed.
For this, an adaptive average-costbased power scheduling algorithm was proposed.
As the lowest energy to find a new path can not be calculated, a scheduling algorithm was developed to approximate it monotonically.
Compared to AFL, which allocated redundant and constant energy each time, our algorithm aims to be economical and flexible, particularly in the exploration stage.
Considering a typical fuzzing process, as shown in Fig. 5, Curve s represents the relationship p(e) between the number of paths p and the number of total executions e when the CGF is fuzzing a target.
Further, Fig. 5 shows that the derivative of p(e) decreases with an increase in the number of executions e, meaning that the CGF found new paths more efficiently in an early stage than a later stage.
Particularly, the point (0, p 0 ) denotes the initial state of fuzzing and the point (e 1 , p 1 ) shows that the CGF found (p 1 − p 0 ) unique paths with the e 1 executions.
The average-cost of finding a path is defined asC(p 1 , e 1 , p 0 ) = e 1 p 1 − p 0(11)This represents the average number of executions required for discovering a new path when the CGF has executed e 1 test cases, which is the reciprocal of the slope of Line L 3 in Fig.
5.
Notice that, the average-cost decreases with an increase in the executions.
Therefore, the next point (e 2 , p 1 + 1) is likely to appear in Area S 4 in Fig. 5.
However, if the CGF generates test cases less than C(p 1 , e 1 , p 0 ) to find a new path, the next point will appear in Area S 1 ∪ S 2 ∪ S 3 , above Line L 3 .
It was expected that CGF could find as many new paths within the average-cost of energy as possible.
Thus, we considered using the average-cost C as the basic line for allocating energy, which is economical for the CGF, to design the AAPS algorithm, as shown in Algorithm 2.
For the seed s, we allocate energy no more than averagecost to s in the exploration stage.
In addition, less energy allocation was considered for the seeds exercising high-frequency paths than those exercising low-frequency path, which is realized by the function CalculateCoefficient().
In detail, we calculate the ratio r of the total number of test cases exercising the same path with s (i.e., s.exec_num) and average_cost.
For the ratio r in (0, 0.5], (0.5, 1] and (1, +∞), we set the coefficient k as the empirical values: 1, 0.5 and 0.25, respectively, allocated energy k ×C corresponding to the reciprocal of the slope of Line L 3 , L 2 and L 1 in Fig. 5.
Require Furthermore, the regret concept in certain solutions of the classic MAB problem were combined for establishing a context-adaptive energy allocation mechanism [1].
This mechanism aims to improve the coefficient of energy utilization.
If more energy is allocated than the seed need to find a path, this mechanism reduces energy assigned the next time.: s, state, rate, average_cost Energy = 0 if state == Exploration then k = CalculateCoefficient(s.exec_num, average_cost) Energy = average_cost × k × rate else if state == Exploitation then ifMoreover, the regret is calculated according to the energy assigned to the seed and the energy it uses if it finds new paths.
Based on a previous assessment of energy allocations, the coefficient rate was updated to adjust the next allocation.
Particularly, to avoid wasting too much energy on a seed in the exploitation stage, we set M as the upper bound for one turn of energy allocation and assign the empirical value 16 × average_cost to M. Real-World Programs.
We evaluated EcoFuzz as per 14 realworld utility programs.
These programs were selected from those evaluated by other AFL-type tools [17,21].
All the evaluation was conducted without dictionaries.
The configuration of all programs is listed in Table 1.
For each case, we ran the fuzzing with one seed provided by AFL.
[6,17,21,41].
We executed the AFLFast and AFLFast.new with the fast model, which is the fastest schedule strategy of AFLFast [6], and ran MOPT-AFL with the parameter "-L 30" to launch the MOPT scheme.Platform.
We fuzzed each case for 24 hours (on a single core) and repeated each experiment 5 times to reduce the effects of randomness according to [16].
The experiments were conducted on a 64-bit machine with 40 cores (2.8 GHz Intel R Xeon R E5-2680 v2), 64GB of RAM, and Ubuntu 16.04 as server OS.
The experiments ran for 490 CPU days.
Energy-Saving Evaluation Metrics.
We choose the total number of paths discovered by different techniques, the total number of test cases generated, and the average-cost as the measurements.
The reason is derived from the model design.
The VAMAB model aims to maximize the number of paths in the least number of test cases generated.
According to the definition of average-cost, our scheduling algorithm uses the averagecost as the basic line for allocating energy and measuring the efficiency of each allocation.
Thus, EcoFuzz intended to achieve the same number of paths with other tools in the least number of fuzz, namely, the least average-cost.
Path Coverage.
For each subject and technique, Fig. 6 plots the average number of paths discovered throughout five runs at each average number of executions point in 24 hours.
Fig. 6 shows that EcoFuzz outperforms other six AFL-type fuzzers on most programs while achieving the upper bound on the number of paths on nm, objdump, size , gif2png, readpng, tcpdump, jhead, magick and bsdtar in the least executions.
The path coverage achieved by EcoFuzz on the other five programs is approximately the same as that of FidgetyAFL or AFLFast.new, and is more than that of FairFuzz and MOPT-AFL.
Particularly, except readelf and djpeg, EcoFuzz finds the most paths with the same executions than other tools.
More analysis is detailed in Appendix 8.1.Average-Cost.
As FidgetyAFL, AFLFast.new, and FairFuzz outperform the other three tools in path exploration, we focused on comparing their efficiency with that of EcoFuzz.
Table 2 presents the number of total paths, total executions, and the average-cost of these techniques on each subject.From Table 2, EcoFuzz generates fewer test cases than the other three state-of-the-art tools on eight subjects, and finds more paths than others on nine programs.
Moreover, EcoFuzz's average-cost is observed to be significantly lower than that of others on most programs.
On size, djpeg and gif2png, though FairFuzz has the lowest average-cost, the number of paths it found is also the least.
In contrast, EcoFuzz finds more paths than others on size and gif2png, with a lower average-cost than that of AFLFast.new and FidgetyAFL.
Particularly, on jhead, EcoFuzz attained more paths upper bound than other techniques in the early stage with fewer executions.
Therefore, EcoFuzz outperforms other tools in energy-saving.
More analysis is detailed in Appendix 8.1.
Statistical Analysis.
Following the guidance of [16], we conducted statistical analyses to ensure that the evaluation is comprehensive.
We used p value and extremum to evaluate the performance of these tools.
For p value, p 1 represents the difference between the performances of EcoFuzz and AFL.
Further, p 2 , p 3 , p 4 , p 5 , and p 6 denote the differences between the performances of EcoFuzz and FidgetyAFL, AFLFast, AFLFast.new, FairFuzz, and MOPT-AFL, respectively.
The number of paths and average-cost were considered for calculating the p value.
All the results and more analysis are shown in Table 6 This subsection focuses on the efficiency of SPEM and AAPS algorithm.
Evaluation Metrics.
We define the utilization ratio of energy, which is the ratio of the energy consumed for finding the newest path to the total energy allocated in each turn, to evaluate the scheduling algorithms of different techniques.
We recorded the turns of allocation and energy consumed in indeterministic strategies.
Because all fuzzers except EcoFuzz implement the splice strategy, and as the mechanism of splice strategy is very similar to that of havoc strategy, each allocation in splice strategy was regarded as a time of energy allocation.
Particularly, if the fuzzer did not find new paths in one turn of energy allocation, the ratio was recorded as 0.
Thus, the value of ratio ranges from 0 to 1.
Based on the utilization ratio, certain indicators for multifaceted assessments, including the average utilization ratio and the effective allocation, were defined.
The index of allocation times was denoted as i, ranging from 1 to N, while the corresponding utilization ratio was denoted as r i .
In addition, the number of paths found in this energy allocation is n i , and the first indicator is average utilization ratio, calculated as¯ r = i=N ∑ i=1 r i N(12)The frequency p of allocation finding new paths (we call this effective allocation) is the second measurement, denoted asp = |{i|n i > 0, 1 ≤ i ≤ N}| N(13)We choose each best run of EcoFuzz, FidgetyAFL, FairFuzz, and AFLFast.new on fuzzing nm to start our evaluation.Evaluation of AAPS Algorithm.
Fig. 7 plots the utilization ratio in each turn of the energy distribution of these four tools during fuzzing nm.
The utilization ratio of a point being closer to 1.0 indicates less energy being wasted.
Further, the degree of density of points represents the path coverage.As shown in Fig. 7, EcoFuzz utilizes energy more efficiently than the other three tools, as its distribution of points is closer to 1.0 than others.
EcoFuzz also found the most paths among all tools, which was significantly more than that found by FairFuzz and FidgetyAFL, with the densest distribution of points.
Further, for the distributions of FidgetyAFL and AFLFast.new, the majority of the points are located in the interval with the ratio being between 0 and 0.5, and only a few points' ratios are higher than 0.5.
In contrast, EcoFuzz's distribution of points is much closer to 1.0 than those of other techniques, with approximately half the points concentrated in an area with the ratio above 0.5, thus proving that the AAPS algorithm assigns energy more efficiently.Why the utilization ratio of most points in FidgetyAFL and AFLFast.new is under 0.5?
As stated in Section 2.1, if AFL finds a new path in random strategies, AFL will double the energy assigned to this seed.
FidgetyAFL and AFLFast both follow this mechanism.
However, Fig. 7 shows that this mechanism can create unnecessary energy depletion as, often during allocation, fuzzers do not find new paths after doubling energy.
Thus, the remaining energy is wasted.
On the other hand, our AAPS algorithm eliminates this mechanism that doubles the assigned energy and introduces an adaptive mechanism.
If more energy has been assigned compared to the seeds that need to find new paths for some time, the AAPS algorithm helps reduce the next energy allocation to decrease energy depletion.
Therefore, the distribution of points in EcoFuzz is more even compared to that in other tools.
In detail, we calculated some indicators to evaluate the AAPS algorithm.
Table 3 shows that the efficiency of different scheduling algorithms on nm.
EcoFuzz demonstrates the best performance with the least average-cost, highest average utilization, and highest frequency of effective allocation.
EcoFuzz's effective allocation frequency is more than FidgetyAFL, while its average-cost is half of FidgetyAFL.We also evaluated the adaptive mechanism in AAPS.
The adaptive mechanism was implemented on FidgetyAFL.
This new FidgetyAFL + Adaptive fuzzer was run on nm and tcpdump for 24 hours for 5 times.
Fig. 8 shows the results.
FidgetyAFL + Adaptive found more paths than FidgetyAFL on nm and tcpdump.
It can be concluded the adaptive mechanism can improve the efficiency of AFL's power schedule.Evaluation of SPEM Algorithm.
As shown in Fig. 7, in the later stage of fuzzing where EcoFuzz transitions into the exploitation stage frequently, EcoFuzz's point distribution is denser than that of the other three tools.
This qualitatively illustrates that the SPEM algorithm is effective.More quantitatively, we calculate the frequency of effective allocation for the seeds chosen repeatedly in the exploitation stage to estimate the efficiency of the search strategies.
The results are shown in Table 4.
EcoFuzz's measured 0.069, which is more than FidgetyAFL at 0.031 and AFLFast.new at 0.026, thus proving that the SPEM algorithm is efficient.
As most tested software are the latest version, it is difficult for these tools to find crashes in them using the seeds provided by AFL.
However, EcoFuzz still found 5 vulnerabilities.
For further evaluating EcoFuzz's efficiency in detecting vulnerabilities, we attempted to select the seeds for the latest version of the software by considering crashes in its previous version.
Unique Crashes.
We tested GNU Binutils-2.31 programs with EcoFuzz and found few crashes in nm and size of GNU Binutils-2.31.
Some crashes were selected as the initial seeds for testing the nm and size from GNU Binutils-2.32.
As AFLFast.new outperforms the other five tools, we compared EcoFuzz with it.
After 24 hours of testing, EcoFuzz found 53 and 63 unique crashes in nm and size, respectively, while AFLFast.new found 17 and 76 unique crashes.Analysis of Vulnerabilities.
EcoFuzz found more unique crashes than AFLFast.new in nm and fewer crashes than AFLFast.new in size.
We used AddressSanitizer for further vulnerability analysis [31].
After analysis, EcoFuzz and AFLFast.new both detect the vulnerability in nm when calling the d_expression_1 function in cp-demangle.c, which has been confirmed as the CVE-2019-9070 by others.
Moreover, two 0-day heap buffer overflow vulnerabilities exist in size that are only found by EcoFuzz.
One is trigged when calling the bfd_hash_hash function and the other is triggered when calling the _bfd_doprnt function.
Although AFLFast.new found more crashes in size than EcoFuzz, it failed to trigger these two bugs.
We submitted the bugs for requiring CVEs, and the heap buffer overflow in _bfd_doprnt has been affirmed as CVE-2019-12972.
Besides, when testing GNU Binutils-2.31, EcoFuzz found four stack-overflow in xmalloc.c and cplus-dem.c.
They were reported to the Binutils group and have been patched.
Table 8 in Appendix 8.2 presents the analysis of all vulnerabilities.
These results show that EcoFuzz can detect vulnerabilities efficiently in some real-world programs.
The LAVA-M dataset is proposed as a benchmark for assessing the fuzzers' performance [12].
The dataset contains four programs that are base64, md5sum, uniq, and who.
Each program was generated by injecting some bugs into the source code.
Recently, several fuzzers (e.g., VUzzer, Steelix, Angora, and T-Fuzz [10,19,27,29]) used this benchmark in evaluation.Baseline.
In addition to tools in Section 5.2, we compared EcoFuzz with other state-of-the-art tools on LAVA-M, including Angora and VUzzer [10,29].
Configuration.
Since our platform in Section 5.2 was not connected to the Internet, for installing and running Angora as well as VUzzer, we deployed them on our cloud server, a ubuntu 16.04 server os with 8 cores (Intel Xeon Platinum 8163 CPU @ 2.50GHz) and 16GB of RAM.
A similar experiment was also conducted by executing each program for 5 hours, such that the configuration was the same as that in VUzzer and Angora.
Each experiment was repeated 5 times.
Further, EcoFuzz was run with the static analysis module, and the dictionary that this module generated is provided for all AFLtype fuzzers.
Table 5 lists the total bugs found by all fuzzers during the five runs.Discovered Bugs.
As shown in Table 5, EcoFuzz found the most bugs and outperformed others on LAVA-M.
On base64, md5sum, and uniq, EcoFuzz found all listed as well as unlisted bugs.
On who, as there were numerous bugs in who, the efficiency of detecting bugs of each fuzzer can be evaluated distinctly.
It was observed that EcoFuzz found the most bugs on who than the other fuzzers, with 1,252 listed and 200 unlisted bugs.
Moreover, AFLFast.new performed the best in other techniques, but it was not better than EcoFuzz.
Angora found 1,012 listed and 155 unlisted bugs, which is less than those found by EcoFuzz.Moreover, the result showed that AFL-type fuzzers could also find numerous bugs on LAVA-M in the dictionary model, with finding almost all bugs in base64, md5sum, and uniq.
In addition, EcoFuzz outperformed other AFL-type fuzzers on who, with finding 3× more bugs than AFL.
Therefore, EcoFuzz is efficient in discovering bugs in LAVA-M.
Since AFL-type fuzzers are deployed in our platform, where the configuration is slightly different from the cloud server, the comparison of EcoFuzz with Angora and VUzzer in Table 5 may not be strict enough.
Therefore, we implement EcoFuzz on the same cloud server and do more analysis in Appendix 8.3.
The previous evaluation proved that EcoFuzz could find more paths than other AFL-type fuzzers in most cases with lower average-cost.
There are also certain specific cases, such as when the test cases have slow execution speed and there is a low upper bound of paths (e.g., fuzzing the IoT devices or binary programs via QEMU), where EcoFuzz's advantages are prominent.
In such cases, EcoFuzz was applied on IoTHunter [37] to fuzz the SNMP component [8].
In RoutterOS'6.44.3 stable version, a vulnerability of SNMP component was observed.
This issue was declared to be a failure of the processing input SNMP packet that may lead to a denial of service.
The SNMP process will crash and restart when the packet in POC is received.
Although SNMP does restart after a crash, repeated crashes might create an extended Denial of Service (DoS) condition, as shown in Table 8.
Though we had submitted the crash, Mikrotik company released a new version of 6.45beta54 that has patched the bug.
Compared to other techniques, EcoFuzz can effectively explore more paths in the same number of executions.
The adaptive mechanism implemented by EcoFuzz enables EcoFuzz to flexibly revise subsequent energy allocations as per the current utilization ratio of energy.It is noteworthy that EcoFuzz developed AFL's search strategy and power schedule, not including the mutation strategies, to be similar to that of AFLFast.
That is, EcoFuzz does not change the transition probability p i j , which is different from FairFuzz.
Though FairFuzz improves the efficiency of random mutation, the result shows that EcoFuzz outperforms FairFuzz in terms of the ability to explore more paths while consuming less energy.
Additionally, when testing the real-world software, sometimes the ability to maximize the coverage while saving energy is crucial for CGF.
This has already been explained by implementing EcoFuzz for testing the IoT devices.As EcoFuzz is built on AFL, EcoFuzz follows AFL's advantages.
Compared to VUzzer [29] or other greybox fuzzing with taint analysis techniques, EcoFuzz's execution speed is higher.
EcoFuzz also benefits from certain techniques used for enhancing AFL (e.g., CollAFL [13]), thus ensuring that EcoFuzz's performance can still be enhanced.More importantly, regardless of which program analysis technique is used, whether the goal is to maximize coverage or explore rare branches, selecting an optimal seed to fuzz and assigning suitable energy are crucial for enhancing efficiency.
The VAMAB model can still optimize the power schedule of other fuzzers, whether they are AFL-type fuzzers or other greybox fuzzers, by simply modifying the definition of goal and rewards as per the actual requirement.
As a novel work that focuses on improving AFL's scheduling algorithm, AFLFast proposed a crucial concept transition probability for illustrating the transition between different paths, providing the direction of improving efficiency in power schedule and search strategy [6].
However, AFLFast did not conduct a deeper study of the transition probability.
In contrast, we developed a VAMAB model for explaining the fuzzing process in terms of game theory and presented the reward probability of depicting each seed's ability to find new paths according to the transition probability.
We also illustrated the probability attenuation of reward probability and stated the reward probability was not calculated accurately.
Moreover, the fuzzing process was classified into three states, and the challenges of the different states were explained, followed by suggesting optimal strategies for each state.
Compared to the Markov chain, our model reveals the challenges in scheduling algorithms more profoundly.Woo et al. [36] once stated searching over the parameter space of blackbox fuzzing as the MAB problem.
However, the goal of Woo et al. was finding the highest number of unique bugs, which is not applicable to CGF.
If more energy is assigned to the seeds finding crashes, it may only trigger the same crashes.
This is one of the reasons for not selecting the number of crashes as the target of our VAMAB model.
On the other hand, aiming coverage helped in finding more seeds exercising rare paths, thus aiding in finding unique crashes in different functions.
In addition, Patil et al. [26] modeled the problem of deciding the number of random fuzzing iterations as Contextual Bandits (CB) problem between the full reinforcement learning problem and MAB problem [18].
Patil et al. considered the seeds as arms and proposed multipliers of the test case's energy, treating them as the arms in the contextual bandit setting [26].
The aim of Patil et al. was to determine the energy value from the test case contents by using reinforcement learning techniques.
However, their work did not utilize the model for explaining the details of the fuzzing process and only presented an algorithm to decide a test case's energy multiplier, given fixed length contents of the test case [26].
In contrast, we considered the trade-off between exploration and exploitation of power schedules in CGF in detail.
Therefore, our VAMAB model is better suited for modeling the scheduling algorithm of CGF than MAB or CB.
To the best of our knowledge, we are the first to model the scheduling problem as VAMAB.
Certain directions for enhancing CGF can be understood based on the VAMAB model.
The first research direction is to improve the quality of the initial seeds, and this includes selecting the seed inputs from a wealth of inputs [30] or generating well-distributed seed inputs for fuzzing programs that process highly-structured inputs [33].
The core of these works is providing the high reward probability seeds to the initial state.
As stated in Section 5.4, EcoFuzz can also benefit from a smart mechanism of seed generation.
Besides, there are researchers who aim to establish the mechanism for estimating each seed's quality, which can help fuzzers accurately select the seeds with high reward probability.
Further, Zhao et al.[44] designed a Monte Carlo-based probabilistic path prioritization model for quantifying each path's difficulty and prioritizing them for concolic execution as well as implementing a prototype system DigFuzz.
Moreover, Böhme et al. [5] proposed the Directed Greybox Fuzzing by using the distance between the seeds and the target to measure the seeds' quality.
Based on the VAMAB model, these researches provide certain methods for accurately estimating the reward probability of their problem.
EcoFuzz also uses the SPEM algorithm to measure the quality of seeds.
Moreover, the experiments in our evaluation showed that the frequency of effective searching in SPEM is approximately twice that of FidgetyAFL on nm, which is regarded as a precise method for estimating the quality of seeds.
Besides, compared to AFLGo [5] and DigFuzz [44], EcoFuzz does not require additional program analysis techniques to achieve the same goals.
Several approaches focus on the second direction that enhances the mutation efficiency by using program analysis techniques.
Some approaches aim to find locations in seed inputs related to high-probability crash locations or to determine statements in the program [10,34], and other approaches try to learn input format and utilize it for assisting mutation.VUzzer [29] leveraged control-and data-flow features of targets and used this information in the feedback loop for generating new inputs.
However, VUzzer realized this function based on Pin [20], which is slower than the techniques of instruments used by EcoFuzz.
FairFuzz is implemented on AFL and can identify the parts of the input that are crucial for satisfying the determined conditions.
In test cases generation, it avoids mutating these crucial parts of the input and reduces the number of fuzz exercising high-frequency paths [17].
Nevertheless, FairFuzz achieves this function depending on the deterministic strategies being implemented, which is not as effective as the random mutation.
In this paper, EcoFuzz was assessed against FairFuzz, and it had been proved that, with the same number of executions, EcoFuzz outperforms FairFuzz in exploring paths.Some researchers aim to learn file formats and use them in mutation to improve efficiency.
Learn&Fuzz [14] used sequence-based learning methods for the PDF's structures.
Further, AFLSmart [28] kept the format attribute unchanged in the mutation by providing prior knowledge.
However, such techniques require lots of initial files or prior knowledge, making it difficult to implement in testing real-world programs.
In contrast, EcoFuzz can be started conveniently.
In this paper, we proposed a variant of the Adversarial MultiArmed Bandit (VAMAB) model and used it for modeling the scheduling problem in CGF.
We also introduced the reward probability for illustrating the ability of each seed to discover new paths and explained problems such as the probability attenuation.
In addition, we classified the states of the seeds set into three categories and illustrated the challenges and opportunities in these states.
Based on this, we proposed the SPEM for measuring the reward probability and developed an adaptive power schedule.
We implemented these algorithms on an adaptive energy-saving greybox fuzzer called EcoFuzz.
EcoFuzz explores more paths than six AFL-type fuzzers with fewer executions, significantly reducing the average-cost for discovering a new path.
Besides, EcoFuzz's adaptive mechanism and energy-saving advantages can help improve other techniques.
EcoFuzz was also compared with other works, and their optimization directions were explained by the VAMAB model, indicating that the applicability of our model is strong.Since our VAMAB model is related to the reinforcement learning and the schedule algorithms of EcoFuzz are slightly empirical, in the future, we may consider to optimize the schedule algorithms and improve our work by implementing some methods of reinforcement learning.
In this subsection, we implement a more in-depth analysis of the evaluation results in Section 5.2.
Path Coverage.
From Fig. 6, EcoFuzz outperforms the other six fuzzers on most programs except cxxfilt, readelf, djpeg, xmllint and infotocap.
For these five programs, on xmllint and infotocap, EcoFuzz finds more paths than other tools in the same number of executions.
The path coverage EcoFuzz achieves is only slightly lower than FidgetyAFL or AFLFast.new.
The reason is that they generate more test cases than EcoFuzz.
On cxxfilt, EcoFuzz performs better than AFLFast.new and FidgetyAFL when the number of paths is below 7,000.
After that, AFLFast.new and FidgetyAFL generate more test cases than EcoFuzz so that the paths discovered by AFLFast.new and FidgetyAFL are more than EcoFuzz.
On readelf, EcoFuzz performs similarly to AFLFast.new and FidgetyAFL in the early stage.
In the later stage, the number of paths discovered by EcoFuzz is slightly less than that of AFLFast.new and FidgetyAFL.
On djpeg, as can be seen from Fig. 6, there are two significant increases in the curve of AFLFast.new and FidgetyAFL in the latter stage, which makes the numbers of paths found by AFLFast.new and FidgetyAFL exceed that of EcoFuzz.
We analyze the result of each run on djpeg and find that there are two runs of AFLFast.new and FidgetyAFL discovering over 4,500 paths on djpeg, respectively.
In other cases, the number of paths they found is approximate to that of EcoFuzz.
We regard this as the impact of experimental contingency.In addition, in most cases, fuzzers without indeterministic strategies (EcoFuzz, FidgetyAFL, and AFLFast.new) were noted to perform better than FairFuzz, AFL, AFLFast, and MOPT-AFL.
This proves that the indeterministic mutation strategies are efficient in general.
Particularly, EcoFuzz finds significantly more paths than these four tools, and overall, EcoFuzz performs better than six other techniques in path exploration and energy saving.Average-Cost and Total Executions.
From Table 2, notice that, on most cases, under the same testing hours, the number of test cases produced by EcoFuzz is far fewer than other techniques, especially on the subjects cxxfilt, xmllint and infotocap.
The reason is that when EcoFuzz assigns energy to a seed, EcoFuzz does not take the execution time or length of the seed into consideration.
That leads EcoFuzz to allocate energy on a long execution time seed as same as other some fast seed, which costs EcoFuzz more time to fuzz it than some other seeds.
Besides, EcoFuzz has fuzzed all seeds from the queue, with implementing more executions on the trim strategy than other techniques.
Different from our scheduling algorithm, the power schedules of other fuzzers we compare against to EcoFuzz are mainly based on that of AFL and maintain most features.
As introduced in Section 2.1, during the indeterministic strategies, AFL assigns energy to the seed according to its performance score, which is calculated based on the execution time, coverage, and discovery time.
The longer its execution time is, the less energy is allocated.
This mechanism guarantees that AFL will not spend a lot of time on fuzzing these long execution time seeds.
However, it makes sense to allocate energy to these long execution time seeds, which also helps us to improve the coverage.More Statistical Analysis.
In Section 5.2, we have reported the results of statistical analysis and pointed out that EcoFuzz outperforms other tools in general.
In this subsection, we analyze the statistical results of p value and extremum in detail.From Table 6, on the path coverage, p 1 is smaller than 10 −4 in all evaluations, indicating that the distribution of total paths found by EcoFuzz and AFL differs significantly.
Further, p 3 , p 5 , and p 6 are also mostly tend to be smaller than 10 −3 , which proves that EcoFuzz also outperforms AFLFast, FairFuzz, and MOPT-AFL notably in path exploration.
In the majority of evaluation, p 4 is approximately the same as 10 −1 , this indicating that the paths EcoFuzz and AFLFast.new find are not significantly different.
However, on the averagecost, p 4 is smaller than 10 −2 on 11 evaluations, thus proving that EcoFuzz's average-cost is significantly lower than that of AFLFast.new.From Table 7, EcoFuzz and AFLFast.new outperform the other five tools on most programs, whether in the maximum or the minimum of discovered paths.
EcoFuzz achieves the upper bound of the maximum of path coverage on six programs, minimum of path coverage on eight programs.
Compared to AFLFast.new, though EcoFuzz achieves the path coverage approximate to AFLFast.new, the energy depletion of EcoFuzz is lower than AFLFast.new.
In Section 5.4, we evaluated the validity of EcoFuzz on detecting vulnerabilities and reported some vulnerabilities found by EcoFuzz in general.
We state some detailed analysis of these vulnerabilities in this subsection.
In addition to the bugs found in GNU Binutils, EcoFuzz also found 5 vulnerabilities on some programs tested in Section 5.2, with 2 heap-buffer-overflow in gif2png, and tcpdump, as well as 3 memory leak in libpng and jhead, which were only found by EcoFuzz, FidgetyAFL and AFLFast.new.
In detail, there are 2 vulnerabilities found in gif2png, a heap-buffer-overflow in the writefile function in gif2png.c and a memory leek in the xalloc function in memory.c.
In addition, since gif2png is built on libpng, EcoFuzz also found a memory leak in png_malloc_warn in pngmem.c of libpng when recurred a crash in gif2png.
Moreover, EcoFuzz found a heap-buffer-overflow in jhead, which is triggered in the process_DQT function in jpgqguess.c and has been requested as CVE-2020-6624 by others.
This vulnerability was only found by EcoFuzz, FidgetyAFL and AFLFast.new, thus proving that EcoFuzz is more efficient than AFL and AFLFast in detecting vulnerabilities.
In addition, we recompiled and tested tcpdump with the ASAN model of AFL.
EcoFuzz found a memory leak in the copy_argv function in tcpdump.c.
Finally, we submitted these 5 vulnerabilities and obtain CVE-2019-17371 as the memory leak in libpng.
All vulnerabilities are listed in Table 8.
In Section 5.5, we evaluate the performance of each technique on LAVA-M in general.
We also point out the comparison between EcoFuzz with Angora and VUzzer is not strict enough.
Now we do a more in-depth and detailed analysis.
We deployed EcoFuzz on the cloud server in Section 5.5.
We also run EcoFuzz with the same setting as in Section 5.5.
After validating the bugs detected by EcoFuzz during 5 times of 5-hours runs, EcoFuzz found all listed and unlisted bugs on base64, md5sum, and uniq, with 48(+4), 57(+4) and 28(+1) bugs.
For who, EcoFuzz found 1,966 bugs in total, with 1,750 listed and 216 unlisted bugs, which are both more than that of Angora and VUzzer.
In detail, EcoFuzz detected 1,139, 1,365, 1,377, 1,450 and 1,210 bugs on who in each run, respectively.
Since different environments have an impact on the experimental results and there is non-negligible randomness in the experiment of fuzzing, it is not objective to deduce that EcoFuzz can always outperform Angora on LAVA-M from the results in our evaluation.
In the origin paper, Angora can find 1,541 bugs on who in one 5-hours run [10], which states that Angora is still an efficient and state-of-the-art tool in detecting the bugs in LAVA-M.
From these results, on base64, md5sum, and uniq, EcoFuzz found all the listed and unlisted bugs, as same as FidgetyAFL and AFLFast.new.
Angora also performs well on these three programs.
Furthermore, these four tools all detected numerous bugs in who.Moreover, AFL-type fuzzers all perform well on LAVA-M in the dictionary mode.
In fact, the way to trigger the bugs injected in LAVA-M is extremely simple, just satisfying the comparison of some four-byte magic bytes in some positions.
However, AFL could not recognize magic bytes in the conditional statement.
Therefore, a comparison of four-byte magic bytes will cost AFL too much energy to traverse.
Some techniques using taint tracking or symbolic execution outperform than AFL without a dictionary on LAVA-M [10,38].
In practice, the static analysis module of EcoFuzz has solved the problem by extracting the hard-code and magic bytes in LAVA-M.
Therefore, it is an efficient way to combine the lowoverhead program analysis techniques (e.g., static analysis) with the high-speed greybox fuzzing (e.g., AFL).
Finally, all unlisted bugs found by EcoFuzz in different environments are listed in Table 9.
The authors would like to thank our shepherd Deian Stefan and anonymous reviewers for their valuable comments and helpful suggestions.
The authors are supported in part by Tianhe Supercomputer Project 2018YFB0204301, National Science Foundation of Hunan Province in China (2019JJ50729), and National Science Foundation China under Grant 61902412 and 61902416.
x SubjectsNumber of total paths Average-cost Number of total paths Average-cost
