Although the importance of format and presentation of privacy notices has been extensively studied in the privacy literature, less explored is the interplay of presentation and content in influencing users' disclosure decisions.
In two experiments, we manipulate the content as well as the format of privacy notices shown to participants who were asked to choose whether they would like to disclose personal information.
We manipulate content by changing the objective privacy risk that participants face from disclosing personal information.
We manipulate format by changing the manner in which these notices are presented.
We find that participants are significantly less likely to share their personal information when the privacy notice is presented under a 'Prohibit [disclosure]' frame, as compared to an 'Allow [disclosure]' frame.
However, and importantly, we find that the effect of changes in framing on disclosure decisions is small when the objective privacy risk from disclosure is low, but the effect of framing becomes larger when the risk is increased-that is, for potentially more sensitive decisions.
Our results highlight the nuanced interaction effects between the objective content of privacy notices and the manner in which they are presented, on disclosure behavior.
Online companies collect many different types of information about their users, such as browsing behavior, search queries, purchase history, location information, and demographic information.
Typically, users agree to share this information when they register for an online service and accept the service's privacy policy.
In some cases, the permission to collect specific types of information is obtained after the registration process is complete, while the user is using the service.
For example, a mobile app may obtain consent for collecting browsing behavior and purchase history in its privacy policy, but may later display a prompt asking for permission to collect location information while the user is employing a feature that specifically requires the use of location information.
In both cases, the service provider designs the interface where the user makes his or her choice to disclose personal information-thus, it can act as a "choice architect" [21], and influence users' decisions and behaviors.
Substantial behavioral research in the privacy field has, in fact, suggested that the interface itself, and not just the content of the policy, may affect individuals' propensity to disclose personal information [e.g., 2].
Much less studied, however, is how the effect of changes in the presentation of privacy-relevant information interacts with the effect of changes in the objective privacy risk from disclosure, on individuals' propensity to disclose personal information.In two experiments, we manipulate the content as well as the format of privacy notices shown to participants.
We manipulate content by changing the privacy risk that participants face from disclosing information (for example, by varying the entity with which the information is to be shared).
We manipulate format by changing the frame under which these notices are presented to the subjects.
We find that participants are significantly less likely to share their personal information when the privacy notice is presented under a 'Prohibit [disclosure]' frame, as compared to an 'Allow [disclosure]' frame.
However, and importantly, we also find that the effect is small when the objective privacy risk from disclosure is low, but becomes larger when the risk is increased to moderate levels.
The results highlight the nuanced interactions between the actual content of privacy notices and the way they are presented, in influencing consumer behavior.The implications of the results are twofold.
First, these results highlight the challenges of relying solely on providing notice and choice to consumers to achieve a policy maker's goal of consumer privacy protection.
The manner in which notices are framed can have a significant effect on behavior.
As long as firms are the choice architects of their own privacy notices, they may implement framing nudges that influence consumers' choices, for instance to affect the rate of disclosure of personal information.
Second, these results provide insights into identifying specific situations where framing effects matter the most (when objective risks are moderate), thus helping organizations, individuals, and policy makers direct their attention to notices that may lead to strong framing effects.
Framing effects refer to the phenomena whereby "simple and unspectacular changes" in the presentation of decision problems lead to changes in choice [11].
These simple changes do not alter the objective factors of the decision.
Evidence from behavioral decision research shows that such seemingly insignificant changes can have a significant impact on individuals' choices.
In other words, they can act as "nudges."
In 1981, Tversky and Kahneman presented participants with the choice between a certain treatment that can save 200 of 600 people affected by a disease, and a Copyright is held by the author/owner.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee.Symposium on Usable Privacy and Security (SOUPS) 2017, July 12 --14, 2017, Santa Clara, California.
.
Thirteenth Symposium on Usable Privacy and Security 377 probabilistic option that has the same expected value (1/3rd probability that 600 people will be saved).
They found that participants prefer the certain choice to the probabilistic one, but when the same choice is framed in terms of the number of lives lost (i.e., 400 people die out of 600 affected) then participants preferred the probabilistic option to the certain choice [22].
The mere framing of the choices (in terms of lives saved or lost) had a significant impact on individuals' decisions.
In 1988, Levin and Gaeth showed that labeling a pack of ground beef as "75% lean" instead of "25% fat" significantly impacted participants' perception of the quality of the beef [14].
Along similar lines, other researchers have found differences in perceptions when situations are described in terms of success rates versus failure rates [6].
Even though framing effects have been shown to significantly impact behavior in many cases, there is also no dearth of examples where framing effects have failed to change behavior ( [15] provides a review of when framing effects have been shown to appear and disappear).
For example, Druckman's 2001 work showed that framing effects can drastically decrease and even diminish when individuals are provided with credible advice about how to make the decision [7].
The intensity of framing effects also changes dramatically across different task domains.
In 1996, Wang studied framing effects in risky choices across three different task domains, where participants had to choose between a sure outcome and a gamble of the same expected value.
In addition to finding significantly different intensities of framing effects across domains, he also found that, within a given domain, framing effects tend to appear and disappear depending on the expected value of the gamble [23].
Since expected value manipulations change the objective benefits provided, this result suggests that when objective content is varied framing effects may change in intensity and may even disappear.In the typical framing studies, participants are asked to choose between a sure option and a gambling option, while the framing of these options is manipulated between conditions.
Under the positive frame, participants choose between winning an amount X for sure and a gamble in which they may win an amount greater than X but with some probability less than 1 (for example, a gamble to win 2X with probability ½).
Under the negative frame, participants are given some money in advance and asked to choose between giving back an amount X for sure and a gamble in which they may lose an amount greater than X but with some probability less than 1 (for example, a gamble to lose 2X with probability ½).
Participants tend to prefer the sure option to the probabilistic one when choices are framed as gains, and the opposite occurs when choices are framed as losses.
But some researchers have found that framing effects can disappear if the payoffs from the choices are too small [9].
Therefore, it is important to investigate the interplay between objective payoffs and framing.
In the case of privacy decisions, framing effects may disappear when the objective risk associated with disclosing personal information is perceived to be too low.
In our studies, we test the interplay between objective risk and framing effects by varying both factors: 1) the objective risk participants face when disclosing personal information and 2) the manner in which the risks from disclosure are framed.Previous researchers have also argued that non-normative factors, such as framing, tend to have an impact on decisions when consumers' preferences are ambiguous, but this effect diminishes (and even disappears) when preferences are more certain [19].
This is because, when preferences are ambiguous, individuals tend to look for additional cues (such as how a problem is framed) to help them construct preferences [18,20].
This suggests that framing may significantly impact decisions when individuals' preferences are ambiguous, and may fail to impact decisions when preferences are certain.
In our work, we test this conjecture by measuring participants' level of ambiguity or uncertainty with their sharing decisions, and evaluating whether uncertainty can explain how framing effects impact disclosure decisions.
In two studies, we manipulate the manner in which privacy notices that inform participants about the risks from disclosure are framed.
These studies were conducted on Amazon's Mechanical Turk (MTurk) platform.
Previous researchers have shown that MTurk workers are more demographically diverse than the typical convenience samples of American college students, and established results have been replicated with this population, confirming its reliability [3,4].
Amazon Mechanical Turk also allows researchers to approve or reject participants' payment based on their performance.
Therefore, each participant has an approval rating, which is the percentage of his or her previously completed surveys or tasks that have been approved.
We implemented a minimum requirement of a 95% approval rating during our recruitment process, and also used attention check questions in our surveys to ensure high quality data.Our framing manipulation was embedded in the choice presented to our participants.
In one condition, we asked participants if they would like to "allow us to share your information" and in another we asked if they would like to "prohibit us from sharing your information."
Similar to framing manipulations used in previous literature, this manipulation allowed us to change the format of the notice while keeping the objective content of the notices constant.
Query Theory research [8,10] suggests that under the 'Allow' frame individuals will be more likely to give permission to share their information because 'Allow' frames typically make individual more likely to think about reasons to act as described in the question (in our context, allow the sharing of their information); whereas individuals will be less likely to give permission to share their information under the 'Prohibit' frame because it makes them more likely to think about reasons to prohibit the sharing of their information.
Therefore, we hypothesize that participants in the 'Allow' condition will be more likely to accept the privacy policy than those in the 'Prohibit' condition.Based on the literature highlighted in the previous section, we expect that, at low levels of objective privacy risk, individuals' sharing decisions will not vary with the framing of the notice.
On the other hand, at moderate levels of disclosure risk, framing will have a significant effect on individuals' sharing decisions.
We tested this hypothesis by varying the objective risk from disclosing personal information between conditions, and comparing the impact of framing at the different objective risk levels.
In addition, we also tested the conjecture that framing effects depend on the level of ambiguity or uncertainty that participants have towards these disclosure decisions.
Specifically, we investigated whether framing effects only tend to appear when participants are less certain about their preferences.
All our studies were approved by the Institutional Review Board at Carnegie Mellon University.
The IRB review covered the deception that we implemented in our studies.
All participants were debriefed at the end of the study to clarify that their data will not be shared with anyone other than the researchers conducting this study.
In this study, we manipulated risk and framing in a context that involved making real information disclosure decisions.
Participants were recruited from Amazon's Mechanical Turk for a study about ethical behaviors.
Following the design put forward by Adjerid et al. in their 2014 work, we first asked participants for their demographic information, and informed them that they would be asked several questions of a sensitive nature, such as "Have you ever had a one-night stand?"
The goal of collecting demographic information before presenting the disclosure choice was to elicit a level of quasi-identifiability, so the subsequent disclosure decisions would not seem entirely risk-free [2].
Then we asked participants to make a disclosure choice for whether they would be willing to share their responses to the ethical behavior questions with a specific audience.
We manipulated objective privacy risk by changing this audience: in one condition, the audience was research assistants for this study, whereas in the other condition the audience was a marketing company.
We expected that participants would perceive sharing information with research assistants as not very risky, but sharing with a marketing company would be perceived as being somewhat risky.
Framing was manipulated using the 'Allow' and 'Prohibit' frames.
For instance, participants in the 'Marketing Company' and 'Allow' frame condition were shown the following sentence: "Allow my responses to be shared with a marketing company."
As participants were aware that they were going to be asked a set of highly intrusive questions, the decision to share their responses with the specified audience involved evaluating actual risks, as opposed to hypothetical ones.
Following this question, we asked them ten questions related to ethically questionable activities.
1 Participants were informed that if they were not comfortable answering any of these questions, they could skip them and proceed with the survey without any penalty.
Note that while participants were told that their information would be shared with the specified audience, we did not actually share their information with anyone outside of the primary researchers associated with this study.
Participants were debriefed about our real motivations at the end of the study.
Three hundred and seventy-six individuals (Mean Age = 32.5; 58% Male) from Amazon's Mechanical Turk participated in Study 1.
Participants in the 'Allow' condition were 21% more likely to share their responses compared to those in the 'Prohibit' condition (86% vs. 71%, í µí¿2 (1) = 12.22, p<0.001).
Furthermore, participants in the 'Research Assistants' condition were 55% more likely to share their responses when compared to those in the 'Marketing Company' condition (96% vs. 62%, í µí¿2 (1) = 64.74, p<0.001).
Therefore, we observe main effects of framing and risk.Looking at the two risk conditions individually, we find that there is no significant effect of framing among participants in the 'Research Assistants' condition (98% vs. 93%, í µí¿2 (1) This interaction effect provides evidence for the argument that the intensity of the framing effect depends on the level of risk that participants are faced with.
When the risk of information sharing is low (such as sharing survey responses with research assistants) then framing effects may disappear, but they appear when the risk of information sharing is relatively higher (such as sharing survey responses with a marketing company).
In addition, these results also suggest that an increase in objective privacy risk under the 'Allow' frame leads to a smaller adjustment of sharing behavior, as compared to an equivalent increase in risk under the 'Prohibit' frame.
This implies that, when privacy policies are framed in a positive way (as most current day privacy policies are), individuals may be less likely to adjust their sharing behavior to account for an increase in objective privacy risk, compared to cases when privacy policies are framed in a negative way.
This result is important as companies frequently make changes to their privacy policies and Thirteenth Symposium on Usable Privacy and Security 379 these changes often involve increasing the privacy risk for consumers.
The results from Study 1 provide evidence that framing nudges in privacy notices can influence disclosure decisions, but these effects are not universal across different levels of objective privacy risk.Positive frames such as 'Allow' make participants more likely to share their personal information when compared to negative frames such as 'Prohibit'.
But there may be credible levels of objective privacy risk at which individuals overcome the effect of framing, because the risk associated with sharing is perceived to be too low (such as sharing survey responses with research assistants).
When the objective privacy risk associated with sharing information is moderate (such as sharing with a marketing company), framing effects are more likely to occur.
This result is consistent with previous research that showed framing effects tend to disappear when objective payoffs from a gamble are small [9,12,13].
Following Study 1, we conducted a set of additional studies to measure the level of perceived risk associated with sharing personal information with different entities.
These studies gave us insight into the relative perceptions of risk associated with the two conditions tested in Study 1 as well as other conditions which we later tested in Study 2.
Participants were recruited from Mechanical Turk for a study in which they would be asked for their opinions about a hypothetical scenario.
Participants were asked to imagine that they were answering a survey about ethical behaviors on Mechanical Turk, which involved answering sensitive questions such as "Have you 2 The differences between 'Publicly Online' and 'On MTurk with Turk ID' for all four variables are not statistically significant.
All other differences are statistically significant at the 0.001 level.ever had a one-night stand?"
They were then told that the researchers of that study first asked them whether they would be willing to share their information with a specific audience.
We manipulated this audience between conditions, testing four different audiences: 1) research assistants, 2) marketing companies, 3) publicly on the Internet, and 4) on Mechanical Turk forums (such as Turker Nation, MTurk Grind, MTurk Forum, etc.) along with their Mechanical Turk ID.
The last condition was included in an attempt to increase the personal relevance of the decision for Mechanical Turk participants, as individuals on Mechanical Turk often use such forums to discuss pragmatic considerations about MTurk tasks such as pay rates or requesters' reputations [5].
Arguably, they may care a significant amount about their reputation on these forums.
As Mechanical Turk does not permit the collection of any personally identifiable information, we attempted to achieve quasi-identifiability by claiming that the responses would be shared along with participants' Mechanical Turk ID.
Next, participants were asked four questions, each on a 1-7 scale from 'Not at all' to 'Very much': 1) how risky they thought it would be to share their survey responses with this audience, 2) how likely they would be to share their survey responses with this audience, 3) how comfortable they would be sharing their survey responses with this audience, and 4) how concerned they would be about sharing their survey responses with this audience.
One thousand, two hundred seventy-nine participants (Mean Age = 32.3; 55% Male) from Amazon Mechanical Turk completed this survey.
As shown by the mean values reported in Table 1, participants did not think sharing their survey responses with research assistants was very risky.
Sharing survey responses with marketing companies, publicly online, and on Mechanical Turk forums with Mechanical Turk IDs were perceived to be increasingly riskier scenarios, in that order.
2 These results confirm the assumption made in Study 1, that the perceived risk of sharing survey responses with research assistant is very low risk while that of sharing survey responses with marketing companies is moderate.
Participants were recruited for a survey about information sharing preferences.
Each participant was shown five scenarios, two of which involved sharing information with a hypothetical news website and three of which involved sharing survey responses to ethical behavior questions with a specific audience.
Therefore, this study was conducted with a within-subjects design as opposed to the between-subjects design of Survey A.
In the two scenarios involving the sharing of information with a hypothetical news website, participants were asked to imagine that they want to read an article on a news website but are faced with the decision to accept or reject the news website's privacy policy before they can read the article.
We tested participants' opinions about two different amounts of personal information purportedly being collected by the news website.
(These two scenarios are used in studies that are not reported in this paper.)
The scenarios involving sharing survey responses with specific audiences were presented in the same way as in Survey A (by asking participants to imagine they are answering a survey about ethical behaviors).
The three audiences tested in this survey were: 1) research assistants, 2) other research organizations, and 3) marketing companies.
We asked participants how risky they thought it would be to share the information and how likely they would be to share it, on a 1-7 scale ranging from 'Not at all' to 'Very much.'
The same two questions were used for the hypothetical news website scenarios as well, and the order of these two questions was randomized across participants.
One hundred twenty participants (Mean Age = 34.3; 67% Male) from Amazon Mechanical Turk completed this study.
As shown by the mean values reported in Table 2, sharing survey responses with research assistants, other research organizations, and marketing companies are perceived to be increasingly riskier scenarios, in that order.
3 6.
STUDY 2 Based on the results of the surveys we designed the second study.In Study 2, we test framing effects at three different risk levels to get a better sense of how framing effects vary with risk.
The design of this study is similar to that of Study 1, but instead of a 2-by-2 design, we used a 2-by-3 design.
Two objective privacy risk levels tested in this study are similar to the ones used Study 1: sharing with research assistants and sharing with marketing companies.
The third risk level is sharing on Mechanical Turk forums (such as Turker Nation, MTurk Grind, MTurk Forum, etc.), along with their Mechanical Turk ID.
The framing manipulation is implemented in the same way as in Study 1, by altering whether participants are asked to 'Allow' the sharing of their information or 'Prohibit' the sharing of their information.
Just as in Study 1, participants were first informed that they were going to be asked sensitive questions.
Then, they were asked for their sharing preferences (varying the scenarios in their framing and risk between conditions) and were subsequently asked the same ethical questions as used in the previous study.
We include an additional question in this study that measures participants' level of uncertainty with the sharing decision, using the uncertainty subscale from the Decision Conflict Scale [16].
This question is included to test whether participants' level of uncertainty with the sharing decision varies in the same way as framing effects vary when objective risk is manipulated (i.e., more uncertainty correlates with larger framing effects).
Such a result would provide support for the conjecture that framing effects only occur when individuals' preferences are ambiguous, consistent with previous research [19].
Participants were debriefed at the end of the study.
Nine hundred ninety-five individuals (Mean Age = 37.2; 47% Male) from Amazon Mechanical Turk completed Study 2.
Participants in the 'Allow' condition were 43% more likely to share their responses when compared to those in the 'Prohibit' condition (73% vs. 51%, í µí¿2 (1) = 51.95, p<0.001).
Furthermore, participants in the 'Research Assistants' condition were 64% more likely to share their responses when compared to those in the 'Marketing Company' condition (92% vs. 56%, í µí¿2 (1) = 109.26, p<0.001), and participants in the 'Marketing Company' condition were 37% more likely to share their responses when compared to those in the 'Mechanical Turk Forums' condition (56% vs. 41%, í µí¿2 (1) = 14.64, p<0.001).
Therefore, we observe the main effects of framing and risk.Looking at the three objective privacy risk conditions individually, we find a significant effect of framing at all three risk levels ('Research Assistants' condition: 96% vs. 87%, í µí¿2 (1) = 7.84, p=0.005; 'Marketing Company' condition: 67% vs. 44%, í µí¿2 (1) = 17.42, p<0.001; 'Mechanical Turk Forums' condition: 58% vs. .
Therefore, we find that when objective risk from disclosure is low, our framing manipulation has a smaller impact on sharing decisions, but as the objective risk increases, the effect of our framing manipulation also increases.
It is important to note that even the highest level of risk tested in this study ('Mechanical Turk Forums') is perceived to be 'moderate', as shown by the mean value of perceived risk in Survey A (mean perceived risk for 'Mechanical Turk Forums' = 4.44 on a 1-7 scale).
So, the increasing trend in the size of framing effects is observed when risk increases from low to moderate levels.
We do not know how framing effects may vary when the perceived risk increases beyond moderate levels to high levels.
Thirteenth Symposium on Usable Privacy and Security 381 Next, we analyze how participants' uncertainty varies with objective risk, to see if uncertainty can explain the increase in the size of framing effects as risk increases.
The three items in the uncertainty subscale of the Decisional Conflict Scale [16] show high reliability (Cronbach's alpha = 0.927) so we follow the instructions provided by O'Connor [17] to code the 1-5 scale (from 'strongly agree' to 'strongly disagree') as 0-4, then average the three items and multiply the averaged value by 25.
The final score ranges from 0 (participant feels extremely certain about the best choice for them) to 100 (participant feels extremely uncertain about the best choice for them The results from Study 2 confirm an increasing trend in the size of framing effects as objective privacy risk increases.
We find a small but significant effect of framing on sharing decisions when perceived risk is low (such as sharing with research assistants).
The size of the framing effect increases as risk is increased to moderate levels (such as sharing on Mechanical Turk Forums along with Mechanical Turk ID).
These results are particularly important from a policy perspective as they suggest that regulators should work towards more nuanced requirements in terms of how privacy notices ought to be framed.
Individuals' propensity to framing effects varies considerably with objective risk.
A single set of blanket requirements for all websites (irrespective of the amount of privacy risk consumers face from sharing information) may not be sufficient to protect consumers' privacy.
For instance, websites that merely collect users' IP addresses versus those that collect web browsing and purchase behaviors should not be subject to the same regulations.
Our results suggest that the latter category of websites may be more capable of nudging consumers' sharing decisions by using framing nudges, and therefore should be held to higher standards by policy makers.
While it is challenging to present information in a truly "neutral" frame, further work should investigate solutions to mitigate the privacy risk faced by consumers, especially in situations with moderate objective risk.It is important to discuss the limitations of this study.
First, the highest level of objective privacy risk tested in this study (sharing on Mechanical Turk Forums along with Mechanical Turk ID) is only perceived to be moderately risky by our participants.
So, the observed increasing trend in framing effects can only be claimed to occur when risk increases from low to moderate levels.
While we do not know for sure how framing effects would vary when risk is increased from moderate to high levels, we suspect that framing effects may decrease at very high levels of risk.
Second, this study also attempted to test whether participants' level of uncertainty can explain the increase in size of framing effects as risk is increased.
We could not find evidence for this, as uncertainty did not vary significantly across the different risk levels.
Further research is required to better understand why framing effects increase when objective risk is increased from low to moderate levels.
In two experiments, we studied the influence of a framing nudge that may be used in privacy notices to influence individuals' willingness to disclose personal information.
We found that the manner in which privacy notices are framed has a significant impact on individuals' disclosure decisions.
Consistent with our hypotheses, notices that use the 'Prohibit' frame reduce the likelihood that individuals will share their information as compared to notices that use the 'Allow' frame.
However, and importantly, we also found that the intensity of this framing effect is small when objective privacy risk from disclosure is small, and it increases as the objective privacy risk increases to moderate levels.These findings have implications for the design of privacy policies that can empower consumers to face the tradeoffs between privacy risks and the benefits associated with data sharing.
Specifically, our results strengthen the notion that simply providing consumers with notice and choice may not be sufficient mechanisms to serve the goal of consumer privacy protection.
The manner in which notice and choice are framed is also important as companies may use framing nudges to impact individuals' sharing decision.
Our results also assist in guiding the attention of organizations and policy makers towards cases where individuals might be most susceptible to framing nudges, specifically when the objective privacy risks are moderate.
Owing to the substantially different intensities of framing effects observed at different objective privacy risk levels, it appears that a blanket policy for all websites, irrespective of the amount of privacy risk consumers face from sharing information with the site, may not be sufficient to protect consumers' privacy.
Companies and policy makers may consider more nuanced sets of rules concerning how privacy policies should be framed, keeping in mind the level of privacy risks put forward by different websites.
6.
Have you ever neglected to tell a partner about a sexually transmitted disease from which you were suffering?
7.
Have you ever had sex with someone who was too drunk to know what they were doing?
8.
Have you ever stolen anything that did not belong to you?
9.
Have you ever tried to gain access to someone else's (e.g., a partner, friend, or colleague's) email account?
*p<0.10; **p<0.05; ***p<0.01 Standard errors in brackets S A. Appendix AQuestions used in Study 2 (from Acquisti et al., 2012):1.
Have you ever had sex with the current husband, wife, or partner of a friend?
2.
Have you ever masturbated at work or in a public restroom?
3.
Have you ever had a fantasy of doing something terrible (e.g., torturing) to someone?
Questions used in Study 2 (from Acquisti et al., 2012):1.
Have you ever had sex with the current husband, wife, or partner of a friend?
2.
Have you ever masturbated at work or in a public restroom?
3.
Have you ever had a fantasy of doing something terrible (e.g., torturing) to someone?
