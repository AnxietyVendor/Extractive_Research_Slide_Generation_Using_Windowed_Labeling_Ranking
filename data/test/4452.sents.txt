We present SA-6, a six-item scale for assessing people's security attitudes that we developed by following standardized processes for scale development.
We identify six scale items based on theoretical and empirical research with sufficient response variance, reliability, and validity in a combined sample (N = 478) from Amazon Mechanical Turk and a university-based study pool.
We validate the resulting measure with a U.S. Census-tailored Qualtrics panel (N = 209).
SA-6 significantly associates with self-report measures of behavior intention and recent secure behaviors.
Our work contributes a lightweight method for (1) quantifying and comparing people's attitudes toward using recommended security tools and practices, and (2) improving predictive modeling of who will adopt security behaviors.
The human in the loop is often the weakest link in any security system [17,78].
Understanding people's attitudes toward security technology is key to designing systems that are both usable and tough to breach.
For this reason, a fair amount of research in usable security and privacy employs in-depth interviews and observation with small samples to understand people's attitudes toward a security practice or technology, e.g. [12,20,29,36,73].
However, we need to seek ways to operationalize such concepts in efforts to better understand the phenomenon and its relation with causes and outcomes in a more robust way e.g., experiments and longitudinal surveys.
It is not always feasible or appropriate to utilize a qualitative approach.
It is time-consuming to identify and label the concepts underlying people's openended responses, and such custom analyses are prone to error.
We need a quantitative measure in order to systematically assess and compare users' security attitudes.The current state of the art for measuring users' thinking about security practices is the Security Behavior Intentions Scale [32,33].
SeBIS' 16 items are grounded in security expert recommendations for user behavior in four areas: device securement, updates, password management, and proactive awareness.
While SeBIS can tell us the degree to which a user intends to comply with these expert recommendations, it cannot tell us people's attitudes about security behaviors.We also find SA-6 significantly associated with self-reported recent security behavior.
Here we go beyond previous work on security behavior intentions, connecting attitudes and intentions to people's recalled security actions in the past week.
We find that SA-6 and SeBIS associate with recent security actions and support for SeBIS as a partial mediator of SA-6's influence on reported recent security behavior.
Our results suggest that SA-6 may help model who is likely to act on security recommendations and who will benefit most from security awareness training or tutorials.This paper makes the following contributions:• The introduction of a six-item validated self-report measure of security attitudes (SA-6) for use by researchers and practitioners to systematically assess and compare user attitudes toward security techniques;• An analysis of the relationship between security attitudes, security intentions, and recent security actions;• A discussion of how and why to use SA-6 for measuring security attitudes to explain and predict user adoption of recommended security behaviors.
Most human behavior is goal-directed [8].
But for most computer users, staying secure and avoiding relevant threats is a secondary goal at best.
The need to understand how to nudge adoption of secure behaviors in spite of this underpins much prior work integrating psychology with cybersecurity.To develop our scale, we identified a concept in the cybersecurity literature that corresponds to the psychological conception of attitude.
We then identified concepts that could be expected to relate to and vary with this attitude factor according to theoretical models of how accept and adopt expert-recommended secure tools and practices.
Attitudes represent people's evaluation of objects, groups, events, that is how they orient to the world around them [4].
Eagly and Chaiken [30] define an attitude as "a psychological tendency that is expressed by evaluating a particular entity with some degree of favor or disfavor."
An extensive body of research in psychology examines attitudes, their antecedents and consequences and their relationship to intentions and behavior [4,6].
In fields as disparate as organizational psychology [57] to environmental sustainability e.g. [9,43], researchers measure attitudes to understand behavior.To develop our measure of security attitudes, we examined the cybersecurity literature for work that documented user attitudes about expert-recommended tools and practices.
The focal concept we identified is security sensitivity.
In the field of usable security, end-user security sensitivity is defined by Das as "the awareness of, motivation to use, and knowledge of how to use security tools" and practices [20].
Das and collaborators based this construct on empirical findings in interview studies that many people believe themselves in no danger of falling victim to a security breach and are unaware of the existence of tools to protect them against those threats; also, they perceive the inconvenience and cost to their time and attention of using these tools and practices as outweighing the harm of experiencing a security breach; and, they think these measures are too difficult to use or lack the knowledge to use them effectively [20][21][22][23].
Das summarized the concept as a series of six questions, which focus in parallel on tools and threats [20].
Restated, these six sub-dimensions are: awareness of the existence of security threats; awareness of the existence of security measures (tools, behaviors and strategies) that can be used to counteract threats; motivation to counteract security threats; motivation to use security measures to counteract threats; knowledge of the relevance of security threats; and knowledge of how to use security measures to counteract relevant threats.
This builds in turn on theoretical and empirical work from Davis and others [25,26] We used the literature from Das et al. on security sensitivity as a main source of items to test for inclusion in SA-6.
Davis et al.'s Technology Acceptance Model [25,26] (TAM) was among the first to integrate users' psychology along with design characteristics to explain the degree to which users accept and use a computational technology.
In their model, a user's attitude toward using a system (affective response) after encountering its design features (external stimulus) is mediated through their perceptions of the system's usefulness and ease of use (cognitive response) to determine their actual system use (behavioral response).
The TAM in turn builds on a psychological framework originated by Fishbein & Azjen, the Theory of Reasoned Action [37] (TRA).
The basic theory posits that behavior is preceded by intention, with intention in turn determined by an individual's attitude toward the behavior (positive or negative) along with subjective norms, e.g. whether the behavior is seen as appropriate in context or socially acceptable.
Azjen's related Theory of Planned Behavior [3] added a third determinant of behavior intention, the individual's perception of behavioral control; he also noted the importance of actual behavioral control in moderating intention and perceived control, as no one can act if they are not able to do.
Venkatesh incorporated these factors in his work with Davis and others to update the TAM as the Unified Theory of the Acceptance and Use of Technology [71,72].
Based on this literature on user behaviors, we incorporated measures of other concepts beyond attitude that we theorized would relate with it, such as privacy, self-efficacy and internet know-how, and also individual measures by which SA-6 would be expected to vary, such as past experience of security breaches, age, and socioeconomic status.
The current state of the art for quantifying users' thinking about security practices is the Security Behavior Intentions Scale [32,33] (SeBIS).
Its asks about intended user behavior in four areas: device securement, updates, password management, and proactive awareness.
SeBIS is not worded as a traditional intention survey -instead of "I intend" statements, it measures intention by asking respondents for their frequency from "Never" to "Always" of such active statements as "I use a password/passcode to unlock my laptop or tablet" -but it has been extensively validated [32,64] and cited by other usable security researchers [31,60].
Its short length makes it practical to include in a larger survey or battery of psychological tests, or to administer during a lab experiment.However, SeBIS is not a measure of attitudes.
Its 16 items are not designed to measure a user's beliefs or emotions about the included behaviors, nor to indicate whether they are attuned to social or situational norms around the behaviors.
They do not measure the extent to which the user has the requisite awareness, perceived ability or relevant knowledge to perform the behavior.
We see a need for a complementary self-report measure that more directly gets at people's security attitudes underlying their intentions and behavior.
We also see a need for a measure that is not tied to technology-specific language, so that the measure retains validity as the security technology changes.
We believe a new psychometric scale for assessing a person's attitudes toward expert-recommended tools and practices will be a net benefit to the usable security field and to humanity.
While the potential for abuse of such technologies has become recently prominent [40], we have also noted the significant impact to world events from human lapses in cybersecurity judgment [55,79].
SA-6 can help researchers and practitioners to design products in good faith that strengthen resilience to attacks.
In developing our self-report attitude measure, we relied on the guidance provided by sources such as A common best practice in psychometric scale development is to generate a long list of possible statements that could measure the underlying construct, in order to increase the chances of developing a sufficiently reliable and valid scale [28,39,46,53].
We generated 200+ items to be rated on a 5-point Likert-type agreement scale (1=Strongly disagree, 5=Strongly agree).
We based the wordings of these items primarily in empirical research by Das et al., but also borrowed some wordings from SeBIS, from other work in usable security and psychology [1,15,16,27,29,41,45,58,66] and from our experiences.
We conducted multiple rounds of review of these items, first with experts in usable security who checked the items for content adequacy, then with several nonexperts in security research, whose feedback was used to ensure the survey protocol was clear, unambiguous and easily understandable, in line with common best practices and [28,39,46,53].
These reviews pared our list of items to 60 for online testing.
Another best practice for scale development is to collect variables that are thought to relate with or to vary with the construct, to test if they relate with and vary with the scale to a similar extent [28,39,46,53].
We used the Theory of Reasoned Action [37] as our guide to which constructs we should include measures of in our survey instrument so that we could test for our scale's degree of associations and variances with these constructs.
We referred to prior work such as [32,33] for identifying measures for need for cognition [14], consideration of future consequences [68], risk perception and risk taking [11], and impulsiveness [67].
We incorporated measures of internet and technical knowhow [48], computer confidence [38], and web-oriented digital literacy [44], along with general and social selfefficacy [66] and the "Big Five" personality factors [42].
We included two measures of privacy concerns [13,51], a subjective norm strongly related to security beliefs [50,54].
To help test for expected variances in security sensitivity, we asked participants the extent to which they, or someone close to them, had been a victim of a security breach, as well as how much they had heard or read about security breaches during the past year.
See Section 12.1 for the list of measures included in this report.Our questionnaire was piloted on Amazon Mechanical Turk with three Masters-qualified workers.
Each provided their feedback and suggestions for improving the survey experience via an open-ended text box added at the end.
The pilot survey designs ranged between 18 and 24 pages in length as we experimented with how best to break the items among pages and provide clear instructions on each page.
The survey was structured to front-load the most important questions, namely the candidate items and the SeBIS questions, because of concern for answers being affected by response fatigue due to the survey length.
After the third iteration received entirely positive feedback from a Masters worker, we submitted a formal modification to our Institutional Research Board for review of our survey and research design and exemption from human subjects regulation under U.S. 45 CFR 46.
A third best practice for scale development is to collect an initial batch of data to determine which candidate scale items meet minimum standards for response variance and for factor and reliability statistics [28,39,46,53].
We administered 60 candidate items on five pages of 12 items each, along with 16 pages of measures theorized to relate to our survey, in a first round of MTurk research in November-December 2017.
We advertised this as a "Survey on attitudes & behaviors among computer users (~30 minutes)" and requested U.S. residents age 18 or older.
Using a base rate of $10/hour and a median pilot duration of 24 minutes, we compensated participants with $5 per survey.
The survey used one openended item asking participants to either mention other security measures they use or to write "None"; this was partly included as a check on attention (if left blank) and fraudulent responses (if nonsensical).
As a precaution against workers taking the survey more than once under different IDs, we removed all but one response from an IP address and/or specific location.We performed an exploratory factor analysis (EFA) and reliability analysis on the N = 196 completed and valid responses.
After finding smaller-than-desired variance in some response distributions and in the alpha and total variance explained by items with high factor loadings, we decided to retain just 18 items without changes.
We The next stage of scale development was to collect a sufficient number of responses from which to narrow the list of items to those that most clearly measured the security sensitivity construct [28,39,46,53].
To this end, in JulyAugust 2018, we collected a third dataset on MTurk and a fourth dataset in a university-run online study pool, using very similar recruitment language and the same participant compensation as in Section 4.3.
A chi-square analysis found that these datasets did not differ significantly by gender: X^2(1, N = 475) =2.95, p = n.s.
We conducted 10 pairwise comparisons of the datasets by age range, first correcting for possible compounded Type I error by conducting a Bonferroni procedure that adjusted alpha to p <.005.
We did not find any pairwise comparisons by age to be statistically significant: overall X^2(4, N=478)=11.42, p = n.s. See Section 12.3 for chi-square statistics for age-level pairwise comparisons and for the pairwise comparisons by levels of education, income and breach-experience measures.Based on the lack of significant differences by age or gender, we merged these to form one sample of N=479.
This ensured a 5:1-to-10:1 ratio of observations to items for finalizing the scale, as recommended by [39,46,53].
See Table 1 for descriptive statistics for this sample.We conducted a series of factor analyses and reliability assessment to identify the number of possible factors from scree plots and factor loadings; which factors explained at least 40% total variance in the sample and eigenvalues over 1.0; and which of these factors met a threshold Cronbach's alpha of .70.
Finally, we tested the goodness-of-fit of each candidate factor structure by conducting a confirmatory factor analysis (CFA) to calculate fit statistics that are appropriate for a large sample [47]: the Comparative Fit Index (CFI), for which an acceptable fit is above .90 and a superior fit above .95, and the Standardized Root Mean Square Residual (SRMR), which should be below .08.
We chose the first factor, which explained 64% of the sample variance with 6 items loading over 0.71 on this factor.
These six items had a Cronbach's alpha equal to .88, demonstrating excellent internal reliability (well above the threshold of .70); and a CFI of 0.96 and SRMR of 0.03, demonstrating superior model fit.
Section 12.4 displays the six item histograms, factor loadings and alpha if item deleted.
To test the reliability and validity of SA-6 outside of the MTurk and university study populations, we repeated our study in September 2018 with a U.S. Census-tailored panel filled by Qualtrics (N=209).
We again targeted compensation at $5 per response, however this was not handled by us directly; Qualtrics worked with its third-party providers to provide sufficient payment in forms such as reward points.We dropped survey measures that were less central to this report, reordered items so that the demographics questions were asked first to fill the survey quotas, added a question about employment status, and (beyond the open-ended item noted in Section 4.3) added a second attention check: "We use this question to discard the answers of people who are not reading the questions.
Please select "51% to 75% of the time" (option 4) to preserve your answers."
The panel received a sufficient number of responses in all variable categories to complete the statistical picture for this report.See Table 1 for descriptive statistics for this sample.As before, we examined the items' statistical properties and confirmed the factor structure in this smaller sample.
SA-6 was found to explain 56% of total sample variance, with a Cronbach's alpha of .84, a CFI of 0.91, and an SRMR of 0.05.
Table 2 displays the six item histograms, factor loadings and statistics for Cronbach's alpha if item deleted for SA-6.
These demonstrate SA-6's solid factor structure, internal consistency and goodness of fit.
In the Census-tailored sample (n=209), we conducted a series of correlations and independent-samples t-tests to assess the degree to which security attitudes as measured by SA-6 converged with measures thought to relate with it (convergent validity) and varied as expected by categorical measures (discriminant validity), consistent with the Theory of Reasoned Action [37].
These tests support that the scale is measuring the concept that it claims to measure.
We excluded some collected variables from validity tests because they did not meet a Cronbach's alpha of .70, which indicates they may include higher-than-acceptable random measurement error.
Section 12.5 reports the Cronbach's alpha values for each observed measure.
To examine convergent validity of SA-6, we first tested its statistical association with SeBIS, the field's standard selfreport measure of security behavior intention.
We did this because attitude is a direct antecedent of behavior intention in the Theory of Reasoned Action [37].
Using a Spearman correlation, we found SA-6 to be significantly positively associated with SeBIS (r =.54, p < .01).
Using linear regression, we found that SA-6 explained 28% of the variance in SeBIS (p<.01).
This result is consistent with longstanding psychological evidence of the relationship between attitudes and behavior intention [5,7,8,37,69,75] and demonstrates SA-6's convergent validity.
To further examine the convergent validity of SA-6, we looked at its statistical association with measures of perceived behavioral control, perceived norms (chiefly privacy) and individual cognitive and risk styles.
We collected and tested these measures because these were used in validity testing for SeBIS [32][33][34] since they represent closely associated concepts.
These concepts are also components of the Theory of Reasoned Action [37].
We found expected significant associations among SA-6 and psychological indicators of perceived behavioral control We found a significant association of SA-6 with the "Big Five" personality factor of Extraversion (r=.175, p<.05).
We included the Big 5 because personality is a background component of the Theory of Reasoned Action [37].
We found an expected significant positive correlation with the Kang Internet Know-How scale (r=.542, p<.01) and with two related scales, one for confidence in using computers (r=.280, p<.01) and the other for web-oriented digital literacy (r=.503, p<.01).
We included these measures because information, skill and ability are key components of the Theory of Reasoned Action [37].
To examine discriminant validity, we tested whether SA-6 varied significantly as a function of personal experiences of and media exposure to security breaches, and by age, gender and socioeconomic status.
We included these measures because social and informational measures are antecedents of attitude in the Theory of Reasoned Action [37] and previous work has found a connection between demographics and security concern [50,54].
For each type of experience with security breaches, we recoded the 5-level variable responses into 2 levels (low experience (1-2) vs. high experience (3-5)) and conducted independent-samples t-tests on the census-weighted sample.
This analysis let us look at how SA-6 varied for people with low versus high levels of experience with security breaches (see Table 3 for a summary).
SA-6 was significantly higher for participants with higher self-reported frequency of participants falling victim to a security breach, higher selfreported frequency of their close friends or relatives falling victim.
and by the amount they had heard or seen about security breaches in the past year.For demographics, we found a statistically significant difference in SA-6 by age group and gender, with a higher score for older participants and men.
SA-6 scores were also higher for participants who attended college and those whose yearly household income exceeded the 2018 U.S. poverty level of $25,100 for a family of four [80].
These differences correspond with differences observed in other studies on cybersecurity opinions and knowledge [50,54].
We did not find a significant difference in SA-6 by citizenship or employment status, with the exception of "Employed fulltime" (M=3.85, SD=.75) vs. "Unemployed looking for work" (M=3.24, SD=.76, F(6,202)=2.59, p<.05).
We were able to go one step further than the authors of SeBIS and ask respondents whether, in the past week, they had at least once taken an expert-recommended action for device securement, updating, password management or proactive awareness.
The item wordings were drawn from those of SeBIS in those areas, with a response set of "Yes/No/Not Sure/NA" and these instructions: "For the following statements, please select the response that best represents your recall of what actions you have taken in the past week.
Please select "I'm not sure" if you don't know the answer.
Please select "NA" if the statement does not apply to you."
We excluded NA responses from the item-level analysis.
We recoded the remaining 3-level variable responses into 2 levels (Yes (1) vs. No or Not Sure (2-3)) and conducted independent-samples t-tests on the census-weighted sample.
This analysis let us look at how SA-6 varied for people who did vs. did not recall performing these certain SeBIS-derived security actions.
We found SA-6 to vary significantly by the answers to all but one item.
This further demonstrates discriminant validity.
See Table 4 for item statistics.We then conducted a series of binary logistic regressions to compare predicted outcomes by (a) models that combined SA-6 with SeBIS as predictors, (b) models using SeBIS without SA-6 as a predictor, and (c) models using only a constant as a predictor (to indicate baseline performance without SeBIS).
Results indicated that there was a significant association among SA-6, SeBIS and item responses.
This improved the performance of models for three items: "In the past week, I have downloaded and installed at least one available update for my computer's operating system within 24 hours of receiving a notification that it was available" (X^2 (2) The pseudo R-squared value generated with logistic regressions cannot be said, as with a linear regression Rsquared value, to show the variance accounted for by the model.
In order to use a linear regression model to calculate this variance explained, we transformed the recalled security action items into one interval variable by computing an average of the scores of the nine items that were found to vary significantly by their SA-6 score.
The Cronbach's alpha for this compound measure was .77, comfortably above the threshold of .70 we used to exclude measures from validity tests.
When we combined SA-6 with SeBIS as a predictor in this model, SA-6 lifted its ability to explain the variance in this compound measure from 23.5% to 24.3% (p<.001, r=.493).
A Spearman correlation also found significant associations (SA-6 with recalled security actions: r=.398, p<.001; SeBIS with recalled security actions: r=.541, p<.001).
These statistics suggest that SeBIS is a partial mediator of SA-6's influence on the recalled security actions measure, as predicted by the Theory of Reasoned Action's model of attitude helping to determine behavior through the mediation of intention [37].
Our careful scale development process gives us confidence that SA-6 has demonstrated construct validity, internal consistency and reliability, goodness-of-fit, and convergent and discriminative validity.
We conducted several tests of our generated items to determine which were most suitable for our scale, then visually inspected the response distributions and conducted factor and reliability analyses to determine which mix of items are the best fit for a short selfreport measure of security attitudes.
We found SA-6 to correlate as expected with privacy and other theorized concepts such as self-efficacy, and to vary by factors such as exposure to breaches and demographics.
Fifteenth Symposium on Usable Privacy and Security 67 SA-6 will be useful to researchers and practitioners who need a reliable and valid method to systematically assess and compare user attitudes about the use and adoption of expertrecommended security tools and practices.
SA-6 is easily administered via an online questionnaire in a web browser or on paper, and it also is shorter than measures such as the 31-item Personal Data Attitude measure for adaptive cybersecurity [2] [52,62] and for pre-and post-study evaluations in cybersecurity education research [19].
An open question in psychology is the degree to which attitude, intention and other factors directly determine behavior.
Sutton's 1998 meta-analyses [69] showed that TRA and TPB explain on average between 40% and 50% of intention variance, with the rest accounted for by changes in factors such as volitional control and random variance.
And Webb and Sheeran's 2006 meta-analyses [75] showed that across 47 experiments, a medium-to-large change in intention (d=0.66) led to a small-to-medium change in behavior (d=0.36).
They conclude that "intentional control of behavior is a great deal more limited than previous metaanalyses of correlational studies have indicated.
"Sutton notes a relevant distinction in this context between explanation and prediction.
In his framing, explanation is a process of identifying what determines intentions and behavior and seeking how such factors combine, while prediction enables the targeting of interventions in spite of not understanding the full degree and nature of a behavior's determinants.
An example Sutton gives of the latter is identification of people at high risk of developing a drinking problem, arguing that, despite not having a clear model of which factors combine to influence alcohol addiction, it is still a benefit to create predictive models of alcoholism risk in order to target an early intervention.
Nevertheless, he writes, a causal model that sheds light on what factors influence drinking in certain individuals may make it possible to extend the predictive model to similar problems and to avoid a "one size fits all" solution that can better target interventions by differing nature and content.Similarly, our results suggest to us that even given the moderate r values shown in our correlation analyses, SA-6 is likely to add valuable predictive weight with SeBIS in computational modeling of who is likely to act on security recommendations and who is open to changing their security behavior.
We see both scales as useful for future research into the degree to which security sensitivity along with security behavior intention can explain which architecture choices or "nudges", as suggested by Egelman & Peer In the past week, I have downloaded and installed at least one available update for my computer's operating system within 24 hours of receiving a notification that it was available.3.95 0.73 3.40 0.75 5.11**** 189 8.6In the past week, I have left my laptop or desktop computer unlocked at least once when I walked away from it.3.49 0.81 3.84 0.70 2.95*** 184 11.0In the past week, I have submitted information to a website at least once without first verifying that it would be sent securely.
[34,35], and Redmiles et al.[59] might best improve security choices by users with specific attitude and intention profiles, thus helping the field move beyond a blanket approach to interventions.
We also are pursuing work to compare SA-6 with two other scales we are developing to measure users' concernedness with and resistance to changing their security behaviors, as part of a new causal model and framework.
We see utility for SA-6 in measuring a user's readiness for educational interventions.
Broadly, SA-6 identifies whether the user is a good candidate for interventions of two types:(1) to raise awareness of the general need for using expertrecommended tools and practices (low SA-6) or (2) to add to users' knowledge of how to use recommended tools and practices (high SA-6).
An example of the first type of intervention might be playing a security awareness game, while an example of the second type would be taking part in a tutorial on creating strong but memorable passwords.Conversely, we see SeBIS as offering specific utility in measuring a user's readiness for motivational interventions that (3) move them into the intention stage (low SeBIS) or (4) move them from intention into action and reinforce action (high SeBIS).
An example of this third type of intervention would be a positive incentive program, such as rewards for 3, 15 and 30 days of consecutive use of a third-party password manager.
An example of the fourth type would be reminders to act, such as context-aware notifications of a newly available software update, or negative incentives for nonaction, such as progressively annoying or persistent notifications for a software update that a user fails to install.
Our project was conducted with U.S.-based populations age 18 or older using a lengthy, English-language, online questionnaire.
More research will be needed to find support for SA-6's reliability and validity in populations of computer users outside the U.S. and/or when translated into other languages.
The ability to generalize our results inside the U.S. is limited by our use of purposive, nonrandom sampling of the subpopulation of online survey-takers.
Our use of online surveys as the only method of questionnaire administration may also have introduced common method bias, suggesting the need also to test the survey in other modes such as written and telephone versions.All correlational research is inherently unable to prove causation.
This work is only the first step toward finding support for a relationship among the variables in our study.
Experimental research will be needed to investigate the hypothesis that changes in security sensitivity will lead to changes in security behavior intention and, ultimately, to changes in actual security behavior by end users.
Additionally, we did not test for measurement noninvariance, which limits SA-6's usefulness for comparing groups.
Finally, some items in SeBIS and in the SeBIS-derived items in Table 4 are out of step with current security recommendations (e.g., many experts now advise against forcing users to periodically change their passwords) and features in consumer systems (e.g., many updates can now be downloaded and installed automatically).
This limits the usefulness of SeBIS and these SeBIS-derived items for accurately measuring security intention and recalled actions.However, we believe that SA-6 is a valid way to measure security attitudes for future studies and experiments relevant to cybersecurity.
We are pursuing a second work that will allow for a side-by-side discussion of this scale with two others in development and provide support for a causal model and framework for targeting security interventions.
In this paper, we introduce and validate SA-6, a self-report measure of end-user security attitudes.
Using principles of psychological scale development, we generated and finalized six items that (a) correspond to prior work on their face; that (b) pilot testers found to be unambiguous and easily answered; that (c) demonstrated sufficient response variance, and that (d) were found in factor and reliability analyses to demonstrate desired psychometric properties.Via analyses of data from a U.S. Census-tailored survey panel, we found SA-6 to be significantly associated with a self-report measure of behavior intention and to exhibit expected variances by participants' recollections of recent security actions.
We found SA-6 significantly associated with other measures of cognition and with measures of subjective norms, chiefly privacy, and perceived behavioral control, such as self-efficacy and internet know-how.
Our scale is a lightweight tool for researchers and practitioners to (1) quantify and compare end users' attitudes toward using recommended security tools and practices, and (2) improve predictive modeling of who will adopt such behaviors.
The field of usable security will benefit from this systematic method for assessing a user's awareness, motivation, and knowledge of expert-recommended tools and practices.
We hope our work helps improve understanding of end-user compliance with security recommendations and the identification of users who are susceptible to attacks and open to changing their behaviors.
This research was sponsored by the U.S. National Science Foundation under grant no.
CNS-1704087.
We thank Sauvik Das for his feedback on early versions of this scale, Maria Tomprou for her advice about statistical analysis and framing, and Geoff Kaufman and members of the CoEx Lab and CHIMPS Lab at CMU for helping us to think through the many iterations of this research and analysis.We also thank our CHI and SOUPS reviewers for their thoughtful critiques, which improved this research paper.
12.1.
The following is the selected list of n=48 candidate items for SA-6 (chosen items are shaded), along with the sources of the items.
These were deployed in questionnaires on Amazon Mechanical Turk, the university-run study pool and to the Qualtrics U.S. Census-tailored panel.
A security breach, if one occurs, is not likely to cause significant harm to my online identity or accounts.
[1,20,21,23]Generally, I am aware of existing security threats.
[20][21][22][23] Generally, I am willing to spend money to use security measures that counteract the threats that are relevant to me.
[ 21,45] Generally, I care about security and privacy threats.
[20][21][22][23] Generally, I diligently follow a routine about security practices.
[author generated]Generally, I know how to figure out if an email was sent by a scam artist.
[20]Generally, I know how to use security measures to counteract the threats that are relevant to me.
[20-23]Generally, I know which security threats are relevant to me.
[20][21][22][23] Generally, I want to use measures that can counteract security and privacy threats.
[ [20][21][22][23] I always pay attention to experts' advice about the steps I need to take to keep my online data and accounts safe.
[15,21] I always trust experts' recommendations about security measures (such as using unique passwords or a password manager, installing recommended software updates, etc.).
[15,21] I am confident that I am taking the necessary steps to keep my online data and accounts safe.
[20-23]I am confident that I can change my security behaviors, if needed, to protect myself against threats (such as phishing, computer viruses, identity theft, password hacking) that are a danger to my online data and accounts.
[76]I am confident that I could change my security behaviors if I decided to.
[76] I am extremely knowledgeable about all the steps needed to keep my online data and accounts safe.
[20][21][22][23] I am extremely knowledgeable about how to take the necessary steps to keep my online data and accounts safe.
[20-23] I am extremely knowledgeable about which security threats (such as phishing, computer viruses, malware, password hacking) are a danger to my online data and accounts.
[20-23] I am extremely motivated to take all the steps needed to keep my online data and accounts safe.
[20-23] I am extremely well aware of existing security threats (such as phishing, computer viruses, identity theft, password hacking).
[20-23] I am extremely well aware of the necessary steps that I can take to counteract security threats (such as phishing, computer viruses, identity theft, password hacking).
[20-23]I am too busy to put in the effort needed to change my security behaviors.
[ 21,29] I care very much about the issue of security threats (such as phishing, computer viruses, identity theft, password hacking).
[20][21][22][23] I dread that using recommended security measures will backfire on me (such as forgetting a needed password, updated software becoming unusable, etc.).
[21,45] I feel guilty when I do not use recommended security measures (such as by reusing passwords, putting off software updates, etc.).
[21]I generally am aware of existing security measures that I can use to counteract security threats.
[20-23]I generally am aware of methods to send email or text messages that can't be spied on.
[20][21][22][23] I have much bigger problems than my risk of a security breach.
[ 21,29] I need to change my security behaviors to improve my protection against security threats (such as phishing, computer viruses, identity theft, password hacking).
[20,76]I often am interested in articles about security threats.
[24] I seek out opportunities to learn about security measures that are relevant to me.
[21]I usually will not use security measures if they are inconvenient.
[20-23] I usually will not use security measures unless I am forced to.
[20][21][22][23] I want to change my security behaviors in order to keep my online data and accounts safe.
[20,76] I want to change my security behaviors to improve my protection against threats (such as phishing, computer viruses, identity theft, password hacking) that are a danger to my online data and accounts.
[20,76] I worry that I'm not doing enough to protect myself against threats (such as phishing, computer viruses, identity theft, password hacking) that are a danger to my online data and accounts.
[20,62] It is a lost cause to take all the steps needed to keep my online data and accounts safe.
[author generated]It is important for me to change my security behaviors to improve my protection against security threats (such as phishing, computer viruses, identity theft, password hacking).
[20,76]It is not possible for me to do more than I already am to counteract security threats (such as phishing, computer viruses, identity theft, password hacking) that are a danger to my online data and accounts.
[author generated]It's a sign of paranoia to use numerous security measures to protect against threats.
[ 21,41] It's a sign of paranoia to use recommended security measures (such as using unique passwords or a password manager, installing recommended software updates, etc.).
[ 21,41] My current lapses in using security measures are harmless.
[1,21] My own actions can make a significant difference in keeping my online data and accounts safe.
[10]Oftentimes, as soon as I discover a security problem, I report it to someone who can fix it.
[33]Oftentimes, I am running on "automatic pilot" when I sift through my email and text messages.
[author generated]Oftentimes, I will check that my anti-virus software has been regularly updating itself.
[33]The exposure of my online data and accounts in a security incident, if one occurs, would be a significant problem for me.
[author generated]The theft of my online data or accounts in a security breach, if one occurs, would be a significant problem for me.
[author generated]There are good reasons why I do not take the necessary steps to keep my online data and accounts safe.
[21] The following The following table contains the chi-square statistics for all of the education-level pairwise comparisons (1=Some high school, 2=High school degree or equivalent, 3=Some college, technical degree or associate's degree, 4=Bachelor's degree, 5=Graduate or professional degree; adj. p <.005).
Some pairwise comparisons were statistically significant, with the sample from the university-run study pool skewing toward higher levels of educational attainment.
Fifteenth Symposium on Usable Privacy and Security 77 r Principal Component Analysis -Factor Loading
