We revisit the problem of performing secure computation of graph-parallel algorithms, focusing on the applications of securely outsourcing matrix factorization, and histograms.
Leveraging recent results in low-communication secure multi-party computation, and a security relaxation that allows the computation servers to learn some differentially private leakage about user inputs, we construct a new protocol that reduces overall runtime by 320X, reduces the number of AES calls by 750X, and reduces the total communication by 200X.
Our system can securely compute histograms over 300 million items in about 4 minutes, and it can perform sparse matrix factorization, which is commonly used in recommendation systems, on 20 million records in about 6 minutes.
1 Furthermore , in contrast to prior work, our system is secure against a malicious adversary that corrupts one of the computing servers.
Instances of data breach and exfiltration continue to occur in great number.
Secure computation offers an appealing avenue for defense.
This cryptographic tool allows user data to be secret-shared across multiple computational servers, ensuring that the breach of any single server provides no information to an adversary, while still enabling the servers to perform arbitrary computation on the data.
As compared with standard encryption, which provides security only while the data remains at rest, secure computation allows the data to remain secure throughout its life-cycle, from the moment it is uploaded by the user, through its incorporation into some statistic or learned model.The theory of secure computation has been studied since the 1980's, and a rich literature has given rise to a line of practical work that has focused on reducing concrete costs to a near minimum.
Of course, there are no free lunches, and computing on secret-shared data will always require increased communication and computation when compared with the cost of computing on plaintext data.
However, several recent research directions have helped narrow the gap between secure data processing and plaintext computations.Low communication MPC.
Several results in secure computation have recently minimized the communication requirements by restricting the number of computing servers to three [2,4,17] or four [10], and assuming an honest majority of the servers.
When representing the computation as an arithmetic circuit over a ring (as we will do here), the cheapest of these results, by Gordon et al. [10], requires sending only 1.5 ring elements per party, per circuit gate.
In contrast, the best two-party protocol requires 290 bytes per party, per Boolean gate [22], and the best honest-majority protocol (supporting arbitrary numbers of parties) requires 12 field elements per party, per gate [4].
Parallelizing secure computation.
Nayak et al. [18] propose a framework for securely computing graph parallel algorithms.
In such algorithms, the data is assumed to reside in a graph structure, and the result of the computation is reached through an iterative process in which a) the data is gathered from all edges to their neighboring nodes, b) a simple computation is applied on the data at each node, and c) the processed data is scattered back to the neighboring edges before the processes are repeated.
Such frameworks have become very popular for plaintext computations on large amounts of data, because the Apply phase can be easily distributed among many processors, making parallelization straight-forward [6,9,13,14].
In this work we implement gradient descent, yielding a secure protocol for sparse matrix factorization (commonly used in recommendation systems), as well as histograms.
Graph parallel frameworks are also used for PageRank, Markov random field parameter learning, parallelized Gibbs samplers, name entity resolution, and many other computations.Allowing differentially private leakage.
Very recently, researchers have explored the idea of relaxing security to al- 29th USENIX Security Symposium 2487 low leakage in secure computation, coupled with a bound demonstrating that the leakage preserves differential privacy [3,12,16,20].
Mazloom and Gordon [16] demonstrated a protocol for computing graph parallel algorithms with differentially private leakage, shaving a log E factor off of the fully secure protocol of Nayak et al., where E is the number of edges in the graph.Securely outsourcing computation.
These advances have introduced an opportunity for several applications of secure computation in which user data from thousands of parties are secret shared among a few servers (usually three) to perform a secure computation on their behalf.
Multiple variants of this application have now been deployed.
In some cases, users have already entrusted their data, in the clear, to a single entity, which then wishes to safeguard against data breach; secret sharing the data among several servers, each with a unique software stack, helps diversify the risk of exposure.
In other cases, users were unwilling, or were even forbidden by law, to entrust their data to any single entity, and the use of secure computation was essential to gaining their participation in the computation.
In many of these cases, the servers executing the secure computation are owned and operated by a single entity that is trusted for the time being, but may be corrupted by an outside party.
In other cases, some data were entrusted to one entity, while other data, from another set of users, were entrusted to a second entity, and these two distrusting parties wish to join in a shared computation.The common denominator in all of these variants is that the computation servers are distinct from the data owners.
In this context, the relaxation allowing these servers to learn some small, statistical information about the data may be quite reasonable, as long as the impact to any individual data contributor can be bounded.
For example, when computing a histogram of the populations in each U.S. zip code, the servers see only a noisy count for each zip code, gaining little information about the place of residence of any individual data contributor.
In the context of securely performing matrix factorization for use in a recommendation system, we allow the servers to learn a noisy count of the number of items that each contributing user has reviewed.
Even when combined with arbitrary external data, this limits the servers from gaining any certainty about the existence of a link between any given user and any given item in the system.Our reliance on a fourth server in the computation introduces a tradeoff between security and efficiency, when compared with the more common reliance on three servers.
2 It is almost certainly easier for an adversary to corrupt two out of four servers than it is to corrupt two out of three.
However, as our results demonstrate, the use of a fourth server enables far faster computation, which, for large-scale applications, might 2 From a purely logistical standpoint, we do not envision that this requirement will add much complexity.
The additional server(s) can simply be run in one or more public clouds.
In some cases, as already mentioned, all servers are anyway run by a single entity, so adding a fourth server may be trivial.
make the use of secure computation far more feasible than it was previously.Results.
In this work, we revisit secure computation of graph parallel algorithms, simultaneously leveraging all three of the advances just described: we assume four computation servers (with an honest majority, and one malicious corruption), allow differentially private leakage during computation, and, exploiting the parallelism that this affords, we construct an MPC protocol that can perform at national scales.
Concretely, we compute histograms on 300 million inputs in 4.17 minutes, and we perform sparse matrix factorization, which is used in recommendation systems, on 20 million inputs in under 6 minutes.
These problems have broad, real-world applications, and, at this scale, we could imagine supporting the Census Bureau, or a large company such as Amazon.
For comparison, the largest experiments in GraphSC [18] and OblivGraph [16] had 1M inputs, and required 13 hours and 2 hours of runtime, respectively, while using 4 times the number of processors that we employ, and tolerating only semi-honest corruptions.
End-to-end, our construction is 320X faster than OblivGraph, the faster of these 2 systems.Technical contributions.
Merging the four-party protocol of Gordon et al. [10] with the construction of Mazloom and Gordon [16] raises several challenges and opportunities:Fixed point arithmetic.
There are few results in the MPC literature that support fixed point computation with malicious security.
The most efficient that we know of is the work by Mohassel and Rindal, which uses replicated sharing in the three party, honest majority setting [17], modifying the protocol of Furakawa et al. [7].
Their construction requires each party then sends 8 ring elements for each multiplication without truncation.
The parties execute two subtraction circuits in pre-processing phase for each truncation.
The pre-processing costs each party at least 21 · (2k − d) bits for each truncation where k is the size of the ring, and d the length of the fraction bits.
With a bit of care, we show that we can extend the fourparty protocol of Gordon et al. [10] to handle fixed point arithmetic, without any additional overhead, requiring each party to send just 1.5 ring elements for each multiplication.
This provides about a 20X improvement in communication over Mohassel and Rindal.
The protocol of Gordon et al. proceeds through a dual execution of masked circuit evaluation: for circuit wire i carrying value w i , one pair of parties holds w i + λ i , while the other holds w i + λ i , where λ i , λ i are random mask values known to the opposite pair.
To ensure that nobody has cheated in the execution, the two pairs of parties compute and compare w i + λ i + λ i .
This already supports computation over an arbitrary ring, with malicious security.
However, if w i is a fractional value, the two random masks may result in different rounded values, causing the comparisons to fail.
We show how to handle rounding errors securely, allowing us to leverage the efficiency of this protocol for fixed point computation.Four party, linear-time, oblivious shuffle.
The experimental results of Mazloom and Gordon have complexity O(V α + E) log(V α+E), where α = α(ε, δ) is a function of the desired privacy parameters, E is the number of edges in the graph, and V is the number of nodes.
The authors also show how to improve the asymptotic complexity to O(V α + E), removing the log factor by replacing a circuit for performing an oblivious shuffle of the data with a linear-time oblivious shuffle.
They don't leverage this improvement in their experimental results, because it seems to require encrypting and decrypting the data inside a secure computation.
(Additionally, for malicious security, it would require expensive zero-knowledge proofs.)
Operating in the 4-party setting allows us to construct a highly efficient, linear-time protocol for oblivious shuffle.
One of the challenges we face in constructing this shuffle protocol is that we have to authenticate the values before shuffling, and verify correctness of the values after shuffling, and because we are committed to computing over elements from Z 2 k , we need to authenticate ring values.
Recently, Cramer et al. [5] proposed a mechanism for supporting arithmetic circuits over finite rings by constructing authentication in an "extension ring": to compute in Z 2 k , they sample α ← Z 2 s , and use a secret-sharing of αx ∈ Z 2 k+s for authentication.
We adopt their construction in our shuffle protocol to ensure the integrity of the data during shuffling.One of the benefits of using 4 parties is that we can separate the operations between two groups of parties, such that one group, for example Alice and Bob, is responsible for accessing the data during Gather and Scatter, while the other group, Charlotte and David, performs the shuffling.
In contrast, in the 2-party setting, if one party knows the shuffling permutation, then the other party must access each data element in a manner that hides the data index.
This seemingly requires using a short decryption key inside the secure computation, rather than a more efficient, 2-party secret sharing scheme.
On the other hand, if neither party knows the shuffling permutation, we need to use a permutation network incurring the additional log overhead.
When comparing our four-party, maliciously secure, oblivious shuffling protocol with the semi-honest construction of Mazloom and Gordon, they require 540X more AES calls and 140X communication than we do.
Computation over a ring.
Both the work of Nayak et al. [18] and Mazloom and Gordon [16] use Boolean circuits throughout the computation.
Boolean circuits are a sensible choice when using sorting and shuffling circuits, which require bit comparisons.
Additionally, as just discussed, Boolean circuits provide immediate support for fixed point computation, removing one further barrier.
However, for the Apply phase, where, for example, we compute vector gradients, computation in a ring (or field) is far more efficient.
With the introduction of our four-party shuffle, which is not circuit-based, and after modifying Gordon et al. [10] to support fixed-point computation, there is no longer any reason to support computation on Boolean values.
We construct a method for securely converting the shared, and authenticated values used in our shuffle protocol into the "masked" ring values required for our four-party computation of the Apply phase.
For the problem of Matrix Factorization on dataset of 1 million ratings, the Apply phase of Mazloom and Gordon [16] requires 550X more AES calls and 370X more bandwidth than ours.
The Graph-parallel abstraction as it is used in several frameworks such as MapReduce [6], GraphLab [13] and PowerGraph [9], consists of a sparse graph that encodes computation as vertex-programs that run in parallel, and interact along edges in the graph.
These frameworks all follow the same computational model, called the GAS model, which includes three conceptual phases: Gather, Apply, and Scatter.
The framework is quite general, and captures computations such as gradient descent, which is used in matrix factorization for recommendation systems, as well as histograms or counting operation, and many other computations.
In Matrix Factorization, as an example, an edge (u, v, data) indicates that user u reviewed item v, and the data stored on the edge contains the value of the user's review.
The computation proceeds in iterations, and in each iteration, every node gathers (copy) data from their incoming edges, applies some computation to the data, and then scatters (copy) the result to their outgoing edges.
Viewing each vertex as a CPU or by assigning multiple vertices to each CPU, the apply phase which computes the main functionality, is easily parallelized.
[18,19] constructed frameworks for securely computing graph-parallel algorithms.
They did this by designing a nicely parallelizable circuit for the gather and scatter phases.
The security definition for secure computation is built around the notion of protocol simulation in an ideal world execution [8].
In the ideal world, a trusted functionality takes the inputs, performs the agreed upon computation, and returns the result.
We say the protocol is secure if a simulator can simulate the adversary's protocol view in this ideal world, drawing from a distribution that is indistinguishable from the adversary's view in the real world execution.
The simulator can interact with the adversary, but is otherwise given nothing but the output computed by the ideal functionality.
3 In prior work, Mazloom and Gordon [16] proposed a relaxation to this definition in which the simulator is additionally given the output of some leakage function, L, applied to all inputs, but L is proven to preserve differential privacy of the input.
They define several varying security models.
Here we focus on one variant, which supports more efficient protocol design.
We assume that thousands of clients have secret shared their inputs with 4 computation servers, and we use E to denote the full set of inputs.
We denote the set of secret shares received by server i as E i .
We denote the input of party j as e j .
Note that the servers learn the input size of each client.
Formally, the security definition is as follows.Definition 1 [16] Let F be some functionality, and let π be an interactive protocol for computing F , while making calls to an ideal functionality G. π is said to securely compute F in the G-hybrid model with L leakage, known input sizes, and (κ, ε, δ)-security if L is (ε, δ)-differentially private, and, for every PPT, malicious, non-uniform adversary A corrupting a party in the G-hybrid model, there exists a PPT, non-uniform adversary S corrupting the same party in the ideal model, such that, on any valid input shares,E 1 , E 2 , E 3 , E 4 HYBRID G π,A(z) (E 1 , E 2 , E 3 , E 4 , κ) z∈{0,1} * ,κ∈N c ≡ IDEAL F ,S (z,L(V ),∀ j:|e j |) (E 1 , E 2 , E 3 , E 4 , κ) z∈{0,1} * ,κ∈N(1)Mazloom and Gordon construct a protocol for securely performing graph-parallel computations with differentially private leakage.
In their protocol, the data is secret shared throughout each iteration: when the Apply phase is executed at each graph node, it is computed securely on secret shared data, with both input and output in the form of secret shares.
The leakage is purely in the form of access patterns to memory: as data moves from edge to neighboring node and back again, during the Gather and Scatter phases, the protocol allows some information to leak about the structure of the graph.
To minimize and bound this leakage, two additional actions are taken: 1) The edges are obliviously shuffled in between when the data is gathered at the left vertex, and when it is gathered at the right vertex.
This breaks the connections between the left and right neighboring nodes, and reduces the graph structure leakage to a simple degree count of each node.
2) "Dummy" edges are created at the beginning of the protocol, and shuffled in with the real edges.
These dummy edges ensure that the degree counts are noisy.
When the dummy edges are sampled from an appropriate distribution, the leakage can be shown to preserve differential privacy.
Note that when the input size of each party is known, the degree count of certain nodes may not need to be hidden, allowing for better performance.
For example, if the data elements owned by user u are weighted edges of the form (u, v, data), it is essential that the degree of node v remain private, as its degree leaks the edge structure of the graph, but the degree of node u is implied by the input size of user u.
The implications of this are discussed more fully in their work.
Neighboring graphs: We represent multi-sets over a set V by a |V | dimensional vector of natural numbers: D ∈ N |V | .
We refer to the ith element of this vector by D(i).
We define a metric on these multi-sets in the natural way:|D 1 − D 2 | = ∑ |V | i=1 |D 1 (i) − D 2 (i)|.
Applying this to graphs, for each v ∈ V , we let in−deg(v) denote the in-degree of node v, and we define the indegree profile of a graph G as the multi-set D in (G) = {in−deg(v 1 ), . . . , in−deg(v n )}.
Then, we have the following definition.Definition 2 We say two graphs G and G have distance at most d if they have in-degree profiles of distance at most d:| D in (G) − D in (G ) |≤ d.We say that G and G are neighboring if they have distance 1.
Definition 3 A randomized algorithm L : G → R L is (ε, δ)- edge private if for all neighboring graphs, G 1 , G 2 ∈ G, we have: Pr[L(G 1 ) ∈ T ] ≤ e ε Pr[L(G 2 ) ∈ T ] + δ We use the secure computation protocol by Gordon et al. for four parties, tolerating one malicious corruption [10].
We provide an overview of the construction here.
The four parties are split into two groups, and each group will perform an evaluation of the circuit to be computed.
The invariant throughout each evaluation is that both evaluating parties hold x + λ x and y + λ y , where x and y are inputs to a circuit gate, and λ x , λ y are random mask values from the ring.
After communicating, both parties hold z + λ z , where z is the result of evaluating the gate on x and y, and λ z is another uniformly chosen mask.To maintain this invariant, the evaluating parties need secret shares of λ x , λ y , λ x λ y and λ z .
Securely generating these shares in the face of malicious behavior is typically quite expensive, but, relying on the assumption that only one party is corrupt, it becomes quite simple.
Each pair of parties generates the shares for the other pair, and, to ensure that the shares are correctly formed, the pair sends duplicates to each recipient: if any party does not receive identical copies of their shares, they simply abort the protocol.
During the evaluation of the circuit, it is possible for a cheating party to perform an incorrect multiplication, violating the invariant.
To prevent this, the two pairs securely compare their evaluations against one another.
For wire value z, one pair should hold z + λ z , and the other should hold z + λ z .
Since the first pair knows λ z and the second pair knows λ z , each pair can compute z + λ z + λ z .
They compare these values with the other pair, verifying equality.
Some subtleties arise in reducing the communication in this comparison; we allow the interested reader to read the original result.
Additive Shares: We denote the 2-out-of-2 additive shares of a value x between two parties P 1 and P 2 to be [x] 1 and [x] 2 ,and between two parties P 3 and P 4 to be [x] [x] i to denote the share of x held by the i th party.
Additive secret shares are used in all steps of the graph computation model except for the Apply phase.
In Apply phase, data is converted from additive secret shares to masked values and back.3 and [x] 4 (x = [x] 1 + [x] 2 = [x] 3 + [x] 4 ).
When it is clear, we use [x] instead ofFunction inputs Our protocol includes many function calls in which P 1 and P 2 either provide additive shares of some input, or they each provide duplicates of the same input.
The same is true for P 3 and P 4 .
We therefore denote inputs to functionalities and protocols as a pair: the first element denotes the input of P 1 and P 2 , and the second denotes that of P 3 and P 4 .
When P 1 and P 2 each provide an additive share of some value E, we simply denote the input by [E].
For example, the input to F MAC is denoted by (( [X], α), [X]): P 1 and P 2 submit additive shares of X, and each separately provide a copy of α.
P 3 and P 4 provide a different additive sharing of X. Masked Values: For a value x ∈ Z 2 k , its masked value is defined as m x ≡ x +λ x , where λ x ∈ Z 2 k+s is sampled uniformly at random.
In our four party computation model, for a value x, P 1 and P 2 hold the same masked value x + λ x and P 3 and P 4 hold the same x + λ x .
λ x is provided by P 3 and P 4 while P 1 and P 2 hold shares of λ x .
Similarly, λx is provided by P 1 and P 2 while P 3 and P 4 hold shares of λ x .
Doubly Masked Values: Four players can locally compute the same doubly masked value for x from their masked values, defined asd x ≡ x + λ x + λ x = m x + λ x = m x + λ x .
Share or Masked Value of a Vector: When X is a vector of data, i.e,X = {x 1 , ..., x n }, we define [X] ≡ {[x 1 ], ..., [x n ]}, λ X ≡ {λ x 1 , ..., λ x n }, m X ≡ {m x 1 , ..., m x n } and d X ≡ {d x 1 , ..., d x n }.
Fixed Point Representation: All inputs, intermediate values, and outputs are k-bit fixed-point numbers, in which the least d significant bits are used for the fractional part.
We represent a fixed-point number x by using a ring element in Z 2 k+s , where s denotes our statistical security parameter.MAC Representation: We adapt the technique used in SPDZ2k [5] for authenticating ring elements.
For a value x ∈ Z 2 k and for a MAC key α ∈ Z 2 s , the MAC on value x is defined asMAC α (x) ≡ αx ∈ Z 2 k+s .
In our framework, MAC α (x)is always kept in the form of additive secret shares.
4 We note that in our framework, all the values, the additive shares, and the masked values are represented as elements in the ring Z 2 k+s .
However, the range of the data is in Z 2 k , and the MAC key is in Z 2 s .
In this section, we explain the details of each small component and building block in graph operations, present their real vs. ideal world functionalities, and provide the security proofs for each of them, under a single malicious corruption.
We partition the 4 parties into 2 groups, with the first consisting of P 1 and P 2 , and the second P 3 and P 4 .
For ease of explanation, we name the parties in the first group, Alice and Bob, and parties in the second group, Charlotte and David.
One of the main challenges we face in constructing a malicious secure version of the graph operations is that we have to authenticate the values before each operation begins, and then verify correctness of the results after the operation is done.
This is simple in a Field, but we choose to compute in a ring to help support fixed point operations.
We adapt the MAC computation and Verification technique proposed in SPDZ2k [5].
In this part, we describe the ideal functionality and the real world protocol to generate MAC values for additive secret shares over a ring.FUNCTIONALITY F MAC Inputs: P 1 , P 2 : [X] = {[x 1 ], . . . , [x n ]}, MAC key α.
P 3 , P 4 : [X].
Functionality: 4 .
If the check does not pass, send abort to all parties.
• Verify that X = [X] 1 + [X] 2 = [X] 3 + [X]• If P 1 , P 2 submit different values of α, send abort to all parties.
• Compute Y = αX.Outputs: P 1 , P 2 receive nothing.P 3 , P 4 receive [Y ].
Theorem 1 The MAC computation protocol Π MAC ( Figure 2) securely realizes the ideal functionality F MAC (Figure 1) with abort, under a single malicious corruption.
We construct a method for securely converting the shared, authenticated values which was used in the Shuffle and Gather phases, into the "masked" ring values required for our fourparty computation of the Apply phase.
The share-mask conversion protocol (Figure 4) securely realizes the ideal functionality F sharemask (F [x]→m x ) ( Figure 3) with abort, under a single malicious corruption.Π sharemask (Π [x]→m x ) 29th USENIX Security Symposium 2491PROTOCOL Π MAC Inputs: P 1 , P 2 : [X], MAC key α.
P 3 , P 4 : [X].
F is a PRF.
Protocol:1.
P 1 , P 2 sample a random PRF key k, by making a call to F coin .2.
P 1 sends [Y (1) ] = {α[X i ] + F k (i)|i = 1, ..., n} to P 3 .
3.
P 2 sends [Y (1) ] = {α[X i ] − F k (i)|i = 1, ..., n} to P 4 .4.
Four parties make a call to F mult (α, [X] 3,4 ).
P 3 , P 4 receive [α] and [Y ] ← [αX].
P 1 , P 2 receive nothing.
5.
P 3 , P 4 compute [Z] = [Y −Y (1) ]and verify Z = 0 by making a call to F checkZero ( [Z]).
If the functionality returns false, they send abort to P 1 and P 2 and terminate.Outputs: P 1 , P 2 output nothing.P 3 , P 4 output [Y ].
Figure 2: MAC computation protocolFUNCTIONALITY F sharemask (F [x]→m x )Inputs:P 1 , P 2 : [β], [X], [Y ](Y ≡ βX).
P 3 , P 4 : β.
Functionality:• Reconstruct β, X, and Y from P 1 and P 2 .
Verify that P 3 and P 4 have sent shares of the same β.
• Verify that Y = βX.
If the check fails, send abort to all parties.
• Sample shares [λ X ] 1 , [λ X ] 2 , [λ X ] 1 , [λ X ] 2 uniformly at random, then reconstruct λ X and λ X .
• Compute m X = X + λ X and m X = X + λ X .
Outputs: P 1 receive (m X , λ X , [λ X ] 1 ), P 2 (m X , λ X , [λ X ] 2 ) P 3 receive (m X , λ X , [λ X ] 3 ), P 4 (m X , λ X , [λ X ] 4 ).
At the end of the Apply phase, the result of the 4-party computation is masked values that need to be converted back to additive shares, before updating the edges.
This conversion step is very simple.
Each party locally converts their masked values to additive shares, without any interaction: givenx + λ x and [λ x ], simply output [x] = x + λ x − [λ x ].
This section presents the small sub-components that are utilized in the Apply operation. ]
= [X] + [λ X ], [m X ] = [X] + [λ X ], [Y ] ← [Y ] + [β]λ X (where λ X = [λ X ] 1 + [λ X ] 2b = false, they call abort.
Else, if b = true, they open m X ← open([m X ]).
9.
All parties compute d X = m X + λ X = m X + λ X , P 1 and P 3 compare h 1 = H(d X )with each other, while P 2 and P 4 compare h 2 = H(d X ) with each other.
If any group sees a mismatch, they call abort.
Masked value: In our protocol, we use masked values for the computation.
Instead of holding shares [x], one group hasOutputs: P 1 , P 2 output m X , [λ X ], λ X .
P 3 , P 4 output m X , [λ X ], λ X .
(m x = x + λ x , λ x , [λ x ])and the other has (mx = x + λ x , λ x , [λ x ]).
Addition: Addition is performed locally by adding the masked values together.For P 1 and Locally P 1 and P 2 computeP 2 : (m x , λ x , [λ x ]) + (m y , λ y , [λ y ]) = (m x + m y , λ x + λ y , [λ x ] + [λ y ]).
For P 3 and P 4 : (m x , λ x , [λ x ]) + (m y , λ y , [λ y ]) = (m x + m y , λ x + λ y , [λ x ] + [λ y ]).
P 1 : [m z ] 1 = m x m y − [λ x ]m y − [λ y ]m x + [λ z + λ x λ y ].
P 2 : [m z ] 2 = −[λ x ]m y − [λ y ]m x + [λ z + λ x λ y ].
and exchange the shares to reconstruct m z = xy + λ z .
Theyoutput (m z , λ z , [λ z ]).
Similarly, P 3 and P 4 output (m z , λ z , [λ z ]).
Multiplication With Truncation: In our setting, x and y are fixed-point numbers with d bits for the fraction.
The result of the multiplication is a number that has its least 2d significant bits in the fractional portion.
A truncation is needed to throw away the d least significant bits: the output of the multiplication is the masked value of the truncation of xy in stead of that of xy.
We provide a method to handle the truncation for our four-party mask evaluation.
First, we have a simple observation: if z, λ z , λ z are integers, the following holds:z+λ z +λ z 2 d = z+λ z 2 d + λ z 2 d + ε 1 = z 2 d + λ z 2 d + λ z 2 d + ε 1 + ε 2 , where ε i ∈ {0, 1}.
For z ∈ Z 2 k , trun(z) = z 2 d , if 0 ≤ z ≤ 2 t 2 k − 2 k −z 2 d , if 2 k − 2 t ≤ z < 2 k Assume that −2 t ≤ xy < 2 tis the domain where xy lies in.
We have two different cases.First, we consider the case of a non-negative xy, which is represented by a ring element z = xy in the range [0; 2 t ].
The above equation works without any modifications when (z + λ z ) and (z + λ z ) are both less than 2 k .
This happens with probability of at least 1 − 2 t−k+1 (we note that 2 t 2 k ).
Second, we consider the case of a negative xy.
A negative xy is represented by a ring element z = 2 k − |xy| in the range[2 k −2 t ; 2 k −1].
With probability of at least 1−2 t−k+1 , both λ z and λ z will be chosen such that (z+λ z ) ≥ 2 k and (z+λ z ) ≥ 2 k , causing modular reduction in our computation.
Specifically, for group 1, P 1 and P 2 hold z + λ z − 2 k = z + λ z mod 2 k , λ z and can compute the following in the integer domain:(z+λ z mod 2 k )+λ z 2 d = (z+λ z −2 k )+λ z 2 d = (z−2 k )+λ z +λ z 2 d .
= − 2 k −z 2 d + λ z 2 d + λ z 2 d + ε, where ε ∈ {0, 2} Let m z = (2 k − 2 k −z 2 d + ε) + λ z 2 d = (z+λ z mod 2 k )+λ z 2 d - λ z 2 d mod 2 k and m z = (2 k − 2 k −z 2 d + ε) + λ z 2 d = (z+λ z mod 2 k )+λ z 2 d -λ z 2 d mod 2 k .
They are the masked value of the truncation of xy for group 1 and 2 respectively.
P 1 and P 2 can compute m z and λ z 2 d themselves without any interaction as they know xy + λ z and λ z .
P 3 and P 4 can provide P 1 and P 2 with shares[ λ z 2 d ].
At the end, P 1 and P 2 obtain the output of the truncated mask evaluation:(m z , λ z 2 d , [ λ z 2 d ]).
Similarly, P 3 and P 4 obtain (m z , λ z 2 d , [ λ z 2 d ]).
The error of the truncated multiplication is at most 1 2 d−1 .
Importantly, the error does not impact proper cross-checking of the two parallel evaluations.Vectorization for dot products A naive way to perform a dot product between two vectors u = {u 1 , ..., u n }, v = {v 1 , ..., v n } is to perform n multiplications then add the shares up.
We use the vectorization technique to bring this down to the cost of one multiplication.
The details are shown in Figure 6.
Communication cost Each multiplication with truncation requires the four parties to communicate only 6 rings in total when done in batch.
For each gate, F triple costs 2 rings (one ring sent from P 3 to P 2 , and the other from P 1 to P 4 ) and the opening of m c and m c each costs 2 rings.
F coin is free when common random seeds are used, and two hashes are needed to be sent for the whole batch.
We note that the cost is the same for dot product gate.
Inputs: For each input wire w:P 1 , P 2 : m w = x w + λ w , [λ w ], λ w ; P 3 , P 4 : m w = x w + λ w , [λ w ], λ w .
Functionality:• Reconstruct λ received from P 1 , P 2 , and verify if it is equal to λ received from P 3 , P 4 .
Reconstruct λ received from P 3 , P 4 , and verify if it is equal to λ received from P 1 , P 2 .
If any of these verification fails, send abort to all parties.
• Compute-(m (1) w , λ(1)w , [λ (1) w ]) ← f unc (m w , λ w , [λ w ]) -(m(1)w , λ(1)w , [λ (1) w ]) ← f unc (m w , λ w , [λ w ])Outputs: P 1 , P 2 receive (m (1) w , λ(1)w , [λ (1) w ]).
P 3 , P 4 receive (m (1) w , λ (1) w , [λ (1) w ]).
Our construction follows the graph-parallel computation model in which the computation is done using three main operations; Gather, Apply and Scatter.
We partition the players into two groups, and in each group, there are two players.
For ease of explanation, we name the parties in the first group Alice and Bob (P 1 , P 2 ), and parties in the second group, Charlotte and David (P 3 , P 4 ).
These parties collaboratively compute a functionality, for example Matrix Factorization.
During the computation, each group is responsible for performing an operation that its results then will be verified by the other group.
For example, one group securely shuffles the data, and the other group verifies that the data is not maliciously tampered, then the latter group performs the operations that access the data (e.g., gather), and then the former group verifies the correctness of that operation.
As described previously, each data access operation, Gather or Scatter, is always followed by a Shuffle operation, in order to hide the graph edge m w = x w + λ w , λ w , [λ w ].
Evaluation: For each gate (a, b, c, T ) following topological order: Evaluation Group 1 (P 1 and P 2 )1.
if T = + : m c ← m a + m b ; [λ c ] ← [λ a ] + [λ b ]; λ c ← λ a + λ b 2.
if T = · (Dot Product/Multiplication Gate) (a) ( ∑ n i=1 λ a i λ b i + λ c , λ c /2 d ) ← F Triple (a, b, c); (b) [m c ] ← ∑ n i=1 (m a i · m b i − m a i · [λ b i ] − m b i · [λ a i ]) + ∑ n i=1 λ a i · λ b i + λ c (c) m c ← open([m c ]); m c ← (m c + λ c )/2 d − λ c /2 d ; λ c ← λ c /2 d ; [λ c ] ← λ c /2 dEvaluation Group 2 (P 3 and P 4 )1.
if T = + : m c ← m a + m b ; [λ c ] ← [λ a ] + [λ b ]; λ c ← λ a + λ b 2.
if T = · (Dot Product/Multiplication Gate) (a) ( ∑ n i=1 λ a i λ b i + λ c , λ c /2 d ) ← F Triple (a, b, c); (b) [m c ] ← ∑ n i=1 (m a i · m b i − m a i · [λ b i ] − m b i · [λ a i ]) + ∑ n i=1 λ a i · λ b i + λ c (c) m c ← open([m c ]); m c ← (m c + λ c )/2 d − λ c /2 d ; λ c ← λ c /2 d ; [λ c ] ← λ c /2 dCross Check1.
All parties make a call to F coin to sample the same random nonce r, compute the double masked value for each wired w = m w + λ w = m w + λ w .
They each computes h i ← hash(d 1 ||...||d n ||r).
2.
P 1 sends h 1 to P 2 and P 4 .
P 3 sends h 3 to P 2 and P 4 .
3.
P 2 verifies that h 1 = h 3 .
If true, he sends 0 to F or a functionality, else he sends 1.
P 4 does the same thing when verifying h 1 = h 3 .4.
Repeat the previous instructions with the variable exchanged as follows, P 2 sends h 2 to P 1 and P 3 , and P 4 sends h 4 to P 1 and P 3 .5.
P 1 and P 3 separately verify they received same values from P 2 and P 4 , and provide input to the F or functionality, accordingly.
6.
All the parties will receive the result from F or in order to determine to continue or to abort.Output: All parties output masked values of the output wires.
P 1 , P 2 output (m (1) V , λ(1)V , [λ (1) V ]).
P 3 , P 4 output (m (1) V , λ(1)V , [λ (1) V ]).
Data Structure: In our framework, the data is represented in a graph structure G = (V, E), in which vertices contain user and item profiles, and edges represent the relation between connected vertices.
Each edge, represented as E, has five main elements, (E.l id , E.r id , E.l data , E.r data , E.isReal), where isReal indicates if an edge is "real" or "dummy".
Each vertex, V, contains two main elements, (V id , V data ).
The V data storage is large enough to hold aggregated edge data from multiple adjacent edges during the gather operation.Dummy Generation: Before the main protocol begins, a number of dummy edges will be generated according to an appropriate distribution, and concatenated to the list of real edges, in order to provide (ε, δ)-Differential Privacy.
Therefore, the input to the framework is a concatenated list of real and dummy edges, and list of vertices.
The circuit for generating these dummies, together with the noise distribution, is taken directly from the work of Mazloom and Gordon, so we do not describe it again here.
The cost of this execution is very small relative to the rest of the protocol, and it is only performed once at the beginning of the any computation, regardless of how many iterations the computation has (both the histogram and the matrix factorization computations require only one dummy generation operation).
These dummy edges are marked with a (secret shared) flag isReal, indicating that dummies should not influence the computation during the Apply phase.
However, they still have node identifiers, so they contribute to the number of memory accesses to these nodes during the Gather and Scatter phases.
The protocol we use Step 0.
Input preparation: We assume the input data is additively secret-shared between parties in each group, so that parties in each group, together can reconstruct the data.
For example, Alice and Bob receive 2-out-of-2 secret shares of E, such that [E] A + [E] B = E mod 2 k+s , as shown in Figure 7.
Step Step 2.
Oblivious Gather: The next operation after Shuffle is the Gather operation, which requires access to the node identifiers, and will be handled by Alice and Bob.
In turn, Charlotte and David should be able to verify the correctness of the Gather operation.
Therefore, before the Gather operation, Charlotte and David agree on a random value β, and all parties make a sequence of calls to the F MAC functionality, generating a new MAC tag for each data element of each edge.
That is, they create three tags per edge: one tag for each of the two vertex ids, and one tag for the edge data.
The Gather operation is performed on only one side of each edge at a time; in one iteration of the protocol, data is gathered at all of the left vertices, and in the next iteration, it is gathered at all of the right vertices.
Gather for the left vertices is described in Figure 13: for each edge, Alice and Bob first reconstruct the id of the left vertex E.l id , locate the corresponding vertex, and then append the data of the other end of the edge, i.e. the data of the right vertex, [E.r data ] with its MAC tags, to the left vertex data storage.
They do the same for all the incoming edges to that vertex.
Note that in the next iteration of the algorithm they follow the same procedure for the right vertex, if applicable.
When Alice and Bob access the left side of each edge, they learn the number of times each left vertex is accessed, which leaks the degree of each vertex in the graph.
However, due to the dummy edges that we shuffled-in with the real ones, what they learn is the noisy degree of each vertex, which preserve deferential privacy.
At the end of this phase, Charlotte and David verify that Gather was executed correctly by calling F checkZero , verifying that the data was unmodified.They abort if the verification fails.
We note that, in addition to modifying data, a malicious adversary might try to move data to the wrong vertex.
From a security standpoint, this is equivalent to the case that the adversary moves data to the correct vertex during Gather, but modifies the shares of the authenticated identifier.
To simplify the analysis, we assume that the adversary moves data to the correct vertex.Step 3.
Oblivious Apply: This operation consists of three sub-operations.
First, additive shares of data are converted to masked values, then the main functionality (e.g. gradient descent) is applied on the masked values (at each vertex), and finally the masked values are converted back to additive secret-shares, which then will be used in the following phases of the framework.Step 3.1.
Secure Share-Mask Conversion: All the parties participate in the Apply phase, providing their shares as input to the Arithmetic Circuit that computes the intended functionality.
However, in order to prepare the private data for the Apply operation, the secret-shared values need to be transformed into "masked" values.
In order to convert shares to masked values, each group agrees on a vector of random mask values, denoted as λ for Alice-Bob and λ for Charlotte-David.
Then they call the F sharemask functionality and collaboratively transform the share values [V ] to masked values V + λ and V + λ .
Step 3.2.
Computing the function of interest on input data: As part of the Apply phase, the parties compute the function of interest on the input data: for example, they perform addition for Histograms, or gradient descent for Matrix Factorization.
The parties execute the four-party protocol described in Figure 6 to evaluate the relevant circuit.Step 3.3.
Secure Mask-Share Conversion: At the end of the Apply phase, data is in the masked format and needed to be converted to secret-shared values.
As described previously, each party can locally convert their masked values to additive secret-shares, without interacting with other parties.Step 4.
Oblivious Scatter: The result of each computation resides inside the corresponding vertex.
We need to update the data on the edges with the freshly computed data.
In this step, all players copy the updated data from the vertex to the incoming (or outgoing) edges.
The players refer to the list of opened ID's obtained during Gather to decide how to update each edge.
Recall, edges are held as additive secret shares; the update of the edge data can be done locally.
Finally, they re-randomize all the shares.
This explanation and accompanying diagrams only show the graph operations applied on the left vertices of each edge.
To complete one round of the graph computation, we need to repeat the steps 1-4 on the right vertices as well.
The hybrid world protocol is presented in Figure 9.
There we assume access to ideal functionalities for Shuffle, Gather, Apply and Scatter.
In this section, we explain how we instantiate each of these ideal functionalities, and provide the security proofs for each protocol under a single malicious corruption.
Charlotte, David hold secret shares of E, such that[E] C + [E] D = E mod 2 k+s .
([E] A , [E] B , [E] C , [E] D ∈ Z 2 k+s, and E ∈ Z 2 k ).
1.
Waits for input from all parties.
[E] A + [E] B = [E] C + [E] D .
If not, sendsabort to all parties.3.
Reconstructs E, then computes E (1) = f unc(E).4.
Secret shares E (1) to P 1 , P 2 ; and E (1) to P 3 , P 4 .5.
Computes the leakage L(G), sends it to all parties.Output: Secret shares of the updated edge values (e.g. user and item profiles).
The parties also obtain the leakage L(G).
The Shuffle operation is used to hide the edge structure of the graph: during the Gather and Scatter operations, the vertex on each side of an edge is accessed, and shuffling the edges between these two phases hides the connection between Π sgas : Four-Party Secure Graph Parallel Computation ProtocolInput: User input is a directed graph, G(E,V ), secret shared between the parties: Alice, Bob hold secret shares of E, s.t. for each edge,[E] A + [E] B = E mod 2 k+s .
Charlotte, David hold secret shares of E, s.t. for each edge, [E] C + [E] D = E mod 2 k+s .
([E] A , [E] B , [E] C , [E] D ∈ Z 2 k+s , and E ∈ Z 2 k ).
Note: The following steps are conducted on the left vertex of each edge (for example in computing Histogram).
In order to perform one single iteration of Matrix Factorization, these steps should be done twice, once on the left vertices, then on the right vertices.1.
Oblivious Shuffle Four players make a call to to aggregate edge data into vertices.
Alice, Bob receive: [V ] = [{V 1 1 .
.
V 1 i }, ..., {V n 1 .
.
V n j }], [W ] = [{W 1 1 .
.
W 1 i }, ..., {W n 1 .
.
W n j }],Inputs:P 1 , P 2 : [E] (s.t. [E] 1 + [E] 2 = E).
P 3 , P 4 : [E] (s.t. [E] 3 + [E] 4 = E).
Functionality: 4 .
If the check fails, send abort to all parties.
• Verify that [E] 1 + [E] 2 = [E] 3 + [E]• Sample a random permutation π.
Figure 10: Oblivious Shuffle Ideal Functionality the security of our Oblivious Shuffle, we provide a simulation for P 1 and P 3 .
The simulations for other parties are identical.
First, a simulation for P 1 :• S receives P 1 's input [E] 1 from the distinguisher and places it in the input tape of P 1 .
• α: S samples a random α and hands it to P 1 to simulate the output from F coin .
S then observes the message that P 1 sends to F MAC : if P 1 does not send the intended messages ( α, [E] 1 ), S submits abort to F shuffle , and outputs the partial transcript.
Else, S submits P 1 's input [E] 1 to the ideal functionality F shuffle and receives [E (1) ].
• [ E (1) ], [ M (1) ]: S samples random ring elements as shares[ M (1) ], hands [ E (1) ] (where [ E (1) ] ≡ [E 1 ])and [ M (1) ] to P 1 to simulate the messages [E (1) ], [M (1) ] P 1 receives from F MAC .
S computes [Z] himself to mirror P 1 's action.
• b: S observes the messages that P 1 sends to F checkZero .
If P 1 modifies his shares [Z], S hands b = false to P 1 as the output of F CheckZero , outputs the partial view, and aborts.Else, S hands b = true to P 1 and outputs whatever P 1 outputs.Claim 1 For the simulator S corrupting party P 1 as described above, and interacting with the functionality F shuffle ,HYBRID π shuffle ,A(z) (E, κ) z∈{0,1} * ,κ∈N c ≡ IDEAL F shuffle ,S(z) (E, κ) z∈{0,1} * ,κ∈NCase 0: If the adversary behaves honestly, the joint distributions in the hybrid and ideal executions are: In conclusion, the joint distributions between the two worlds are identical.
Now, a simulation for P 3 :HYBRID π shuffle ,A(z) (E, κ) z∈{0,1} * ,κ∈N = {α, [E (1) ], [M (1) ], b = true, o 1 , o 2 , o 3 , o 4 } IDEAL F shuffle ,S(z) (E, κ) z∈{0,1} * ,κ∈N = { α, [ E (1) ], [ M (1) ], b = true, o 1 , o 2 , o 3 , o 4 }• [ M]: S receives [E] 3 and places it in the input tape of P 3 .
S observes the message that P 3 sends to F MAC : if P 3 modifies [E] 3 before sending it to the functionality, S aborts and outputs the partial view.
Else, S samples random ring elements as shares [ M] 3 and hands them to P 3 to simulate the output P 3 receives from F MAC in the hybrid world.
• π: S queries the ideal functionality with P 3 's input, [E] 3 , and obtains the output [E (1) ] 3 .
S computes π such that [E (1) ] 3 ← π( [E] 3 ), then agrees on the permutation π with P 3 in Step 3 (playing the part of P 4 ).
S computes [m (1) ] ← [ π( m)] to mirror P 3 's action.
• b: S observes the messages that P 3 sends to P 1 in Step 3.
If P 3 sends [E (1) ] 3 = [E (1) ] 3 +D or [m (1) ] = [m (1) ] 3 +Dwhere D = 0 mod 2 k , D = 0 mod 2 k+s , S aborts and outputs the partial view.
Else, S outputs whatever P 3 outputs.Claim 2 For the simulator S corrupting party P 3 as described above, and interacting with the functionality F shuffle ,HYBRID π shuffle ,A(z) (E, κ) z∈{0,1} * ,κ∈N c ≡ IDEAL F shuffle ,S(z) (E, κ) z∈{0,1} * ,κ∈NCase 0: If P 3 follows the protocol honestly, the joint distributions in the hybrid and ideal execution is:HYBRID π shuffle ,A(z) (E, κ) z∈{0,1} * ,κ∈N = {[M], π, b, o 1 , o 2 , o 3 , o 4 } IDEAL F shuffle ,S(z) (E, κ) z∈{0,1} * ,κ∈N = {[ M], π, b, o 1 , o 2 , o 3 , o 4 }The messages [M], [ M] and π, π are all distributed uniformly at random, and independently from the remainder of the view, including the joint distribution over the output shares.
The output distribution is identical in both worlds as well.
Thus, the joint distributions between both worlds are identical.Case 1: If P 3 deviates from the protocol in Step 2 by sending the wrong shares of [E], abort happens in both worlds, and the joint distributions in both worlds are both {⊥} and identical.Case 2: S observes what P 3 sends to P 1 in Step 3.
If he does not send the intended messages:P 3 sends [E (1) ] = [E (1) + D] or [M (1) ] = [M (1) + D ] where D = 0 mod 2 k , D = 0 mod 2 k+s , S abort in the ideal execution.
The joint distribu- tion in the ideal world is {[ M], π, b = false, ⊥}.
In the hybrid world, there is a small chance that P 1 and P 2 do not abort.
This happens if P 3 chooses the additive terms D and D such that αD + D = 0 mod 2 k+s .
The probability that this happens is at most 2 −s as shown in Section 3.1.
So, with probability 1 − 2 −s , the joint distribution in the hybrid world is { [M], [π], b = false, ⊥}.
Thus, the joint distributions in both worlds are statistically close.In conclusion, the joint distributions in both worlds are statistically close.
Gather operation aggregates the data from neighboring edges to each vertex.
The data will be stored at the vertices for further computation handled by Apply operation.
Inputs:P 1 ,P 2 : [E] (s.t. [E] 1 + [E] 2 = E).
P 3 , P 4 : [E] (s.t. [E] 3 + [E] 4 = E).
Functionality:• Sample a random MAC key β.
• Wait for shares [E] from all parties.
Verify that [E] 1 + [E] 2 = [E] 3 +[E] 4 .
If the verification fails, send abort to all parties.
Else, reconstruct E.• For all vertices v ∈ V , set v ← / 0.
• For each edge e ∈ E do:For v ∈ V s.t. v.id = l id : v.Append(e.r data )• Compute W ← βV .
[β].
P 3 , P 4 receive β.Outputs: P 1 , P 2 receive [{V 1 1 .
.
V 1 i }, ..., {V n 1 .
.
V n j }] , [{W 1 1 .
.
W 1 i }, ..., {W n 1 .
.
W n j }], Theorem 5 The Oblivious Gather protocol ( Figure 13) securely realizes the ideal functionality F gather (Figure 12) with abort, under a single malicious corruption.
Apply computes the main functionality of the framework on the input data.
In the Gather operation, the data is aggregated into vertices, therefore Apply runs the computation on the vertex data.
The oblivious Apply protocol Π apply (Figure 15) securely realizes the ideal functionality F apply (Figure 14) with abort, under a single malicious corruption.
During the Scatter operation, the updated data in the vertices are pushed back to their corresponding edges in the graph, replacing the old values stored in the edges.
This step is done locally by each party, P 1 and P 2 , with no interaction between them.
Therefore, this step is secure.
After updating the edges, the shares are re-randomized to break the correlation between the edges (edges with the same left (or right) id are updated with the same shares during scattering phase.
If any of the parties cheats and modifies the data before scattering to the edges, it will be detected in the following phase, which is the Shuffle operation of the next round.
Inputs:P 1 , P 2 : [{V 1 1 .
.
V 1 i }, ..., {V n 1 .
.
V n j }], [{W 1 1 .
.
W 1 i }, ..., {W n 1 .
.
W n j }], [β].
P 3 , P 4 : β.
Functionality:• Verify that β[V ] = [W ].
If the verification fails, send abort to all parties.
Else, reconstruct V.•For v ∈ [{V 1 1 .
.
V 1 i }, ..., {V n 1 .
.
V n j }]:Compute v (1) ← f unc(v).
Note: f unc is the computation applied on the data, e.g. computing Gradient Decent for Matrix Factorization or Addition in Histogram algorithm.Output: All parties receive:[{V (1) 1 1 .
.
V (1) 1 i }, ..., {V (1) n 1 .
.
V (1) n j }].
In this section, we formally define our overall framework in a hybrid-world model.
But first, we define the leakage function L(G) to be the noisy degree of each vertex in the graph, as was done by Mazloom and Gordon [15] (Definition 7).
That is, in the ideal world, after receiving secret shares of the graph description, the functionality creates an array containing the to masked values.
•P 1 , P 2 use input [{V 1 1 .
.
V 1 i }, ..., {V n 1 .
.
V n j }] , [{W 1 1 .
.
W 1 i }, ..., {W n 1 .
.
W n j }], [β] ).
P 3 , P 4 use input β.
• For each vertex, P 1 ,P 2 receive (m V , λ V , [λ V ]).
P 3 , P 4 receive (m V , λ V , [λ V ]).
For v ∈ [{V 1 1 .
.
V 1 i }, ..., {V n 1 .
.
V n j }]:Four parties execute F eval ( Figure 5), to obtain the masked values of the updated vertex data.
4.
Secure Mask-Share Conversion Each party locally converts their masked values to additive shares.
• P 1 andP 2 computes [V ] ← (V + λ V ) − [λ V ], • P 3 and P 4 computes [V ] ← (V + λ V ) − [λ V ].
Output: All parties output:[{V(1) 1 1 .
.
V (1) 1 i }, ..., {V (1) n 1 .
.
V (1) n j }].
Figure 15: Protocol for securely computing Apply.vertex degrees.
It then generates an equal length array of integer noise values, each independently sampled from some appropriate distribution.
5 The functionality perturbs the vertex degrees by adding the two arrays, and returns the result to the simulator.
Mazloom and Gordon describe a particular distribution that is easy to sample inside a secure computation, and prove that it provides differential privacy.
We use the same one in our experiments.Theorem 7 ( [16]) The randomized algorithm L is (ε, δ)- approximate differentially private.Theorem 8 The protocol Π sgas (Figure 9) securely computes the ideal functionality F sgas (Figure 8) with L leakage in the (F shuffle , F gather , F apply , F scatter )-hybrid model with abort, under a single malicious corruption.
We implemented our four-party secure computation framework in C++.
The source code is available at https://github.com/sama730/National-Scale-Secure-ParallelComputation.
We measure the performance of our framework on a set of benchmark algorithms in order to evaluate our design.
These benchmarks consist of the histogram and matrix factorization problems, which are commonly used for evaluating highly-parallelizable frameworks.
In all scenarios, we assume that the data is secret-shared across four non-colluding cloud providers, as motivated in Section 1.
We compare our results with the closest large-scale secure parallel graph computation schemes, such as GraphSC [18] and OblivGraph [16].
In our four-party framework, the histogram and matrix factorization problems can be represented as directed bipartite graphs.Histogram: In the histogram computation, which for example can be used to count the number of people in each zip code, left vertices represent data elements (people), right vertices are the counters for each type of data element (the zip code), and existence of an edge indicates that data element on the left has the data type of the right node (e.g. the user on the left belong to the zip code on the right).
Matrix Factorization: In matrix factorization, left vertices represent users, right vertices are items (e.g. movies in movie recommendation systems or a product in targeted advertising systems), an edge indicates that a user ranked that item, and the weight of the edge represents the rating value.
Vertex and Edge representation: In all scenarios, our statistical security parameter s = 40.
We choose k = 40 to represent k-bit fixed-point numbers, in which the least d significant bits are used for the fractional part.
For histogram d = 0 and for matrix factorization d = 20.
This requires data and MACs to be secret shared in the Z 2 80 ring.
In our matrix factorization experiments, we factorize the ratings matrix into two matrices, represented by feature vectors that each has dimension 10.
We choose these parameters as to be compatible with the GraphSC and OblivGraph representations.
We run the Histogram experiments on graphs with sizes ranging from 1 million to more than 300 million edges, which can simulate the counting operation in census data gathering [1].
For example, if each user contributed a salary value and a zip-code, using our framework we can compute the average salary in each zip-code, while ensuring that the access patterns preserve user privacy.
We run matrix factorization with gradient descent on the real-world MovieLens datasets [11] that contains user ratings on movies.
We report the result for one complete iteration of the protocol, performing GAS operations one time on both the left and right nodes.
The results are the average of five executions of the experiments.Experiment settings: We run all the experiments on AWS (Amazon Web Services) using four r4.8xlarge instances, each has 32 processors and 244 GiB RAM, with 10 Gbps network connectivity.
For the LAN experiments, all instances were in the same data center (Northern Virginia).
For the WAN experiments, they were spread across Northern Virginia (P 1 and P 4 ) and Oregon data centers (P 2 and P 3 ).
The pairs (P 1 , P 4 ) and (P 2 , P 3 ) each communicate O (1) .
In all the experiments, the privacy parameters are set as ε = 0.3, δ = 2 −40 .
Run time and Communication Cost: Figure 16a demonstrates that the run time required to compute the Histogram protocol on a graph with 300 million edges is less than 4.17 mins, using multiprocessor machines in the LAN setting.
Table 1 shows the results in more detail.
Figure 16b shows the amount of data in MB, transferred between the parties during the Histogram protocol.
Communication cost shows linear decrease with increasing the number of processors.
Both graphs are in log-log scale.
Similarly, Figure 17a shows that computing Matrix Factorization on large scale graph data sets takes less than 6 minutes, using our four-party framework, in our AWS LAN setting.
The running time is expected to decrease linearly as we increase the number of processors, however due to some small overhead incurred by parallelization, the run time improvement is slightly sub-linear.
Table 2 shows the results in details.
Figure 17b shows the communication cost during Matrix Factorization on large data sets.
Both graphs are in log-log scale.
We measure the run time for each of the graph oblivious operations in our framework, to understand the effect of each step in the performance of the framework as a whole.
Figure 18a and 18b demonstrates the run time break-down of each oblivious operation in Histogram and Matrix Factorization problem, on the input graph with only 1 million edges.
The oblivious Shuffle operation has the highest cost in calculating the Histogram, while Apply phase is taking the most time in Matrix Factorization, due to the calculation of gradient descent values, which are more expensive than counting.
Comparison with previous work: We compare our results with OblivGraph which is the closest large-scale secure parallel graph computation.
OblivGraph used garbled circuits for all the phases of the graph computation, while we use arithmetic circuits.
In both approaches, the amount of time needed to send and receive data, and the time spent computing AES, are the dominant costs.
We compare the two protocols by the communication cost and the number of AES calls in each of them.
In Table 3 and 4, we demonstrated both the gain in our four party oblivious shuffle against the two party shuffle [21] Table 5, compares our running time with those of GraphSC [18] and OblivGraph [16], while computing matrix factorization on the real-world, MovieLens dataset, with 6040 users, 3883 movies, 1M ratings, and 128 processors.
Effect of differential privacy parameters on the run time:(k + s)|E| Share Conversion - (192|E| + 120|V |)(k + s) Oblivious Apply 186032κ|E| + 2960κ|V | (212|E| + 120|V |)(k + s) Oblivious Scatter 0 0 Total 4752κ|E| log |E| + 181312κ|E| (996|E| + 240|V |)(k + s) +2960κ|V | + 4752We study the effect of differential privacy parameters on the performance of our framework using multiprocessor machines in the LAN setting, Figure 19.
We also provide the number of dummy edges required for different value of ε and δ in Figure 20 shows a dramatic slowdown in the run time when we deployed the computation servers across data centers, rather than having them in the same geographic region.
Nevertheless, even in the WAN setting, we still greatly out-perform the LAN implementations of GraphSC and OblivGraph.
In this work, we combine the best results of secure multi-party computation with low-communication cost, and a security relaxation that allows the computation servers to learn some differentially private leakage about user inputs, and construct a new framework which can compute the histogram problem on 300 million users in almost 4 mins and the Matrix Factorization problem on 20 million records in about 6 mins.
It reduces the overall runtime of the state of the art solution by 320X, and its communication cost by 200X.
Furthermore, in contrast to prior work, our system is secure against a malicious adversary that corrupts one of the computing servers.
We assume that we have access to the following oracles: F coin (Figure 21), F rerand (Figure 22 Input Two parties P 1 , P 2 hold shares of [X].
Functionality• The ideal functionality waits for shares [X] from the parties, reconstruct X.• The ideal functionality samples random values ∆, sends [X (1) ] 1 = ∆ to P 1 and [X (1) ] 2 = X − ∆ to P 2 .
Output The parties receive [X (1) ]Figure 22: Rerandomize additive shares FUNCTIONALITY F checkZero Input Two parties (P 1 , P 2 or P 3 , P 4 ) hold shares of [Z].
Functionality• The ideal functionality waits for shares [Z] from the parties, reconstruct Z.Output If z i = 0 mod 2 k+s ∀i ∈ {1, ..., n}, output True.
Else, send False to all parties.
Inputs: All parties have input (A, B, c), where A, B are input wires, and c is output wire.
A = {a 1 , ..., a n }, B = {b 1 , ..., b n }, c = ∑ n i=1 a i b i .
P 1 and P 2 both provide λ A , λ B .
P 3 and P 4 both provide λ A , λ B .
Functionality:• If either pair sends mismatched messages, send abort to all parties.
• Sample λ c uniformly at random.
• Inputs: All parties have input (A, B, c), where A, B are input wires, and c is output wire.
A = {a 1 , ..., a n }, B = {b 1 , ..., b n }, c = ∑ n i=1 a i b i .
P 3 and P 4 both provide λ A , λ B .
Protocol:• P 1 , P 3 , and P 4 query F coin to sample shares [ Functionality:• Verify that P 1 and P 2 send the same α.
If not, send abort to all parties.
• If the corrupted party is P 3 or P 4 : wait for the attack terms U = {u 1 , ..., u n } from that party, compute Z = α(X +U) mod 2 k+s .
• Send shares [α] and [Z] to P 3 and P 4 .
Output: P 3 and P 4 receive [α] and [Z].
P 1 and P 2 receive nothing.
Inputs: P 1 and P 2 have inputs α.
P 3 and P 4 have inputs [X].
F is a PRF.
Protocol:1.
P 1 and P 2 make two calls to F coin to sample two random numbers λ α , r.
They both send r to P 3 and λ α − r to P 4 .
Then they compute (α − λ α ).
They both send (α − λ α ) to P 3 and P 4 .
P 3 and P 4 verify that they receive the same values, otherwise, they abort.2.
P 1 and P 2 agree on a random key k 1 , k 2 .
They both send k 1 to P 3 , then k 2 to P 4 .
P 3 and P 4 verify that they receive the same values, otherwise, they abort.
This material is based upon work supported by the Defense Advanced Research Projects Agency (DARPA) and Space and Naval Warfare Systems Center, Pacific (SSC Pacific) under Contract No.
N66001-15-C-4070.
It is also supported by NSF award #1564088.
