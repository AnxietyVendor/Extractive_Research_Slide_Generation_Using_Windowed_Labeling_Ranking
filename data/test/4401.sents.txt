On most online social media sites today, user-generated data remains accessible to allowed viewers unless and until the data owner changes her privacy preferences.
In this paper , we present a large-scale measurement study focussed on understanding how users control the longitudinal exposure of their publicly shared data on social media sites.
Our study, using data from Twitter, finds that a significant fraction of users withdraw a surprisingly large percentage of old publicly shared data-more than 28% of six-year old public posts (tweets) on Twitter are not accessible today.
The inaccessible tweets are either selectively deleted by users or withdrawn by users when they delete or make their accounts private.
We also found a significant problem with the current exposure control mechanisms-even when a user deletes her tweets or her account, the current mechanisms leave traces of residual activity, i.e., tweets from other users sent as replies to those deleted tweets or accounts still remain accessible.
We show that using this residual information one can recover significant information about the deleted tweets or even characteristics of the deleted accounts.
To the best of our knowledge, we are the first to study th information leakage resulting from residual activities of deleted tweets and accounts.
Finally, we propose an exposure control mechanism that eliminates information leakage via residual activities , while still allowing meaningful social interactions with user posts.
We discuss its merits and drawbacks compared to existing mechanisms.
"every young person one day will be entitled automatically to change his or her name on reaching adulthood in order to disown youthful hijinks stored on their friends' social media sites".
-Eric Schmidt [14] The unprecedented sharing of personal, user-generated conCopyright is held by the author/owner.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee.
Symposium on Usable Privacy and Security (SOUPS) 2016, June 22-24, 2016, Denver, Colorado.
tent on online social media sites like Twitter and Facebook has spawned numerous privacy concerns for the users of the sites [5,6,10,13,16,24].
In this paper, we focus on a dimension of user privacy that becomes more challenging to manage with the passage of time, namely, longitudinal privacy.
Users' privacy preferences for sharing content are known to evolve over time [5,6].
There can be many reasons for such temporal changes in privacy preferences -e.g., the sensitivity or relevance of shared content changes with time; the biographical status of users and their friend relationships change over time.
The challenge of managing longitudinal privacy for a user refers to the difficulty in controlling the exposure of the user's socially shared data over time.
This challenge becomes more complex over time as the set of contents shared in the past grows larger and new technologies like archival (timeline-based) searches make it easier to access historical content shared under outdated privacy preferences.Against this background, this paper asks and investigates the following two foundational questions related to understanding and controlling longitudinal exposure of user data in social media sites, respectively:1.
In practice, is there evidence for users changing their privacy preferences for content shared on social media sites 5 to 10 years in the past?
If so, what is the extent of the change in longitudinal exposure of user data?
2.
In practice, how effective are the mechanisms provided by social media sites to enable users to control the exposure of their shared data over time?
Could we improve the effectiveness of longitudinal exposure control mechanisms?To address these questions, we have gathered extensive longitudinal data (over 6 years) from the Twitter social media site.
Compared to the Facebook social networking site, the privacy preferences of users for messages (tweets) posted (tweeted) in Twitter are relatively simple -each tweet is either publicly visible to everyone, or privately visible only to the user's followers, or deleted from the site by the user.
However, the simplicity of privacy choices in Twitter allows us to measure the temporal evolution of their users' privacy preferences by simply tracking the public visibility of users' tweets over time.Our analysis of Twitter messages 1 reveals striking evidence of a significant fraction (∼35%) of all Twitter users changing their privacy preferences over time.
Only a minority (∼8%) of all Twitter users selectively withdraw (i.e., delete or make them private) a small (∼10%) fraction of all their public posts.
On the other hand, a sizeable fraction (∼27%) of all Twitter users withdraw all of their public posts older than a few (4-6) years.
While a few recent studies have attempted to understand how user's privacy preferences might change with time through user surveys [5,6], to our knowledge, our work presents the first large-scale measurement study of how users actually change their privacy preferences in practice.
Since our exploration is data driven (as opposed to user surveys), we could not investigate the user intentions behind the changes in privacy preferences.
A limitation of our work lies in the assumption that these changes are driven by users' privacy concerns.Our investigation of the effectiveness with which Twitter users control the public exposure of their tweets reveals a fundamental problem.
Even after a user withdraws her public posts, the past interactions of her friends and other users with those posts (by the way of comments and replies) leave a trail of residual posts that remain on the site (as the residual posts are not authored by the same user, they cannot be withdrawn by her).
We show that these residual activities are in many cases sufficient to recover significant amounts of information about the withdrawn posts.
Our analysis of residual activities highlights this inherent flaw with the longitudinal exposure controls currently being provided to Twitter users.
To make users more aware of the flaws in the existing exposure control mechanisms, we also design a Twitter app, deployed at http://twitter-app.mpi-sws.org/footprint/, where any one can login with their Twitter account and check the residual activities around their posts.Having identified the limitations of existing longitudinal exposure controls, we discuss why devising a perfect solution to control longitudinal exposure is extremely difficult.
Then we present an investigation into merits and drawbacks of a few advanced longitudinal exposure control mechanisms.
Specifically, we focus on the recent trend towards ephemeral posts in new social media sites like Snapchat, where every post is timed to be deleted once it reaches a pre-set age (expiry time).
The challenge with such ephemeral posts, however, lies in determining the "correct" pre-set deadlines for post deletion.
We show that a different approach, where a post is deleted based on a pre-set duration of inactivity, offers users comparatively better control over their longitudinal privacy.
In this section we explore the related work in this space along three axes.Are users concerned about privacy of their old data?
Understanding and improving privacy control in online social media sites garnered quite a bit of attention in recent times [5-8, 10, 11, 13, 16, 19, 20, 22, 24, 28].
The focus of these studies range from identifying regrettable / deletable con-tent, to understanding the usage of privacy management mechanisms for sharing data, to designing better privacy management tools.
However, there has been relatively little research on exploring the longitudinal privacy management mechanisms.
Two recent studies [5,6] surveyed tens to hundreds of users to explore how online social media users want to manage their longitudinal privacy for old content uploaded in the recent past (last week, month, year).
The study in [5] performed a user survey and found that a user's willingness to share content drops as the content becomes old.
Moreover, willingness of share further decreases with a life-change, e.g., graduating from college or moving to a new town.
The other study [6] performed two surveys and discovered that users want some old posts to become more private over time and their desired exposure set for the content remained relatively constant over the years.
Both of these studies indicate that users are, in general, concerned about the privacy of their old content, possibly because these content do not reflect who they are at present (possibly after a change in life).
Hence, these studies provide a strong motivation for us to study at large scale how users in the real-world behave to address their privacy concerns.How do users control longitudinal exposure of their old data?
One natural way for a user to protect her longitudinal privacy is to delete her old content.
Some recent studies have focused on content deletion by users.
For instance a PEW survey [18] on 802 teenagers found that 59% of respondents edited or deleted their content in OSNs.
Almuhimedi et al. [4] reported the largest study so far on deleted tweets using real world data, however they only collected data which are deleted at most one week after posting.
Specifically, they collected 67 million tweets from 292K users posted during a week, and found that 2.4% of those tweets are deleted within that week.
Out of their set of deleted tweets, 89.1% were deleted on the same day on which they were posted.
Moreover 17% of those deleted tweets were removed by the user due to typos or to rephrase the same tweet.
However, note that, they primarily focused on content posted in the near past (no more than one week old) which were selectively deleted by the user.
We will report later in this study how the exposure controls are quite different for the content posted in the near and far past, and show that the study [4] missed a large part of deleted tweets posted in far past (e.g., 6 years back).
A few other studies [12,17] explored the changing behavior of Twitter users over time.
Out of them, Liu et al. [17] analyzed the collective tweeting behavior over time including deletion of content.
They observed that social media users are either selectively deleting their tweets or deleting their entire account.
However, they did not check if there are limitations of these mechanisms to control exposure.
Neither did they explore the relative merits and drawbacks of different exposure control mechanisms.
We explore these unanswered questions in detail.What are some proposed mechanisms to help users control longitudinal exposure?
Some recent studies mentioned possible mechanisms to improve the usability of longitudinal privacy mechanisms in OSNs.
Bauer et al. [6] observed that users are possibly becoming more privacyaware about their longitudinal data.
This change in users' privacy concerns is further reflected by the advent and pop-ularity of systems like Snapchat [2] which deletes all users' posts after a predefined expiry time.
Aylan and Toch [5] proposed longitudinal privacy management mechanisms like allowing users to set expiration dates on content or having an archive feature for old content.
We build upon these studies and propose a smart policy for content withdrawal, which dynamically tries to decide which content to delete or archive based on its longitudinal exposure.
In this section, we aim to understand how users are presently withdrawing their socially shared content to control longitudinal exposure.
We start by answering the simple questionwhat are the longitudinal exposure control mechanisms available today in Twitter, for withdrawing shared content?
We found three distinct mechanisms of withdrawing socially shared content (tweets) in Twitter today:1.
Withdrawing tweets via selective deletion: The reasons for such deletion ranges from regrettable content in the tweets to simply correcting typographical errors or rephrasing [4].2.
Withdrawing tweets via deleting account: All tweets posted by a user can be withdrawn by deleting her whole account.
In Twitter, user-accounts are either 'public' or 'private'.
Tweets posted by a public account are visible to anyone online, but tweets posted by a private account are visible to only the followers of that account, who must be approved by the private account owner before they can be a follower.
Unlike Facebook, Twitter does not have sophisticated access control mechanisms whereby a tweet can be made visible to only a subset of one's followers.
In Twitter, a tweet is either public to all users, or at least to all followers of the user who posted the tweet.
Thus, if a user makes her account 'private', all tweets posted from this account are no longer available publicly.Note that there is another factor that will result in tweets becoming inaccessible -if Twitter suspends a user's account for violating their terms of service, all tweets posted by that account will became inaccessible.
However, we do not consider this factor as a mechanism for exposure control, since suspension is not carried out by the user herself.To perform this study at scale, we needed to identify a large set of tweets that have been withdrawn by Twitter users.
Additionally, we also needed to ascertain why a tweet has become inaccessible, so that we can ignore tweets that have become inaccessible due to Twitter suspending the users, and focus only on tweets that have been withdrawn by the users themselves.
The rest of this section describes how we identified such tweets.Methodology for identifying tweets withdrawn by users: Our methodology consisted of taking a large set of tweets posted and archived in the past, and checking which ones have become inaccessible at the time of this study (Oc- tober 2015).
We observed that if we query the Twitter API with a tweet-id (a Twitter-generated unique identifier for a tweet) that was archived in the past when the tweet was public, if the tweet is inaccessible at present, the Twitter API sends back an error code and an error message as explanation.
These error codes are customized by Twitter and are different from the normal HTTP error codes 404 (resource not found) and 403 (access forbidden) that are also obtained during this querying process.
During our experiments consisting of querying for millions of tweet-ids (details given later), we noticed four distinct error codes that are shown in Table 1, along with the corresponding HTTP error codes, the corresponding error messages, and the practical interpretation of the error codes.
These practical interpretations are based on the Twitter error messages and experiments performed using one of the author's Twitter account (as described below).
As shown in Table 1, the error messages accompanying codes 179 and 63 respectively identify the cases where the tweet has become inaccessible because the user made her account private, and where Twitter suspended the account.
In this study, we will henceforth ignore the tweets that returned error code 63, since these tweets became inaccessible not due to user controlling their exposure, but rather due to Twitter suspending the users.However, neither the Twitter official documentation 2 nor the error messages help to practically interpret the difference between the error codes 34 and 144.
We experimented using the Twitter account of one of the authors of this paper, and observed that, both these error codes practically correspond to the case where the tweet has been withdrawn.
However, these two error codes do not distinguish between the cases where the user selectively deleted a tweet and where the user deleted her account as a whole.
To distinguish between these two scenarios, we further queried the Twitter API to check the status of the user account that had posted the tweet.
The interpretation of codes is much simpler for user accounts (as compared to those for tweets) -the Twitter API returns HTTP code 200 OK for existing accounts, and error code 404 for deleted accounts.Thus, by querying the Twitter API with archived tweet IDs (and the userids of users who posted the tweets), and ob-serving the error codes returned, we can determine whether a previously public tweet has been withdrawn.Limitations of our methodology: We do not know exactly when a tweet became inaccessible, i.e., how long after posting was it withdrawn.
However, this limitation does not have much effect on the analyses we intend to conduct in the later sections.
As we mentioned in the introduction, we also do not capture the user intention behind the withdrawal, i.e., we do not know exactly why a user withdrew her tweet or account.
That said, we do view historical tweet withdrawal as being implicitly motivated by the desire for controlling longitudinal exposure of prior posts.
To measure the longitudinal exposure of user data over the last six years from the time of the experiment (October 2015), we used two sets of archived data -(i) a near-complete crawl of Twitter done in September 2009 [9], consisting of 1.7 billion tweets posted by 54.9 million users, and (ii) a 10% random sample provided by Twitter (Gardenhose sample) collected from 2011 till the time of this study.
Note that all of these archived tweets were publicly shared when the data was originally collected.
3We fixed twenty-two time periods over the last six years, ranging from 1 day ago (from the date of our experiment in October 2015) to 6 years ago (see the x-axis in Figure 1).
Then we randomly sampled 5,000 tweets from each of those time periods from our archived data.
4 We used the method described in the previous section on these tweet samples to check how many of the tweets from each time period have been withdrawn today due to exposure control of user data.
We repeated the experiment over multiple consecutive days to make sure that the particular day examined was not an outlier (e.g., a holiday, the day a privacy news story broke, etc.).
Specifically, for each of the time periods earlier than 2 months ago, we sampled 5,000 random tweets per day for a week around that time period and repeated our experiment.1.
How much of the archived data has been withdrawn?
Figure 1 shows the variation in the percentage of tweets that have been withdrawn for each time-period.
We show box and whiskers for time periods that are greater than or equal to 2 months, representing results from multiple days around those timestamps.
We observe that there is little variation among results from the repeated experiments over multiple consecutive days.
Unless otherwise stated, we will report the median from the values obtained through the repeated experiments.We discover that a substantial amount of past data has been withdrawn today.
As shown by the solid red curve in Fig- ure 1, the percentage of withdrawn tweets increases from 4.3% of the tweets archived 1 day ago to 28.3% of the tweets archived in 2009.
Our observation suggests that users control the exposure for a significant amount of their past data.Hence the natural next question is: how do the different exposure control mechanisms account for this inaccessibility?
2.
What is the relative usage of different control mechanisms for longitudinal exposure?
Figure 1 further shows the variation of the percentage of tweets withdrawn via the three longitudinal exposure controls -(i) users selectively deleting tweets (green dashed curve), (ii) users deleting their account (blue curve), and (iii) users making their account private (pink curve).
Surprisingly, we find that tweets posted from the near to far past have been withdrawn via very different exposure controls.
Tweets posted in the near past (e.g., 1 month ago) have mostly been withdrawn via users selectively deleting some of their tweets.
However the percentage of tweets withdrawn via selective deletion quickly stabilizes over time.
On the other hand, the percentage of tweets withdrawn due to users deleting their accounts or making their accounts private, ramp up as we go further back in the past.
In fact, these tweets account for the bulk of the older withdrawn tweets (e.g., 6 years back).
Specifically, out of 8.9% withdrawn tweets from September 2015 (1 month back), 5.9% consists of tweets selectively deleted by users and only 3% is contributed by users who deleted their account or made it private.
Whereas, out of 28.3% withdrawn tweets posted in 2009, as much as 16.2% is contributed by users who deleted their account and only 3.2% by users who selectively deleted tweets.It is important to note that prior studies on deleted tweets, e.g., by Almuhimedi et al. [4] exclusively focused on data from the near past (e.g., 1 week in the past), most of which are deleted shortly (within a few days) after they are posted.
Hence, they ended up analyzing only the selectively deleted tweets, and missed the significant fraction of tweets posted in the far past that have been withdrawn due to users deleting their accounts or making the accounts private.Summary: We analyzed the longitudinal exposure of socially shared data by measuring the percentage of tweets posted at different time periods in the past, that have been withdrawn as of today.
We discovered that a surprisingly large fraction of old tweets has been withdrawn.
Moreover, the exposure controls responsible for this withdrawal are very different for the near and far past.
This global view motivates us to better understand privacy related behaviors at a user-level, i.e., how are individual users controlling their longitudinal exposure?
We address this question next.
In this section, we assess individual users' behavior for controlling longitudinal exposure in the long-term.
From the near-complete snapshot of Twitter data collected in September 2009 [9], we randomly selected 100,000 users who posted at least 100 tweets.
For each selected user, we randomly sampled 100 tweets out of all the tweets posted by her (as obtained from the dataset).
To simplify further analysis, we selected only the tweets that are in English, i.e., tweets in which at least 50% of the words appear in an English dictionary.
Further, we ignored users who were later suspended, and the tweets posted by these users.
We were left with 8,950,942 tweets (more than 89% of all tweets), posted by 97,998 users (97.9% of the users).
Age of archived tweets withdrawn tweets (aggregate) tweets withdrawn by users via selective deletion tweets withdrawn by users via account deletion tweets withdrawn by users via making account private Figure 1: Percentage of tweets in our sample of archived tweets that have been withdrawn as of October 2015.
The age of a tweet is the difference between the time when the tweet was posted and the time of querying the Twitter API with the tweet-ids (October 2015).
The amount of withdrawn tweets is increasing considerably over time -more than 28% of tweets posted 6 years back have been withdrawn today.
The dotted vertical lines in the figure demarcate the points on the x-axis where the scale changes (days vs. months vs. years).
Using the methodology described earlier, we found that 29.1% of all the tweets that we checked have been withdrawn in the last six years, and these tweets were posted by 34.6% of our selected users.
We start with categorizing our users into 3 distinct categories based on their usage of longitudinal exposure controls for withdrawing their tweets.1.
Non-withdrawers: users who did not withdraw any of their tweets.
65.4% of the users in our random sample fall in this class.2.
Partial withdrawers: users who only selectively withdrew some of their tweets.
8.3% of users in our sample are in this class.
They have contributed 9.7% of the tweets that have been withdrawn.3.
Complete withdrawers: These are the users who have withdrawn all of their old tweets by either deleting their account or making their account private.
As many as 26.3% of our selected users (25,751 in total) are in this class.
Out of these users, 60.4% users have controlled exposure of their data by deleting their account, while 39.6% have made their account private.
Out of all the withdrawn tweets in our sample, these users have contributed the bulk -90.3% of all withdrawn tweets.
Table 2 shows the relative presence of each category of users in our dataset.
We also show the breakdown of these users across different countries where only the top few countries (according to number of users) are shown.
5 The percentage of users with the different privacy preferences remains relatively constant across locations.
This observation gives us some confidence that these privacy preferences are not location-specific, rather they are more universal.One concern with our methodology is that, since we randomly sampled 100 tweets per user, we might potentially undercount the fraction of partial withdrawers.
To check 5 We obtained the country of our users by leveraging location data of Twitter users gathered by Kulshrestha et al. [15].
They used the location and timezone field of the Twitter profile for inferring location of users.
Table 2: A breakdown of all users by their privacy preferences as well as by their countries.
Note that the breakdown of users by privacy preferences remains relatively consistent across countries.how serious this concern is, we repeated our experiments using all tweets posted by a set of users.
However, due to the presence of some very active users, our sampled users posted more that 60 million tweets in total, and given the rate limitations imposed by the Twitter API, it is very difficult to obtain the present status of all these tweets.
Hence, we analyzed a slightly less active set of ∼ 97k random Twitter users from 2009, who posted between 10 to 100 tweets each.
We repeated the same analysis as above considering all of their 2,622,808 English tweets.
We found out that 13.6% of the users in this new random sample are partial withdrawers, which is only slightly higher than the fraction of partial withdrawers in our original sample of active Twitter users (8.3%).
We also found that, for a large majority of the users who posted between 10 to 100 tweets, the amount of information available is not sufficient for most of the analyses that we performed further (as described in the subsequent sections) due to lesser activity of these users.
Hence, in the rest of our study, we will report results for our original set of 97,998 active users who posted 100 or more tweets each.
Having identified users with different privacy preferences, we now check who these users are, by correlating the lon- gitudinal privacy preferences of the users with their demographics.
Twitter maintains only minimal demographic information for users, which includes only a profile bio and location.
In spite of the absence of user-reported fine grained demographics information, there has been lot of prior work to infer different demographics characteristics for Twitter users [15,21,23].
We leverage this prior work to infer one important demographic for users from the available profile information -gender of these users.
We focus on the gender since Tufekci et al. [26] noted a correlation between gender and privacy preferences of users in online social media.We infer the gender from the self-reported first names specified in the user profiles using the methodology developed in [21].
Table 3 shows the percentage of female users among the users with different longitudinal privacy preferences.
Interestingly, a majority of the partial and complete withdrawers are female, whereas the exact opposite is true for nonwithdrawers.
As a baseline, we checked that in a random sample of Twitter users, the percentage of males and females is similar.
These results suggest that female users are controlling exposure of their old data more than male users.
This finding is also supported by an earlier study on Facebook [26] which reported that women are more likely than men to delete social media content.Summary: We identify three distinct categories of users based on their individual use of longitudinal exposure control mechanisms.
These privacy preferences of individual users do not vary significantly across countries.
We also find that a majority of the content withdrawers are female.After understanding the privacy preferences of different users, and observing the significant use of longitudinal exposure controls among them, we investigate our next question -are there any limitations of the current exposure controls?
Across online social media sites, the existing longitudinal exposure control mechanisms have an inherent limitation in the form of retained residual activities associated with a withdrawn post (e.g., a deleted tweet) or a withdrawn (deleted or private) account.In these sites users frequently engage in conversations with other users, spurring interactions linked to their posts or to their accounts themselves (e.g., by mentioning a user in a tweet or by tagging a user in a Facebook post).
Such interactions also include someone publicly replying to a specific post.
When a user selectively deletes her post or withdraws her whole account, those old interactions (from others) associated with her withdrawn post or account become residual activities which still points to the withdrawn tweet or account.
We show later in this section that, anyone today can collect a number of residual activities (e.g., residual tweets on Twitter) around both withdrawn tweets and accounts posted as far as six years back from the time of this study.We acknowledge that such residual activities might exist even when a user deletes her recent post or withdraws her account created in recent past.
However, intuitively, the amount of residual activities grows over time as an account stays longer in an online social media site, and consequently the associated privacy concerns become higher.
Thus, we focus our analysis on the residual tweets around withdrawn tweets and accounts posted long back in the past (in 2009).
The presence of residual activities raises an immediate privacy concern -do the residual activities actually breach the longitudinal exposure control mechanisms?
In other words, in the context of Twitter, can one recover information about selectively deleted tweets and deleted/protected accounts by simply collecting and analyzing the residual tweets associated with them?
We first focus on the selectively withdrawn tweets, which are deleted by their account holder while retaining some other tweets posted from their accounts.
Specifically, we ask: what is the amount of the retained residual activities associated with these withdrawn tweets today, and what can we learn from them about withdrawn tweets?
Data collection: We analyzed all the users who selectively withdrew one or more of their tweets from our random sample of 97,998 active users from 2009 (the same dataset as employed in Section 3.3).
We then used Twitter search to collect conversations that mention any of those user accounts.
Among these conversations, replies to a tweet still contain the tweet id of the tweet.
Thus, we also identified the reply posts i.e., residual tweets involving those selectively withdrawn tweets from our dataset.Limitation of our data: Modified residual tweets like RT@XTZ:<copiedPartialTweetText> are easy to (programmatically) assign to withdrawn accounts (@XYZ) but not to particular withdrawn tweets.
Therefore we included such residual tweets in the analysis of withdrawn accounts in Section 4.2, but not for the analysis of withdrawn tweets in this section.
Thus, the data used in this section is effectively a lower bound on the residual activity around tweets.
However, even so, we will show that one can still infer significant information about withdrawn tweets using this data.How many residual tweets remain around the selectively withdrawn tweets?
: In our dataset, a total of 8,174 users selectively withdrew their 253,853 tweets.
We were able to collect 12,415 residual tweets posted in response to 9,738 of the withdrawn tweets.
Although only 3.8% of all selectively withdrawn tweets have at least one residual tweet, these withdrawn tweets with residual activ-ities were selectively withdrawn by a significant fraction of the users -29.2% of 8,174 users who controlled longitudinal exposure by selective withdrawal.
We further analyze the number of residual activities per withdrawn tweet.
Figure 2 shows that, although a majority (89.2%) of these 9,738 selectively withdrawn tweets (with residual activities around them) have only one residual tweet, 3.8% of those tweets have more than two residual tweets.
There is a maximum of 59 residual tweets around a single selectively withdrawn tweet in our data.
We start by asking -can we recover meaningful words from the original withdrawn tweets just from the residual replies?
To answer this question, we first removed all stopwords 6 (no hashtags were removed in the process) from selectively withdrawn tweets and their associated residual activities, then stemmed the remaining words.
We call the resulting set of words for a tweet keywords.
We then checked what fraction of keywords from a withdrawn tweet also appears in the keywords from the set of residual tweets around it.How many keywords can we recover from the withdrawn tweets?
: Figure 3 shows the fraction of keywords shared by the withdrawn tweets and the residual tweets, as the number of residual tweets increases.
We report the median values (unless otherwise stated) in this section, and the boxes in Figure 3 indicate the 25th and 75th percentiles.
Note that we could recover 16.7% of the keywords when the withdrawn tweets received two or more replies.
Moreover, as expected, more residual tweets allow recovery of more information -the fraction of common keywords increases as the number of residual tweets increases.Keywords revealed from the residual tweets: Table 4 shows some sample withdrawn tweets along with their residual tweets and the keywords gathered from the residual tweets.
The keywords that also appear in the withdrawn tweets are highlighted using a bold font.
Note that even if all the keywords from residual tweets do not match the ones in the withdrawn tweet, they offer significant contextual information regarding the withdrawn tweet.
This becomes more evident as the number of residual tweets increases.
This observation motivated us to consider another ambitious idea: to what extent is it possible for a human observer to guess the meaning of a withdrawn tweet from the residual tweets?
Specifically, we asked human observers to guess a withdrawn tweet from its residual tweets, and then informally checked whether the meaning of the guessed tweets is qualitatively similar to the meaning of the original withdrawn tweet.
Since guessing the meaning of a tweet automatically is a hard problem, we instead took help of human annotators from Amazon Mechanical Turk (AMT) for a preliminary demonstration.
We used three AMT master workers from the USA for this survey.
Each worker was first shown 5 example tweets and their replies.
We first binned all of our selectively withdrawn tweets into five bins by the number of their residual tweets (i.e., tweets with 1, 2, . . . , 5 or more residual tweets) and selected ten withdrawn tweets from each bin.
For our randomly sampled 50 withdrawn tweets, all the AMT workers were then shown the residual tweets of each withdrawn tweet and were simply asked to "Guess the original tweet".
Finally we read through the guessed tweets and informally checked the (qualitative) resemblance between the meaning of the original withdrawn tweet and that of the guessed tweets.
Table 5 shows a part of the result from our AMT experiment.
7 As expected, when the number of residual tweets is small, the AMT workers were sometimes unsure about the meaning of the withdrawn tweet.
Nevertheless, as the number of residual tweets increased, all the human observers guessed the meaning of the withdrawn tweets reasonably well (as reflected in their guessed tweets).
This observation indicates that residual tweets often give out sufficient information for a human observer to guess the meaning of selectively withdrawn tweets.Summary: We demonstrate that it is possible to recover both keywords and meaning from the withdrawn tweets by collecting and analyzing the available residual tweets associated with them.
This is definitely a bad news for the users Table 5: Examples of selectively withdrawn tweets and the corresponding tweets guessed by AMT workers who were shown only the residual tweets for a withdrawn tweets.
As the number of residual tweets increases, the AMT workers guessed the meaning of the original withdrawn tweet more closely.who wish to control exposure of their old post through selective withdrawal.
Twitter users widely employ two mechanisms towards controlling longitudinal exposure of their accounts -some prefer to delete their accounts, while others prefer to make accounts private making their content inaccessible to a public observer.
We collectively call these deleted or protected accounts withdrawn accounts.
Here, we study two questions: what amount of residual activity around a withdrawn account is available, and what information does this residual activity reveal about the withdrawn accounts?
We collected residual tweets around withdrawn accounts using a similar methodology as described in Section 4.1.1.
We considered the withdrawn accounts from our random sample of 97,998 users from 2009 (same dataset from section 3.3), and then used Twitter search to collect posts that mentions any of those user accounts.
We limited our search to the period when the withdrawn accounts were active in our dataset, i.e., from the account creation date to the date of the last tweet appearing in our data.How many residual activities remain around withdrawn accounts?
: We collected a total of 1,403,716 residual tweets that mentioned 23,526 withdrawn accounts.
In other words, a substantial fraction (91.4%) of the 25,751 withdrawn accounts have some residual tweets around them.
We analyzed the number of residual activities around each account.
Figure 4 shows that a significant amount of residual activities remain even at an individual account level -55.9% of all withdrawn accounts have 10 or more residual tweets.
Next, we ask what information can we recover about these withdrawn accounts, using both the residual tweets and the existing accounts that posted those residual tweets?
Percentage of withdrawn accounts Figure 5: The accuracy of our social connection inference with the percentage of withdrawn accounts for which we get this accuracy.
For more than 30% of withdrawn accounts, all of their residual tweets came from their social connections.
We expect that two users converse mostly when they are socially connected.
Thus, as a first test, we check if the users who mentioned a withdrawn account were connected to the withdrawn account by the follower-following relation.
Cha et al. [9] had collected all the followers and followings of all Twitter users in 2009 and our withdrawn accounts are part of their dataset.
Leveraging their collected data, we took all the social connections (both followers and followings) for each withdrawn account as our ground truth.
Then we did a simple prediction: we predicted that each of the accounts mentioning a withdrawn account are either followers or followings of the withdrawn account.
The accuracy of our inference for each user was: for what percentage of cases was our prediction correct?
Figure 5 shows the accuracy of our inference and for what percent of users we have a specific accuracy.
Significantly, for 33.3% of the withdrawn accounts, the accuracy is 100%, i.e., all residual activities around these withdrawn accounts were posted by their social connections.
For 48.3% of the withdrawn accounts, accuracy is more than 80%.
Therefore, simply by checking who posted the residual tweets associated with a withdrawn account, we can recover some social connections for a significant number of withdrawn accounts.A large number of existing studies pointed out that connected users in online platforms show homophily, i.e., have similar characteristics [3,25].
So we next check if we can recover some of the demographic attributes, like location, for the withdrawn accounts by leveraging the demographics of the accounts who contributed to the residual posts.
We here focus on whether we can infer the location of an withdrawn account from the location of the accounts who contribute to the residual activity around the withdrawn account.
As stated earlier, we obtained the ground truth country-level location for user-accounts from the study [15].
We then picked the most frequent location among the accounts which posted the residual tweets, as our predicted Figure 6: 6(a) Accuracy of our location inference leveraging residual activities.
We can infer location with high accuracy and the inference is consistently better than baseline.
6(b) the accuracy for withdrawn accounts from different countries.
First bar for each country is accuracy of our method and second bar is percentage chance that a random user will belong to that country.location for the corresponding withdrawn account.
Our accuracy was decided by the number of withdrawn accounts for which our prediction was correct.
As a baseline for comparison, we take the accuracy of a trivial predictor that selects USA as location every time (the most popular country in Twitter population).
Demographics prediction accuracy: Figure 6(a) shows the accuracy of our prediction with increasing number of user accounts associated with residual tweets.
Significantly, when a withdrawn account has three or more accounts posting residual tweets around it, just by leveraging the residual activities we can infer the withdrawn account's location in 85.8% cases.
This is consistently better than the baseline.We also analyzed accuracy of our location inference for top five countries for the withdrawn accounts with some residual activities.
The baseline accuracy for each country in this analysis was the accuracy of a predictor that outputs location based on the chance that a random Twitter user will belong to that country (computed using the full random sample of ∼98K users from Section 3.3).
Figure 6(b) shows the comparison of accuracy for top five countries.
We note that even for countries like Japan, where the chance of a random user coming from the country is as low as 2.25%, our inference is accurate for more than 87% withdrawn accounts.
To recover potential topics the withdrawn accounts could have been interested in, we leveraged a special type of keyword -hashtags.
Hashtags are words in tweets that starts with a '#' symbol and are included to provide the tweet a specific context.
Practically hashtags are used to group together multiple tweets on the same topic.
For example, there were multiple tweets posted with "#iranelection" in 2009 to identify the topic of the tweet related to Iran election 2009.
Using data from [9], we determined that 3,855 accounts in our set of withdrawn accounts posted at least one tweet with a hashtag.
Out of those, for 58.7% accounts (2,263 in total), 296 2016 Symposium on Usable Privacy and Security USENIX Association the residual tweets revealed at least one of their hashtags, and in total 3,625 unique hashtags were revealed for these withdrawn accounts.
This correlation encouraged us to further check what percentage of the hashtags revealed by the residual tweets were also used by the withdrawn accounts.
Figure 7 shows our results: interestingly, in 25% of the cases, all the hashtags revealed by the residual tweets were also used by the withdrawn account.
Table 6: Hashtags revealed by residual tweets for 10 withdrawn accounts.
These users themselves used each of these hashtags.
Also shown are some manually annotated topical categories these hashtags fall into.
These hashtags give us an idea of what might be the topics of interest of the withdrawn accounts.We further analyzed the hashtags revealed from residual tweets for some individual withdrawn accounts, and manually annotated the hashtag topics.
Table 6 presents some example hashtags from the residual tweets of 10 users, who had used all of these hashtags in their now withdrawn tweets.
As shown by our manual topical annotation of these hashtags, these hashtags shed light on the user's interests partially if not fully.
Interestingly, some of these hashtags like "#iran-election", "#nsfw" might even be considered sensitive, while other hashtags such as "#daviscup", "#tech" or "#nascar"give away specific interests of the withdrawn accounts.
This observation provides evidence that the residual tweets still reveal information about what a withdrawn account was interested in, even when the account become inaccessible.Twitter app to raise awareness about residual activities: To increase user awareness about their residual activities, we designed a Twitter app, using which any Twitter user can check what information about her account and individual tweets can be inferred by simply analyzing her residual activities on Twitter.
We invite readers to use the app by visiting http://twitter-app.mpi-sws.org/footprint/.Summary: We found significant evidence that the residual tweets and their associated user-accounts can be leveraged to at least partially recover the social connections, demographics (location) and even topical interests of the withdrawn accounts.
Hence, the goal of the withdrawn tweet / account owners to control exposure of their (past) data cannot be achieved by the existing exposure control mechanisms.
In the next section, we discuss the relative merits and demerits of a few exposure control mechanisms, and how such mechanisms can be improved.
Our analyses in the earlier sections show that a large number of users withdraw their past social content, but often a significant amount of residual information is left behind, which might lead to significant information leakage about withdrawn social content (and consequent privacy violation).
This calls for an improvement of longitudinal exposure control mechanisms, which will directly increase the usability of such systems from a privacy perspective.However, it must be understood that improving longitudinal exposure control mechanisms is a complex problem, as this has to take into consideration multiple (and sometimes contradictory) factors, such as the desire to retain some old content while allowing other content to be completely removed without a trace [6].
In fact, analyzing the effectiveness of such a mechanism might require a far richer understanding of many dimensions like incorrectly (not) limiting exposure of (non-)desirable content, potential privacy impact of such false flags, ownership of residual activities, ease of use and even user sentiment.
Hence, it is very unlikely that there is a silver bullet to solve all the problems with longitudinal exposure control.
The longitudinal exposure control mechanisms that are being deployed in different online social sites today, aim towards improving different dimensions of the problem, some of which we discuss below.
We also propose a novel mechanism for longitudinal exposure control, which addresses some of the limitations of the existing mechanisms.
It can be argued that withdrawing the residual activities along with the withdrawn posts and accounts is a natural solution to this issue or residual information.
However, any such tampering of the content authored by other users (other than the one who specifically wishes to delete her content) raises several difficult questions associated with ownership and control of the content.
8 2.
Age based withdrawal: Ephemeral social media sites such as Snapchat [2] and Cyber Dust [1] offer a potential way out of the residual activity problem.
On such sites, every message is associated with an expiry time after which the post is automatically withdrawn and becomes inaccessible to the users.
Ayalon et al. [5] also suggested that the system operators of non-ephemeral social media sites can offer their users similar timed expiry option such that the posts will become inaccessible to the public after the expiry time.
Though this mechanism solves the problem of residual activities (since even the residual activities will be inaccessible over time), it has two limitations.
First, the default expiry time used in such mechanisms is generally too small (e.g., few seconds or few minutes), which prevents any meaningful discussion around any post.
Since the most interesting posts also get deleted after the expiry time, such mechanisms might not be preferred in sites like Twitter which promote social discussions.
Second, as noted in [6], users are generally poor at anticipating when a post should be deleted, which reduces the practical use of this mechanism even if users are given the option of setting the expiry time.
Our proposal is based on a simple intuition -when a post becomes inactive, i.e., it does not generate any more interaction or receive any more exposure, the post can be safely withdrawn (deleted/archived/hidden) from the public domain.
Note that 'interaction' is a general term that can involve several tasks based on the social media site; e.g., it can mean sharing the post (e.g., retweeting in Twitter), replying to the post or even viewing the post by the original posting account or other users.
Large social media operators today collect all of these interactions.
9 Hence, they can easily check if a post is inactive for more than T days (for any given definition of inactivity), and then the post can be withdrawn from the public domain.
Also note that a user can be given various options for withdrawing her posts which become inactive; for instance, instead of fully deleting the posts, she may instead decide to limit access to the post to only select friends or may even anonymize the posts by removing any identifiable information.
Here we generally consider withdrawal of posts from the public domain, and leave the details of the exact access control decisions to the social media operators.Compared to age based withdrawal, this mechanism has the following advantages.
First, the users need not be bur-However, we do acknowledge that just like earlier mentioned mechanisms, our proposal is not a silver bullet.
For instance, this mechanism does not capture a user's intent to retain some old content even after it becomes inactive (e.g., because it had acquired large popularity, or because of some user-sentiment around a particular post).
Another limitation of this mechanism is that, if a post is continuing to get interactions because it is controversial in nature, this mechanism would lead to the post remaining in the public domain.
To address such issues, this mechanism should be coupled with other exposure control mechanisms such as a user being able to specifically withdraw some posts, or indicating her desire to retain a post even after it becomes inactive.Even if a user wishes to adopt our proposed mechanism, a technical question needs to be addressed -how to select a value for T , the number of days after which a post will be withdrawn?
With a very small value of T (say, 1 day), we may end up losing some valuable interactions; on the other hand, if T is too high (e.g., six years) users run a significant risk of someone digging up information about their past lives.
Next, we demonstrate how the system operators can leverage the past interaction history to select an appropriate value of T .
Deciding an inactivity threshold: We ask a simple question in this direction: if we set a threshold of T days of inactivity before withdrawing a post, how much of the interaction generated by a post is likely to be lost?
To that end we perform the following experiment.
We randomly sample 700,000 tweets posted in the first week of November 2011, i.e., more than four years back.
Note that all of these tweets are accessible today.
In our experiment we take "retweets" as a proxy for generated interactions by a tweet.
For a given tweet, we can obtain this interaction information directly from the Twitter API (unlike interactions like residual activities).
In our dataset, 30,014 tweets received at least one retweet and they received 74,705 retweets in total.
We collect information about when each tweet received their retweets using the Twitter API, and simulate setting our inactivity threshold at T days, i.e. each of these tweets will become inaccessible after T days of not getting any retweets.
We analyze the number of future retweets we would lose for different values of T .
Figure 8 shows that if we set our threshold to be too low, say 1 day, we will lose a significant 5.5% of all the retweets.
However, if we set our threshold at only 180 days (i.e., decide that after six months of inactivity a tweet might be withdrawn from the public eye) then only 0.4% of the future retweets will be lost.
Note that the parameter T need not to be global, and every user may choose her own value.
In fact, the system operator can show a range of values of the threshold and point out the associated percent of stopped activities based on a user's past history, and allow the user can make an informed decision.A comparison between the inactivity-based withdrawal and the age-based withdrawal: To demonstrate advantages of inactivity-based withdrawal over the age-based withdrawal, we also simulated age-based withdrawal policy with different thresholds over the same dataset of 700,000 random tweets and their retweets.
Our age-based withdrawal policy is simple: after T days the tweet will be withdrawn and all future retweeting will be stopped.
We closely investigate how many retweets will be affected by both these policies if we set same threshold.
Table 7 shows the absolute number of retweets stopped and the number of tweets these retweets come from.
It demonstrates that for the same threshold T , inactivity-based withdrawal stops comparatively fewer retweets than age-based withdrawal.From our experiments, we make a more interesting observation: age-based withdrawal also affects tweets which generates lot of interaction (i.e., retweets) over a longer period of time, e.g, a tweet from the president of the United States.
Let us take an example: Table 7 shows that when the threshold is set to 180 days, inactivity-based withdrawal stops 300 retweets from our dataset as it makes 181 tweets inaccessible.
For the same threshold, age-based withdrawal makes 12 more tweets inaccessible (total 193), but stops 279 retweets from those additional 12 tweets, (i.e., on average 23 retweets per tweet).
Notice that, by generating a lot of activity, popular tweets increase the usefulness of social content sharing systems.
Thus, since age-based withdrawal might affect popular tweets, even with a high threshold it might not be suitable in the real-world adaptation.
To demonstrate the effect of this issue, we measure actual time when a tweet will be withdrawn when we set an inactivity-based threshold of T days for different values of T .
In Figure 9, we plot the withdrawal age of the (inactivity-based) withdrawn tweets, and rank them in a sorted order based on their age.
From the slope of these plots for different values of T , it is clear that the actual age of most tweets is significantly higher than their inactive age (or period).
: Actual time when a tweet will be deleted when we set an inactivity-based threshold of T days.Summary: We consider our inactivity-based withdrawal method to be an improvement over the age-based withdrawal, as it removes the need for a user to guess when her content should be withdrawn.
Instead, the social site operator can present suggestions to users when a post becomes inactive, and facilitate the withdrawal.
Our proposed mechanism does not solve all the problems with longitudinal exposure control, but we do believe it is a step toward more usable longitudinal exposure control mechanisms.
In this paper, we explored a dimension of user privacy that becomes more challenging to manage with passing time, namely, longitudinal privacy.
Specifically, using extensive data from the Twitter social media site, we studied whether online users employ longitudinal exposure control mechanisms in real world to limit exposure of their old data.
We find that a surprisingly large fraction (28%) of tweets posted in the far past are withdrawn by users today.
After exploring the usage of existing privacy mechanisms by individual users, we find a significant problem with mechanisms to control data exposure today -social media sites retain residual activities around withdrawn content, which can be used to recover various important information ranging from social connections to user interests and even parts of the withdrawn content.
We also proposed an exposure control mechanism called inactivity based withdrawal -an embodiment of the simple idea that old content can be safely withdrawn when it does not generate any more activity -and showing its benefits for controlling longitudinal exposure over existing age-based exposure controls.
However, our study also calls for further research in this field, as much remains to be done in this space of understanding and improving longitudinal exposure controls of socially shared data.
