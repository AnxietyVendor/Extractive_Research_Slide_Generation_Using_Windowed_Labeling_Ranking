This paper explores how the user interface can help users invoke the right to be forgotten in social media by decaying content.
The decaying of digital artifacts gradually degrades content, thereby becoming less accessible to audiences.
Through a lab study with 30 participants, we probe the concept of aging/decaying of digital arti-facts.
We compared three visualization techniques (pixelating, fading , and shrinking) used to decay social media content on three platforms (Facebook, Instagram, and Twitter).
We report results from qualitative and quantitative analysis.
Visualizations that most closely reflect how memories fade over time were most effective.
We also report on participants' attitudes and concerns about how content decay relates to protection of their online privacy.
We discuss the implications of our results and provide preliminary recommendations based on our findings.
Online sharing contributes to individuals' well-being and social interactions [1,9,13,39].
For example, directed communication on Online Social Networks (OSN) can promote social bonding and positive feelings [13].
It can also facilitate the process of finding and interacting with classmates [1] or maintaining relationships with family and acquaintances [28].
In addition, the use of social media provides individuals with needed social support in case they experience negative feelings such as grief [72] or loneliness [39].
Online communication and social media can also positively contribute to adolescent development through increasing self-esteem and providing an outlet for identity experimentation [9,68].
However, many incidents and research have also demonstrated the potential negative consequences of online sharing.
For example, OSN data may be considered during important selection processes (such as in hiring or school admission decisions) [38,73], resulting in individuals' professional [3,23,45,46], or academic future [65] being compromised by their digital footprints.
Moreover, the Internet exploits the fact that a privacy paradox [1,2,18,33,49,58,66] exists among users by making salient the desire to divulge while downplaying the desire for privacy [33].
In addition, Coopamootoo and Groß suggest that it may be challenging for users to follow both a privacy attitude and a sharing attitude simultaneously because the Copyright is held by the author/owner.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee.
USENIX Symposium on Usable Privacy and Security (SOUPS) 2018.
August [12][13][14]2018, Baltimore, MD, USA.
two attitudes stem from two opposing forces or emotions: fear and happiness, respectively [18].
OSNs and other online repositories have contributed to making ephemeral information permanent.
In the European Union (EU), the Right to be forgotten entitles individuals, after a certain time has passed and under other specific conditions, to ask search engine companies to de-index and delete potentially damaging personal digital material.
As a result, forgetting digital memories [45] has become an important principle to diminish the potential negative repercussions resulting from the persistent reproduction of our digital footprints.
While there exists a general emphasis on reminiscing [21,56], forgetting digital memories introduces a converse emphasis on dissociating from obsolete and irrelevant digital artifacts.
In this regard, there has been an emphasis on representing the passage of time in the field of Human-Computer Interaction (HCI) [42] to preserve the temporal contextual integrity of previously published information [5,10,48,50].
One approach to dissociate from obsolete content is to visualize the passage of time within the user interface (UI) by having older content gradually age or decay.
Aging of content has two conceivable purposes.
It provides temporal context to viewers and it provides some privacy advantages as posts become less accessible to viewers.
Different temporal cues for indicating the age of Facebook online content were proposed by Novotny [50] who implemented and partially evaluated one such prototype.The literature suggests opportunities to design forgetting mechanisms that support users' online identity management needs.
However, it is unclear how the UI can provide temporal context that is non-obtrusive and natural to users, while also protecting their privacy.
Our study examines the concept of aging of social media digital artifacts from the user's perspective.
It aims to identify representations that match users' metaphor of aging and explores the representation of temporal cues [50] on OSN profiles for supporting user privacy.
In particular, we were interested in these two research questions: (RQ1) Which of the three studied visualizations best represents digital aging on social media from a user perspective?
and (RQ2) What are users' attitudes and concerns relating to digital aging on social media?Through a lab study with 30 participants, we compare three different visualization techniques that decay OSN content visible to other users on three different social media platforms.
Using both qualitative and quantitative analyses, we identify which visualization best represents aging of digital artifacts.
We report participants' attitudes and concerns, and discuss their preferences regarding content decay.
We further offer some preliminary recommendations for using decay to enhance online privacy.
Since the phenomenon of sharing data online is broad and includes various dimensions, some aspects are beyond the scope of our review.
Among these dimensions are issues of practical implementation and enforcement of privacy laws.
Other issues relate to sensor data privacy [57] and data collection and behavioural tracking by institutions or apps [15,40,59,77].
While these are important concerns, they are tangential to our current research questions.
We concentrate our literature review on privacy issues relating to interpersonal sharing on OSNs.
A dichotomy exists between online users' reported attitudes and their actual behaviour towards privacy, coined as a privacy paradox [1,2,4,5,18,33,49,58,66].
Online users report willingness to protect their own privacy [2], but studies show that few actions are performed for that purpose [2,4,5,66].
Moreover, even privacy concerned individuals unknowingly disclose information that might be sensitive when they are in specific web contexts, such as online shopping [66], or when expecting a payoff or a reward [2].
Some information users disclose online might be regrettable in the future [33,74].
Digital footprints may bring unintended negative consequences in important selection processes [3,23,38,45,46,65,73].
Furthermore, although users are keen to reveal details about themselves through social media posts [13,33,58], their willingness to re-share the same content significantly decreases with time [4].
Researchers have investigated ways to embed privacy management tools in OSNs to handle past or regrettable disclosed information.
For example, Wang et al. [75, 76] introduced nudging to Facebook users to prevent potential regret when sharing status updates.
Three nudges were introduced [76]: reminding users about the audience of the post, delaying publishing the post, and giving feedback regarding content containing strong sentiments.
Although perceived as beneficial, users started to ignore the nudges within days.
Moreover, while users liked the first nudge, they found the second and third nudges intrusive.
Another way to prevent potential future regret about disclosed information is to set an expiry date for the published information [4], as discussed in Section 2.2.2.
The idea that individuals should be able to move beyond their past artifacts and actions has been most prominently discussed by the EU.
Principles of the Right to be forgotten (RTBF) were upheld in May 2014 by the European Court of Justice in González's versus Google [67].
The court ruled that search engines must remove links to pages that "appear to be inadequate, irrelevant or no longer relevant or excessive in the light of the time that had elapsed" when requested by individuals.
In May 2018, the EU's new General Data Protection Regulation [55] comes into effect.
Concepts of data minimization from the RTBF, however, have been included in earlier data protection laws and in the EU Data Protection Directive of 1995 [54].
During the same year, a joint study [70] by the Dutch Data Protection Authority and the Information and Privacy Commissioner of Ontario in Canada also explored a new approach to privacy and identity protection, that served as basis for seven Privacy by Design (PbD) principles [14], namely:1.
Proactive not reactive; preventative not remedial 2.
Privacy as the default setting 3.
Privacy embedded into design 4.
Full functionality -positive-sum, not zero-sum 5.
End-to-end security -full lifecycle protection 6.
Visibility and transparency -keep it open 7.
Respect for user privacy -keep it user-centricThe PbD principles serve as a framework for proactively embedding privacy during the system engineering process and more broadly within organizational practices.
The framework's main goal is to make central the concern for individual privacy by promoting user trust and accountability when handling personal data.Two decades have passed since these initial efforts, but many issues remain unresolved or only partially addressed.
More recently, the right to be forgotten in the context of digital artifacts was described as a fundamental need in Mayer-Schönberger's [45] book, Delete: The Virtue of Forgetting in the Digital Age.
The book illustrated several examples of individuals who have had their professional lives compromised because of their digital footprints, and emphasized the importance of "forgetting" in the digital age.
Ochrat and Toch [4] and Ayalon and Toch [5] found that users' willingness to re-share information decreases with time, as it becomes less relevant.
In the meantime, the probability that they delete such irrelevant information was low [4,5] and there was no obvious tendency of users to permanently change their old content.
Thus, users' reported approaches towards sharing do not align with their actual behaviour, which could be explained by the privacy paradox [5].
However, other reasons also include the desire to keep past posts for reminiscing [5,7].
Similarly, participants in Zhao et al.'s [80] study appreciated reflection over their past and revisited their older content, expressing regret over their deletion decisions.
Thus mechanisms that permanently delete content do not appear appropriate for most users as a solution for long-term retrospective privacy [5] or when curating their online-self [80].
These mechanisms include solutions such as the Web 2.0 Suicide Machine [17], or deleting content after a certain amount of time [7].
Based on the identified gap between users' sharing preferences and their willingness to delete, Ochrat and Toch [4] proposed having an information expiry feature on Facebook.
They [4,5] also suggested other mechanisms for ongoing privacy management instead of deletion: archiving, compaction, and blocking.When considering an information expiry feature, it might be challenging to set expiration defaults to accommodate preferences for sharing information for short periods and long periods [4].
In addition, Bauer et al. [8] cast doubt on the usefulness of content expiration and suggested that extensive archival features would not be appropriate for users.
Through two studies about privacy settings using the temporal dimension, Bauer et al. [8] found a gap between users' prediction about how their own privacy preferences would change over time and the actual change in their preferences.
They instead suggested designing interfaces that promote reflection on older content [8].
Gulotta et al. [25] suggested that a more subtle mechanism to handle irrelevant content, such as selective archiving rather than extensive archiving, would be more helpful to users because archiving moves irrelevant content to a secondary storage that remains accessible only by the content publisher [5].
A more concrete and elaborate theoretical proposal of forgetting mechanisms and interfaces was discussed by Barua et al. [7].
They set forth theoretical foundations for the design of user-controlled forgetting mechanisms in HCI that parallel forms of human forgetting.
They discuss the benefits and consequences of implementing five forgetting mechanisms: decay, deletion, compaction, blocking, and archival.
For example, they demonstrate that a decay mechanism that provides gradual removal of obsolete content would simulate the decay process in human memory [11,62].
Another approach is to fully or partially obfuscate sensitive photo elements [32,41] or user attributes [16,61].
Obfuscating attributes, however, may not be effective against inference attacks [16].
Li et al. [41] further showed that some commonly used face and body obfuscation are neither [41] effective for privacy nor preferred by users.
One limitation to face and body obfuscation in OSNs is that it does not provide integrated protection of all contextual cues [41] or personally identifiable information [71].
For example, other parts of the photo or post (e.g., background, comments, time, and location check-in) can be recognized by other users [41].
While arguments for enabling forgetting aim to allow people to move beyond their past, there are benefits to remembering and allowing individuals to reflect on their histories.
People tend to keep physical artifacts with certain tangible or intangible value [35], and online users also tend to keep and archive their digital artifacts [35,43].
It is thought that the capabilities of digital technology should be used to eliminate limitations of human memory and to provide a valuable lifelong remembering experience [21,56].
Therefore, some HCI practices seek to support everyday reminiscing [21,56], use the web as a personal archive and for information management [43], consider digital inheritance [53], and enable reflection on social relationships [64] or personal past [69].
As discussed in Section 2.2.1, reflection over old content is important to users, especially when maintaining their online identity.
Ayalon and Toch [4] suggested that the format of the Facebook timeline offers a reasonable starting point for enabling users to review and reflect on old content, and to manage their privacy.
The following section reviews existing work on authoring of history and selfreflection.
However, we focus on contextual privacy and its potential in providing better control and space for users when curating and reflecting on their online self.
Barth et al. [6] proposed a formal model of privacy and contextual integrity that links protection of personal data to norms in specific contexts.
Contexts refer to how individuals act in certain roles within distinctive social domains [6].
The model serves as a conceptual framework endorsing the concept that privacy is not about secrecy, and individuals willingly share personal information if they are assured that specific social norms have not been violated.
Online users, as individuals in the society, transact in different capacities by managing their online identity.
They present themselves in a way that matches current social circumstances [5,25,26,29].
The literature has shown that maintaining online identity is not an ephemeral act, rather, it is an enduring one [29,79].
Harper et al. [27] and Hogan [29] explored the concept of identity articulation through time on Facebook.
They reflected on how outdated content can resurface, highlighting that social media focuses on "now" even though the associated events may have occurred in the past [27,29].
OSN content associated with online identity can become an exhibit that is encountered by different audiences, in different times, and in different contexts [29].
In this regard, some researchers proposed ways in which users can edit their past histories or choose how these histories should be handled in the future.
For example, Thiry et al. [69] used the timeline metaphor to introduce a framework that allows authoring of personal histories to build meaning between the present and the past.
In addition, Gulotta et al. [25] proposed three systems that prompt users to choose how their digital artifacts should be handled in the future.
Based on their findings, Gulotta et al. [25] encouraged the development of tools that provide users with selective archiving and safekeeping of digital data denoting experiences outside of daily activities.
The literature also recognizes a need for contextual privacy settings [5,6,44].
Users curate online self-representational data to meet current circumstances [5,25,26,29].
Madejski et al. [44] showed that Facebook privacy settings did not match users' sharing intentions, and identified a need for contextual privacy settings.
Zhao et al. [80] noted that Facebook did not support an obvious personal space for private reflection when users curate their data and exert control over how they will be exhibited.
In addition, Novotny and Spiekermann [51] showed that users desire control over their disclosed personal information in OSNs and need to dissociate from obsolete information that represents their past identity.
One approach to dissociate users from obsolete information is to visualize time within the UI and have older content gradually decay [50].
As suggested by Novotny [50], this approach can preserve information's temporal contextual integrity, which is one of the key building blocks of user privacy [10,48].
Based on a focus group, Novotny [50] proposed a catalogue of temporal interface cues to indicate the age of Facebook posts.
He [50] classified these cues into temporal indices that incorporates time as a property of the posted information and temporal symbols that can be used as additional visual cues.
A table summarizing Novotny's catalogue is available in Appendix A.
The temporal indices manipulate the display properties of the information (e.g., through size, motion, decay), while temporal symbols include objects that indicate the time of the post (e.g., adding pictograms) and methods to manipulate the layout (e.g., horizontal or vertical) or typography [50].
Although an interesting proposal, few of Novotny's [50] temporal interface cues have been evaluated.
A Facebook prototype visualized the passage of time by gradually decreasing the size of posts, and posts were arranged horizontally on the user's timeline.
Although properties of the photo in the post and the caption were manipulated, other contextual cues that might be revealing, such as date of the post [41] were not manipulated.
It was also suggested [50] that shrunk posts should still be clickable to ensure readability but it was not clear whether the prototype implemented this feature.
However, we think that making the original information available defeats the purpose of degrading them.
The prototype was partially evaluated in a study with 14 participants by having them complete one task.
The horizontal arrangement of posts did not appeal to participants because it did not match other familiar interfaces which display posts vertically in chronological order.Another experimental lab study [52] adopted two other temporal cues (temporal order and graphical timelines) in a hiring process simulation where reputation profiles of job-seekers were shown to participants acting as employers [52].
Results showed that the graphical timeline helped users more easily disregard obsolete information compared to the temporal order cue.
However, the other temporal cues suggested by Novotny [50] remain untested.
Although the literature has explored different forgetting mechanisms and provided insights on how to better match users' goals, such as providing contextual privacy settings and allowing reflection over older content, it is unclear how these mechanisms apply within OSNs.
For example, how can an OSN timeline support forgetting and reflection simultaneously?
How can an interface provide an immediate contextual visual cue that can promote privacy whilst presenting a natural non-obtrusive metaphor to users?
There also remains other open design and research questions about visualizing the passage of time in HCI [42].
How should designs handle the disconnect between representations of time and time as remembered?
Which metaphors represent a clearer analogue to human experience?
And, how should the passing of time be depicted?
[42].
Furthermore, how do users prefer to depict the passage of time to others, to represent their current personalities, and to show progression in life?
And would users actually want time to be depicted; what benefits or concerns exist with such mechanisms?
And finally, what are the privacy implications relating to these issues?
In our present study, we further probe the concept of having older content gradually decay and become less accessible to audiences.
We believe this approach simulates the idea of archiving as a subtle mechanism to handle digital artifacts.
It also provides an immediate contextual cue to the viewer about the age of posted content.
We extend Novotny's [50] study by comparing three different visualizations on three different OSN platforms.
We choose three different OSN platforms instead of one to see if our findings are applicable across platforms.
We also chose three distinct visualizations that degrade content differently and fall under two of Novotny's [50] suggested temporal indices: display salience and degrading display quality.
Our study partially answers some of the remaining open research questions regarding visualizing time in OSNs.
Our two research questions are: RQ1: Which of the three studied visualizations best represents digital aging on social media from a user perspective?
RQ2: What are users' attitudes and concerns relating to digital aging on social media?
Our study explores visualizations of social media posts to simulate the decay or fading of memories over time.
The visualizations are intended to illustrate that posts are getting older or aging to the viewer.
The visualization is applied to content viewed by "others" as opposed to content that is self-accessed.
For example, it is applied to Jane's Facebook profile as viewed by her friends, not content solely viewable by Jane.
Aging of posts has two possible interrelated purposes.
It provides temporal context to viewers and it provides some privacy advantages as posts become less accessible by viewers.
There are, however, several dimensions when considering aging of posts, such as information sensitivity, access control options, and determining the appropriate decay function given a specific sharing scenario.
For this first study, we focus on identifying the best decay representation out of three studied visualizations from a user perspective, recognizing that further work focusing on the other dimensions will be needed in other studies.
Our study also captures users' attitudes and concerns regarding the concept and its potential purposes, including privacy.
During the study, we introduced the concept of "aging" as posts getting older over time, but we carefully avoided mentioning "privacy" as a reason why this might be desirable until the very end of the study to avoid unduly influencing participants' perspectives.To answer RQ1, we gauged users' preferences as determined by responses to Likert-scale questions and interview questions about the preferred visualization for use on their own data.
Likert-scale questions considered aspects such as meaning, intuitiveness, most natural metaphor, and visual appeal.To address RQ2, we collected more in-depth answers from users through interview questions and open-ended questions in a wrapup questionnaire.
For example, some questions explored their interpretations and impressions of the visualizations, if they think the concept of aging digital artifacts is necessary, and if they would like their own artifacts to age.
We also asked about how aging should take place and if they could think of cases in which aging is more useful than deletion or content expiration.
Other questions were relevant to the process itself, e.g., what are the thresholds for the aging process, what should the settings look like, and how does this concept relate to their privacy.The study methods and questionnaires were pilot tested prior to data collection.
Descriptions of the study tasks, interview guide, and questionnaires are available in Appendices B through D.
The study was cleared by our Research Ethics Board.
Recruitment was done through posters posted across campus and a social media page for advertising the university's HCI studies.
Participants were compensated $15 for their time.
Before beginning the session, participants read and signed a consent form that explained the purpose and the procedure of the study, and it reminded them that the session will be audio-recorded.
Personally identifiable information collected from participants was limited to their voice; responses were pseudo-anonymized and non-attributable.
We had 30 participants; 12 were male and 18 were female, with a mean age of 26 (Std.
Dev = 9 years).
They reported having an average of three social media accounts each and spending an average of three hours (Std.
Dev = 2 hours) online daily.
The majority were university students; 16 participants were undergraduate students, 9 were graduate students, and 5 were university staff.Participants were assigned a username that is not linked to their identity and these usernames were used during data compilation and to report results in the paper.
Usernames were generated according to participants' assigned platform (e.g., Facebook: FB1-FB10, Twitter: TW1-TW10, Instagram: IG1-IG10).
We created a fictitious social media profile on three different social networks: Facebook, Twitter, and Instagram.
We choose several platforms to explore whether our results applied across a range of interfaces.
Facebook, Twitter, and Instagram are among the top 5 most popular OSN sites [20,34] and each has a distinct purpose.In our prototypes, the profile layout and arrangement imitated the existing look and feel of July 2017 UI versions of each of the three platforms.
The content on both Facebook and Twitter was identical; it included miscellaneous photo posts with captions and status updates.
To conform with Instagram's layout, its fictitious content included only photos with captions.
We intentionally included content that is personal in nature [30], such as family photos, photos of a car with the licence plate number visible, and photos of a house with a visible street address.
Status updates included personal sentiments and opinions about potentially sensitive subjects [37] (e.g., political views, support for LGBT).
We implemented decay techniques on the three OSN platforms (Facebook, Twitter, Instragram), using three different approaches: (1) content fading, (2) content pixelation, (3) content shrinking, resulting in 3×3 = 9 prototypes.
We chose techniques from Novotny's taxonomy [50] that seemed likely to convey privacy and aging based on our literature review; others could also be considered.The dates of the fictitious posts were separated by a month and each prototype showed posts spanning one year.
The decay was applied linearly across posts; for example in the fading prototype, transparency levels were reduced by equal increments between any two sequential posts.
Figures 1, 2, and 3 show the nine prototypes on Facebook, Twitter, and Instagram respectively.
Each prototype was displayed to the user as a scrollable webpage.Unlike face, body, or object obfuscation, the decay techniques in our prototypes degraded the entire post.
To ensure that limitations posed by such obfuscation techniques [41] were avoided, we manipulated all the contextual cues related to a post that might be recognizable [41] along with the image itself.
These manipulated cues included the image's caption, its intended audience, publishing date and time, comments, date and time of the comments, and tagged friends.
Manipulated content was also unclickable to prevent retrieving or accessing the original unmodified post.
Moreover, although pixelation is ineffective for privacy as an obfuscation technique [41], we choose it as one of the decaying visualizations as the obscuring effect was linearly increased across multiple timerelated posts, which is a different application of pixelation than its application in obfuscation of time-unrelated data.
Thirty participants took part in our 3 × 3 mixed design lab study featuring one between-subject variable (social media type) and one within-subject variable (decay technique); ten participants were assigned to each of three social media types, and each participant saw all three visualizations.
Assignment of social media types and presentation order of the visualizations was controlled using a full latin square to ensure that all combinations were cycled and to avoid possible ordering effects.
For example Participant X saw {Facebook-Fading, Facebook-Pixelating, Facebook-Shrinking} and Participant Y saw {Twitter-Pixelating, Twitter-Shrinking, Twitter-Fading}.
We collected participants' feedback verbally and through online questionnaires in a 60-minutes session.
A session unfolded as follows:1.
View and explore Prototype A 2.
Complete visualization questionnaire A 3.
View and explore Prototype B 4.
Complete visualization questionnaire B 5.
View and explore Prototype C 6.
Complete visualization questionnaire C 7.
Interview/conversation about the concepts and prototypes 8.
Complete wrap-up questionnaire In Steps 1, 3, and 5, participants viewed the social media content as if they were previewing another user's social media profile, not their own.
We asked some probing questions while participants viewed each prototype, e.g., what was their interpretation of the visualization, what was most appealing/confusing, and whether they would change anything in the design.
Other questions explored if the visualization was meaningful in terms of conveying the idea that posts were getting old.
In Steps 2, 4, and 6, the visualization questionnaires consisted of 10 Likert-scale questions covering agreement with the visual representation: (Q1) easily showed posts were getting old, (Q2) was meaningful, (Q3) was confusing, (Q4) was complete, (Q5) changed their perspective, (Q6) was appropriate to the content, (Q7) was obtrusive, (Q8) of photo posts was intuitive, (Q9) of text posts was intuitive.
And finally, (Q10) whether they would use the visual representation on their social media account.
Step 7, the wrap-up interview questions sought to learn about users' attitudes and concerns as both a user browsing another user's profile and as an owner of the profile concerned about other users.
For example, we asked for participants' reaction if they came across a profile that uses one of the content decay visualizations.
Other questions examined participants' perception of aging of digital artifacts, how necessary it is, and by which means it should be implemented in OSNs (e.g., by deletion, expiration, or decay).
More questions probed whether participants would use one of the visualizations to display their own digital artifacts when accessed by other user groups, whether the study changed how they would use social media in the future, and whether content decay would promote their online privacy.In Step 8, the wrap-up questionnaire consisted of one Likert-scale question and three open-ended questions.
In total, each participant gave feedback on three different prototypes, filled out four online questionnaires, and shared opinions pertaining to the concept of content decay.
To answer our two research questions, we performed both quantitative and qualitative analyses.For the statistical analysis, we were primarily concerned with our within-subject variable, visualization type, with three levels (fading, shrinking, and pixelating).
We used Friedman tests (significance level of p < 0.05) to test for main effects of visualization type.
In cases of significant omnibus test results, we followed up with pairwise Wilcoxon signed-rank test with Bonferroni correction applied (significance level of p < 0.017).
The qualitative data consisted of 23 hours of audio-recordings from the interviews and open-ended questions from the questionnaires.
We transcribed the relevant parts of the interviews.
We used content analysis methodologies [31] following an inductive process which included multiple iterations across the transcripts.
We categorized data primarily according to 1) expressed preferences/dislikes/reasons for each, 2) attitudes towards digital aging, 3) interpretation of the purpose of the visualizations, and 4) interest in incorporating aging into their social media, and the requirements/settings for such functionality.
The main researcher compiled the data and extracted the main themes looking for key patterns and particularly insightful feedback through several rounds.
A second researcher was involved refining the patterns, interpreting the data, and handling any complicated cases, but did not independently code the data.
We summarize results of our statistical and qualitative analysis pertaining to our first research question: Which of the three studied visualizations best represents digital aging on social media?
Participants completed ten 5-point Likert scale questions per visualization technique.
Mean responses are available in Table 1; higher means indicate more positive scores.Using the within-subjects variable, visualization technique, we compared questionnaire responses to see if participants favoured any technique.
We found a significant difference in nine out of the ten questions.
Friedman's test results are presented in Table 2, with significant differences highlighted in gray.
Table 3 shows the pairwise comparison between the three approaches and the associated p values (Bonferroni corrected).
Mean responses to the questionnaire ranged from negative to neutral, suggesting that participants were generally unenthusiastic about the visualization techniques.
Reasons for this are discussed in Section 5.2; participants were mainly concerned that the visualizations might obstruct browsing within social media.The statistical analysis showed that pixelation was least favourable to participants.
Shrinking was the most favourable, but participants did not significantly favour it over fading.
Nevertheless, shrinking and fading were significantly more preferable than pixelation.For completeness, we also verified whether there was a main effect of social media type (Facebook, Instagram, Twitter).
This was a between-subjects variable and we performed Kruskal-Wallis tests on the 10 questions.
We found no significant effect of media type; with one exception: Q9 showed a significant difference, with Instagram having a lower mean.
We believe this single difference occurred because Q9 asked about "text posts", which Instagram does not support.
The written and verbal feedback from participants aligned with the Likert scale results: shrinking was the most favourable visualization, followed closely by fading; pixelating was least favourable.As suggested by the feedback for each prototype, detailed next, participants found the shrinking technique most visually pleasing as it looked more "natural".
Moreover, it was best associated with memory and the passage of time; putting less significance on older posts by making them tinier.
Participants also liked the fading visualization because the idea of graying out posts resembled how artifacts fade in real life.
In both cases, the visualizations were reasonable metaphors that provided a logical parallel with their impression of how human memories work.
They recognized and brought up their understanding of the metaphors without prompting.Next, we discuss specific feedback relating to each visualization.Prototype 1: Pixelating: The initial reaction to pixelation for fourteen participants was that there might be a glitch in the system/website or that the Internet connection was slow and pictures were not loading correctly.
Mostly, participants had no idea what was going on.
They reported various negative emotions, including thinking of something bad/criminal (FB6), feeling irritated (FB1), angry (IG8), and scared/lost (FB10).
In addition, ten participants felt confused or annoyed.
Moreover, they thought that someone using the technique on social media must be hiding something (n = 7) from specific people (e.g., non-friends), blocking someone (n = 4), or that the content had been censored (n = 2).
Participants thought that it was pointless to keep posts in such a representation, and felt that it would be better if the post was simply deleted.
Overall, participants neither associated such representation with the passage of time nor found it visually appealing.
Clearly, the pixelating visualization failed to convey the appropriate metaphor, and instead invoked other negative connotations.Prototype 2: Fading: Fifteen participants found the fading effect intuitive and indicative of its purpose.
In addition, it was visually appealing since the gradual fade-out inherently showed a smoother transition between posts.
Eleven participants liked the idea that they could see details about the post, text in particular, compared to the pixelating and the shrinking techniques.
Furthermore, the idea of fading the posts resonated for some participants (n = 12) with the metaphor of memories or physical photos fading over time.As Nevertheless, some participants (n = 4) thought that faded out content would raise suspicion about the user, for example, suggesting that the user had something to hide.
Others were unsure whether they would have guessed its purpose if they suddenly saw this visualization on their OSNs.Prototype 3: Shrinking: Overall, the majority (n = 17) thought the shrinking approach was most intuitive and visually appealing.
However, some participants (n = 8) initially thought that bigger posts were of higher importance and relevance to the user publishing the content.
They believed that the user had somehow chosen to make some posts larger, rather than realizing that size was an automatic characteristic that varied over time.
The most common complaint from participants (n = 27) was being unable to have clear legibility of posts as they shrunk.
However, between fading and shrinking, they thought shrinking offered better visibility.Users' preferences: when asked to choose one visualization to be applied to their own artifacts, 14 participants favoured the shrinking prototype, 11 participants preferred fading, three participants were undecided between both prototypes, one participant wanted both combined, and one participant preferred pixelation.
Participants How necessary is aging of posts in social media?
or Fading as appropriate visualizations for conveying digital aging.Interestingly, participants (who were not initially told that this study was about privacy) expressed annoyance resulting from not being able to clearly read the posts as they decayed.
Some mentioned a preference for the fading technique because it enabled them to decipher the details of the posts for the longest time.
So while they understood the metaphor, they still favoured the visualization which showed the least decay.
We note that levels of decay could be adjusted for any of these visualizations and that in an actual implementation, the effect would appear much more gradual since there would likely be more posts in the span of a year.
We concluded the session with an interview and a wrap-up questionnaire to capture participants' opinions regarding the concept of aging digital artifacts and to discuss if it would increase their online privacy.
This part of the session took place after participants had seen all three visualizations and had provided their feedback about each one.
The next subsections summarize the responses from the interview and the open-ended questions of the questionnaire.
The first question of the wrap-up questionnaire asked "How necessary is aging of posts in social media?"
.
Sixteen participants thought that digital content aging is necessary, while a third were neutral.
Figure 4 shows participants' Likert-scale responses.In our interviews, we asked participants if they would opt-in to the content decay feature for their own content, if available.
Twothird of participants (n = 20) thought they would, believing that digital content should age, whether to reflect the person they are today, to depict different time periods, or to protect their online privacy.
The remaining participants disagreed, or were concerned about how aging of digital artifacts would impact their access to content on their own profiles.
While they thought that aging might be appropriate for others viewing their profile, they wanted to retain access to the unedited versions of their own content.
We further discussed with participants what it means to have their social media content age, and how this should happen.Eighteen participants recognized that social media content lost relevance as time passed.
Two-thirds of participants (n = 20) wanted to either delete or archive content themselves or potentially have content decay.
Their choice of method depended on the social media platform and the content itself.
Some explicitly mentioned that they wanted to delete content when it no longer reflected their current personalities [25,26,29] or the impression that they wanted to convey to the world.Secondly, two-third of participants (n = 20) saw a need for a decay feature on OSNs: one-third would unconditionally opt in and one-third would opt for it conditionally, i.e., if they retained some control over the operation of the decay feature.
For example, if it was programmed to allow an undo of the decay, and if the decay did not apply to their own self-view.
Other preferences included being able to select which decay visualization technique should be applied.
Moreover, the majority (n = 17) wanted to select which content should decay rather than have it automatically executed.
Their choice would depend on specific time thresholds, or the context of the content itself.
Fifteen participants thought decay should depend on characteristics of the content more than on how much time has passed.
In addition, eight participants wanted to choose which audience views the decayed content.Participants (n = 25) thought decay would be particularly beneficial in several situations.
For instance, they thought it might reduce information overload when browsing other users' profiles.
They also thought it would be beneficial if they might regret deletion of specific content.
As one participant explained: Lastly, two participants thought that the only cases in which content should automatically expire is when the person is deceased or the profile is no longer in use.
Alternatively, they suggested the family of deceased person could choose to decay the content instead.
We also wanted to explore participants' perspectives on online privacy.
We asked a group of participants † if content decay would protect their online privacy.
Participants' opinions were polarized.
A minority (n = 3) thought the idea does not contribute to online privacy at all.
Their main concern was that concealing content would raise questions about the content or the user, hence, they found no contribution to privacy.
However, most (n = 11 out of 17) thought it was the only purpose for using decay.
For instance, they would decay obsolete content when seeking employment, or when beginning new chapters in their lives.
As explained by FB5: "It would be beneficial to me if I was applying for a new job, or even entering a new relationship, I would not want the company or person to be able to scroll and see my old posts and judge me by them."
† We explicitly asked 17 participants at the very end of the interview.
However, it was implicitly discussed with other participants.When the eleven participants who thought decay is beneficial for privacy were asked which visualization technique is most preferable for privacy, six participants favoured the pixelating technique.
They thought pixels hid the content appropriately since pixelation obscures content more quickly by nature.
Four participants thought either the fading or shrinking techniques might be helpful to privacy as well, depending on how fast/gradual they decay the content.
One participant did not specify a preference.
Participants thought that digital artifacts should age to accommodate changes in their real lives.
Decaying digital content was appreciated, and if available on social media, participants would opt-in to the feature.
They generally found it useful for online privacy, but responses varied for which visualization they would adopt for their own accounts.
Specifically for privacy, pixelation was most popular but is also held negative connotations for several participants.
Changing of perspective: Eleven participants said that introducing the concept of aging of digital artifacts changed their perspective on how they use social media today.
For instance, they intended to go through their own content, re-examine their privacy settings, and re-think which posts remain appropriate for their current lives.
This aligns with previous research suggesting that conversations about privacy lead users to reflect on their own practices [2,33,58].
We observed a shift during some sessions.
Participants initially were concerned about how aging of digital artifacts would affect the visibility of their content to themselves and to others.
As the session progressed, they accepted the concept and realized its value for online privacy when displaying content to others.Other participants (n = 6) expressed no major change in perspective.
They were already careful with what they post, or they were accustomed to the look and feel of social media today and saw no reason to change.
As one participant noted: "If I have choice between changing and not changing, I'm not gonna change [...] if they have it changed and I'm forced, I'm not gonna change it either."
-FB1Downsides of decay: While participants realized that the feature has merit, three participants expressed concerns.
Examples in which the feature would be problematic include translating decayed content for people with accessibility issues, or when the content is needed as an evidence to verify information (i.e., in a police investigation of a criminal activity).
Our motivation exploring how to represent the aging of digital artifacts within the UI.
We further investigated what aging of digital artifacts means for users and to what extent incorporating this concept within the UI would conform to their sharing and privacy needs.
We elaborate on the privacy and design implications of our findings in the following subsections.
We then translate those implications into a tentative set of system design recommendations.
We found that participants' mental models of how their content should appear online depended largely on whether they were considering aging or privacy at the time.
In our study, we intentionally avoided mentioning privacy until late in the session so that we could determine if privacy concerns arose unprompted.When participants considered the management of their data in terms of aging, they favoured a gradual fading/shrinking of artifacts over time because it matched their idea that memories lose prominence over time, as suggested by human memory decay theory [11,62].
As with real memories, they also expected the UI to differentiate between important memories or life events that are clearly remembered despite the passage of time and everyday happenings that are gradually forgotten.They expressed that the visualization should represent the natural forgetting process and should not seem like the artifacts were being manipulated.
For example, several participants specifically disliked the pixelation visualization because it suggested that something was being intentionally obscured and this raised suspicion.When prompted to consider privacy implications of digital artifacts, we observed a shift in priorities and requirements.
This aligns with previous research regarding the privacy paradox [1,2,4,5,18,33,49,58,66]; people do not intuitively consider privacy risks and sometimes accept them until prompted to consider privacy.
Some participants felt that the pixelating visualization best reflected the idea of privacy by making it clear that something was intentionally being kept private.
Pixelation fit with these participants' mental model of privacy: content was being censored or obscured.
They also noted a more discrete dimension to privacy: something should be either kept private or made public.
It was not necessarily viewed as a gradual process whereas "aging" was clearly gradual.We are left with this interesting paradox: users want gradual, natural decaying of digital artifacts (with exceptions for important events) to more accurately reflect human memory, but at the same time want discrete, intentional private/public representation of artifacts to reflect their concept of privacy.
For participants, these were two distinct requirements, whereas the literature generally views them as closely related [5,45,50,51].
In both cases, however, participants recognized the benefits of removing irrelevant content and recognized that their preference for the visibility of specific digital artifacts would likely change over time.
The question remains: how do we best reconcile these two distinct intentions while displaying digital artifacts in OSNs?
Participants require distinct rules when representing aging on their self profiles versus their public profiles.
Aligned with previous research [35,43], participants wanted their own content to always be visible to themselves.
However, they then had complex rules for how their content should be displayed to different user groups.
Those rules differ significantly depending on the category of the content published on their profiles and the intended audience.Although this was not our intention, participants re-iterated that they expected that the representation of profiles should not be automatically altered to represent aging when self accessed.
Normally, participants use the web and OSNs as backup repositories to retain their digital possessions [43].
Our participants were concerned that their view of their own data would be altered or the data would become inaccessible without their consent, losing access to the artifacts representing these milestones.
Therefore, when the self UI visualizes aging, the default representation should not decay content.
While not the intended purpose of decay, the discussion does serve as an anchor for participants' explanation of how things should work for content viewable by others.When being accessed by the public/others, participants desired different rules.
Because they are concerned about their online presence and their availability to other online users, it is important that their content is visible to their audience.
However, they wish to manage the visibility and aging settings of their online content for both availability and privacy purposes.
In this case, the audience comprises a spectrum of closest friends, specific circles of friends, and moving outwards to the public.
Participants wished to consider two main factors when visualizing aging on the UI for other audiences: (1) the context/category of the published content and (2) where its intended audience falls on the spectrum.
Other practices [41] in the online photo sharing domain similarly adopt a privacy framework by controlling two elements: content and recipient.
Indeed the two factors are significant determinants of privacy [41] since some online artifacts are more personal in nature than others [30] (e.g., a self-portrait versus a photo of a landscape).
However, the rules are individualized to each user and can be complex as they encompass all possible scenarios and exceptions.
Moreover, rules changed dynamically based on specific contexts or based on exceptions for a specific audience.
For example, Joe might enjoy sharing his life memories with others, but Jim prefers having personal photos or embarrassing photos decay when viewed by work colleagues and unmodified when accessed by family members or close friends.
Complexity might further increase if Jim also wanted the same artifacts decayed when viewed by a cousin and unaltered for a specific work colleague.
Accurately reflecting users' real intentions could quickly become untenable.This suggests that incorporating controls into the UI that maintain such rules becomes an added effort for users.
Firstly, it is impractical that each user can internalize all their desired rules and adjust the rules whithin the UI whenever they publish new content.
Secondly, because the desired rules change as time passes and circumstances change, it is unlikely that a system could generalize these rules to match the preference of every user.
This leaves us with another question: should we integrate such complex functionality for controlling the display of digital artifacts in OSNs and can we do so without adding undue effort to users?
The literature show that although users rationally accept privacy risks as a trade-off for the benefits of online sharing, they also express an intuitive concern when prompted [1,2,4,5,18,33,49,58,66].
Very few of our participants initially realized the privacy merit of content decay, but opinions evolved throughout the sessions, as presented in Sections 6.3 and 7 (Change in perspective).
Initially, participants who favourably viewed content decay said they would opt-in for different purposes.
For example, they wanted it as a way of compressing, keeping track of their activity, or forgetting specific memories.
Privacy is an intangible subject [33] to users; our participants did not intentionally ignore it, but rather it did not immediately occur to them.
However, when prompted about privacy [33] and the ways in which aging of digital artifacts contributes to privacy, they started to realize its potential added value.In some instances, privacy could be viewed as a positive by-product of decaying content.
Some users liked the idea of decaying digital artifacts for reasons other than privacy (e.g., it makes it easier to quickly tell how recently information was posted).
These users might be persuaded to adopt the visualization due to its perceived usability benefits, but subsequently also gain privacy benefits with no additional effort.The literature has shown that some Facebook users manage their privacy by trusting their abilities in manually controlling information being shared [1]; few changed Facebook's default privacy settings [24].
Our participants thought they would simply delete what they no longer wanted available online.
Although they expressed interest in retaining detailed control, practically speaking and, as shown in the literature [2,24,66], this is unlikely.
Moreover, even if participants had the time and initiative to delete old content, this is actually very difficult to do in OSNs; for example, Facebook only loads a bit of data at a time, in reverse chronological order.
And even though the "activity log" allows a user to review older content by year, there is no way to easily access and manage that content.
Our participants thought that after the study, they would revise their own OSN content and delete what is no longer relevant.
However, this intention only arose because they were specifically primed to consider the privacy of their OSN data [2].
This suggests that normally users remain indifferent to the need to perform retrospective privacy management.
Based on the literature and our findings, we provide the following recommendations.
Given that this study has raised additional questions and other aspects should be explored, these recommendations are preliminary in nature and intended to fuel further discussion.R1: Have digital decay features enabled by default as a failsafe mechanism: A principle of usable security and privacy is to include the safest outcome in the path-of-least-resistance since it is likely what users will choose [63,78].
Given that the ultimate pathof-least-resistance for users is to do nothing [78], system settings should be secure by default [63,78].
The privacy paradox [1,2,4,5,18,33,49,58,66] also suggests that users' actions rarely match their privacy intentions.
Thus, fail-safe decay mechanisms could at least partially protect users from their unintended self-disclosure on public profiles.
This further aligns with the Privacy-by-Design principles [14] of having preventative and default measures.As a result, users would be mostly relieved of the burden associated with retrospectively managing their digital artifacts.
Digital aging gives temporal context to the viewer and emphasizes content that is currently most timely, indirectly supporting their online privacy by gradually removing content from the public sphere as it ages.In practice, the aggressiveness of the decay algorithm could be increased for additional privacy protection and to avoid possible reversal of deteriorated posts at the early stages of decay.
As shown in the literature on using redaction for visual privacy [60], increasing the strength of a privacy filter [19,36] and the masked area [19] increases privacy.
Although digital decay does not address all aspects of online privacy, such a fail-safe mechanism could be a key component to minimize the negative consequences associated with long-term availability of OSN digital artifacts.R2: Match the aging metaphor: Metaphors are a helpful tool that serve humans' cognitive functions [22] and metacognitive strategies [12].
Metaphors link an abstract concept to a concrete concept [22], allowing extraction of common properties from both concepts to better understand the abstract concept [22].
Metaphors have had a radical impact on interface design practices [47].
The use of metaphors in the UI can reduce the mismatch between the designer's intention and the user's mental model of the system [47].
As discussed in Section 8.1, participants felt that visualizations for aging of digital artifacts should reflect the natural forgetting process.
Based on our early findings, the shrinking and fading visualizations were found to best depict the metaphor of decaying memories [11,62] and could be used either individually or potentially in combination.
However, if a system designer is faced with selecting only one approach, shrinking would be recommended since it was most preferred by participants and was thought to be most intuitive and natural.
Other research suggests that visualizations such as pixelation or blurring are actually ineffective at preserving privacy of social media photos [41].
Our study found that the pixelation visualizations were interpreted as "concealing"; they invoked negative connotations and aroused suspicion.
Taken together, these results suggest that pixelation should be avoided as a method for increasing privacy.
Online sharing and privacy are guided by complex social norms and expectations [48]; any visualization used should be carefully implemented to ensure that it does not inadvertently make the user appear as if they are breaking such social norms.
: Allow overrides: Users should be allowed to override decay defaults, if they wish to.
As suggested in R1, the default settings should be secure, but allowing users to have control over their content is also important.
By allowing overrides, users can disable the feature or adjust settings to perform more selective decaying [25] and to control the decay rate [7] based on the context and specific online content.
Whereas automating such privacy decisions may be desirable, the complex, personal, and dynamic nature of these decisions makes it unlikely that they can be performed algorithmically in a fully automated way.
In particular, the risks of miscategorization could lead to privacy violations if the user expects something to automatically decay and it does not.Given these constraints, users should remain involved in decisions to make some digital artifacts visible beyond the normal decaying period, or to avoid the decaying process altogether.
It is possible that they could be assisted by the system, but the ultimate choice should rest with the user and involve a distinct, conscious decision by the user that enables them to reflect on their intended privacy and sharing needs.
This could also support existing recommendations [4,8,80] suggesting that the UI should promote user reflection of aged content.We believe our early recommendations align with Principles 1, 2, 3, and 7 of the Privacy-by-Design framework [14].
Our recommendations place privacy as a core function of the user interaction (Principle 3; privacy embedded into the design) by reducing the long-term exposure of digital artifacts and reducing risks of privacy violations (Principle 1; proactive not reactive).
They seek to insert privacy into the design of OSNs by default as a fail-safe feature (Principle 2; privacy as the default setting).
The recommendations aim to maximize privacy defaults, while giving users granular privacy options to customize their privacy preferences based on their privacy and sharing requirements (Principle 7; keep it user-centric).
By supporting the aging metaphor, the recommendations also focus on matching users' mental models as closely as possible (Principle 7; keep it user-centric).
Within OSNs, several implementation issues would need to be addressed when implementing decay visualizations.
First, digital content shared on OSNs may not be exclusively controlled by its publisher/owner [71].
For example, other users may be tagged in a post, or content may be re-shared by other users.
In these cases, and cases where multiparty access control is required [71], it is unclear what should happen to decaying content.
Do all instances decay at the pace set by the original owner?
Should other users be able to override decay settings?
What happens if content is reposted/shared after significant time has elapsed?
Does it reset to full visibility or get posted partially decayed?Another significant concern is that traces of the digital content might still be available elsewhere outside the original OSN.
For example, content may be copied or downloaded by others before the decaying process begins, leaving unaltered instances of the digital artifacts.
The owner of the content may also have shared copies of content on other mediums.
Thus, the feasibility of decaying social media digital artifacts might be limited when considering other aspects of online sharing and availability of online data.
The study had the usual limitation common to lab studies; asking participants to share feedback about a partially unfamiliar concept in a limited amount of time in an artificial environment.
A future field study could be designed to complement our findings.
Furthermore, the sample size of thirty participants might be small when considering that they were divided across three social media platforms (although every participant saw all three visualizations), and the university sample of users is not necessarily representative of the whole population.
Additionally, when designing the study prototypes, we distributed fewer than 20 posts across a year to more easily and clearly show the effect of decay.
Had we added more posts to the prototypes, the change in visualizations would have appeared more gradual, which could have impacted participants' opinions.
We chose to use artificial data in the prototypes rather than applying the visualizations to the users' own content.
This may have made the content seem more abstract to participants since it was disconnected from any particular context or personal connection.
However, this design decision was taken because protecting the privacy of participants was viewed as more important than the slight methodological advantage to be gained in these early stages of the research.
The study offers a starting point in empirically testing visualizations for aging of digital artifacts.
Further comparison with other visualizations should also be considered.This research has led to several possible future research directions.
Further research could explore design or technical aspects of implementing decay features or examine how feasibility limitations of the feature can be addressed in specific online sharing scenarios.
It could also subjectively [41,60] or objectively [36] evaluate technical privacy protection offered by the decay visualizations, and explore whether decay visualizations might lead users to become less proactive in managing their online content (e.g., by leaving content online rather than deleting it).
The design of a future study could consider other relevant aspects such as information sensitivity, access control options, different types of artifacts, and parameters of the decay function.
It could include scenarios to help users with specific contexts, and to provide insights into identifying the primary factor for choosing to decay artifacts: characteristics of the artifacts or their age.
It could also consider using real social media data that is connected to participants.
Another future study could empirically examine how aging digital artifacts on an OSN profile affects viewers' impression of its owner.
This could be explored in several different social contexts: political, employment, or relationships/dating contexts.
We conducted a lab user study exploring the concept of aging or decaying of digital artifacts and reported results from both qualitative and quantitative analyses.
Results showed an inclination towards visualizations that closely represent fading memories over time.
Because of the nature of human memory, and users' mental model of privacy, we identified distinct user requirements when addressing either aging or privacy in the UI.
These two distinct purposes should be further explored to determine how they can be best reconciled in interaction design.A balanced approach to addressing users' requirements would seek to promote privacy while minimizing user effort and simultaneously enabling user reflection.
Towards this goal, we provided three preliminary design recommendations.
Although decay features do not address every aspect of online privacy and long-term data availability dimensions, it can help minimize the potential unintended consequences associated with data availability on OSNs.To summarize, this work compares three OSN content decay visualizations, investigates users' attitudes and concerns about the aging of digital artifacts, and provides early recommendations that would contribute to users' privacy and sharing needs.
We also believe the study is a step towards answering currently open research questions pertaining to visualizing passage of time in OSNs.
We thank our study participants and paper reviewers for their time and valuable feedback.
R. Mohamed acknowledges funding from the Ontario Trillium Scholarship (OTS) program.
S. Chiasson acknowledges funding from NSERC for her Canada Research Chair and Discovery Grant.
.
APPENDIX APPENDIX B: STUDY TASKS AND INTERVIEW QUESTIONSHow?
By decaying?
Or by deleting forever? 
Would you prefer having the option to keep old posts the same without decaying as a way to reminiscing or highlighting a blast from the past? 
Would you want the process of decaying to be automated?
Or manual?
What kinds of settings would you want?
o Select specific posts to decay based on: time of publishing, specific keywords in the caption/status, pictures taken with specific friends, posts/pictures with specific location? 
Did our study change the way you browse social media today? 
Do you think decaying can protect your online privacy?
If so, which visualization from the ones you saw today would you use for privacy?
APPENDIX APPENDIX D: WRAP-UP QUESTIONNAIREHow necessary is aging of posts in social media?
( ) Very necessary to ( ) Very unnecessary ( ) Prefer not to answerIf available, would you choose to have your posts age?
Why or why not?Can you describe a situation where aging of posts would have been particularly beneficial to you?Can you describe a situation where aging of posts would have been particularly problematic for you?
APPENDIX How?
By decaying?
Or by deleting forever? 
Would you prefer having the option to keep old posts the same without decaying as a way to reminiscing or highlighting a blast from the past? 
Would you want the process of decaying to be automated?
Or manual?
What kinds of settings would you want?
o Select specific posts to decay based on: time of publishing, specific keywords in the caption/status, pictures taken with specific friends, posts/pictures with specific location? 
Did our study change the way you browse social media today? 
Do you think decaying can protect your online privacy?
If so, which visualization from the ones you saw today would you use for privacy?
How necessary is aging of posts in social media?
( ) Very necessary to ( ) Very unnecessary ( ) Prefer not to answerIf available, would you choose to have your posts age?
Why or why not?Can you describe a situation where aging of posts would have been particularly beneficial to you?Can you describe a situation where aging of posts would have been particularly problematic for you?
APPENDIX
