Autonomous vehicles are becoming increasingly popular, but their reliance on computer systems to sense and operate in the physical world introduces new security risks.
In this paper, we show that the location privacy of an autonomous vehicle may be compromised by software side-channel attacks if localization software shares a hardware platform with an attack program.
In particular, we demonstrate that a cache side-channel attack can be used to infer the route or the location of a vehicle that runs the adaptive Monte-Carlo local-ization (AMCL) algorithm.
The main contributions of the paper are as follows.
First, we show that adaptive behaviors of perception and control algorithms may introduce new side-channel vulnerabilities that reveal the physical properties of a vehicle or its environment.
Second, we introduce statistical learning models that infer the AMCL algorithm's state from cache access patterns and predict the route or the location of a vehicle from the trace of the AMCL state.
Third, we implement and demonstrate the attack on a realistic software stack using real-world sensor data recorded on city roads.
Our findings suggest that autonomous driving software needs strong timing-channel protection for location privacy.
Recent years have seen significant efforts to develop autonomous vehicles.
Autonomous unmanned aerial vehicles (UAVs) have already been used in some cases for commercial parcel delivery [21].
Today's passenger vehicles include many advanced driver assistance features, and future vehicles are expected to have even more autonomous driving capabilities.
For example, Tesla vehicles include the Autopilot [14] system, which enables autonomous cruise on freeways.
Uber [15] and Waymo [18] are testing commercial taxicab services using fully autonomous vehicles.
While autonomous vehicles can enable many exciting applications, they also introduce new security risks by allowing a computing system to sense and control the physical system.In this paper, we show that the location privacy of an autonomous vehicle may be compromised by software sidechannel attacks when the vehicle's driving software and the attack software share a hardware platform.
In particular, we demonstrate that a cache side-channel attack can be used to infer the route/location of a vehicle that uses the adaptive Monte-Carlo localization (AMCL) algorithm [35] for localization.
Previous studies on traditional computer systems have demonstrated many cache side-channel attacks for inferring confidential information, so it is not surprising to find cache side channels in the computing platforms of autonomous vehicles.
What is novel and interesting about our attack is that the cache side channel can be used to infer a victim vehicle's physical state, exploiting the correlation between the physical state of the vehicle and the cache access patterns of the vehicle's control software.
Moreover, our experimental results show that this information leak is sufficient to identify the vehicle's route from a set of routes in the known environment, and even the location of a vehicle if an attacker knows the vehicle's initial location.In autonomous vehicles, perception and control algorithms are often adaptive in order to improve their efficiency and accuracy.
The adaptive algorithms perform more computation when there is more uncertainty in the environment or an event that affects the vehicle's state, such as a new obstacle showing up or the vehicle making a turn; conversely, they perform less computation when there is no significant change.
These adaptive behaviors are natural and important for efficiency.
However, they also create strong correlation between the algorithm's memory access patterns and a vehicle's physical movement and environment.
For example, we found that the amount of data accessed by the AMCL algorithm, commonly used for localization, reveals when the algorithm's uncertainty on the vehicle's location changes.
This correlation allows our cache side-channel attack to infer when a vehicle is turning.While the observation that the AMCL algorithm's cache behavior is strongly correlated to a vehicle's physical state is interesting by itself, we found that cache side-channel attacks on an autonomous vehicle's control software introduce new challenges that do not exist in traditional cache side-channel attacks.
Unlike cryptograhic keys in memory, the physical state of a vehicle changes continuously as the vehicle moves.
Work on inferring AES keys via cache side channels has aggregated results from multiple measurements [55].
However, it is difficult to measure the fast-changing physical state of a vehicle multiple times using a cache side channel.
Moreover, physical environments are inherently noisy.
As a result, cache timing measurements are affected not only by noise in the computing system but also by physical noise.In this paper, we address these challenges and demonstrate an end-to-end cache side-channel attack on the location privacy of an autonomous vehicle.
Specifically, we demonstrate that an unprivileged user-space program, without access to sensor inputs or protected state of control software, can predict the route or the location of an autonomous vehicle using a prime-and-probe cache timing channel attack on the control software.
Our attacks differ from many previous cache side channel attack in that we use timing measurements over a period of time when a vehicle is moving.
We introduce a statistical learning model based on random forests to predict the route or the location of a vehicle from cache timing measurements while dealing with noise.
The experimental results based on both a simulated robot and recorded data from a real-world vehicle show that this attack can fairly accurately predict the vehicle's route or location.Our results show that the location privacy of an autonomous vehicle can be compromised when its perception and control software share hardware resources with less trusted software.
Without new processor designs that provide strong isolation guarantees regarding timing channels, our findings suggest that separate platforms should be used for autonomous driving software and the rest of the system.The following summarizes the main contributions of the paper:• We show that the adaptive behaviors of perception and control algorithms may introduce a new security vulnerability that reveals the physical properties of a vehicle or its environment through side channels.
• We introduce statistical-learning models that predict the AMCL algorithm's state from its cache access patterns, and infer the route or the location of a vehicle from the trace of the predicted AMCL state.
• We implement and demonstrate the attack on a realistic software stack using both simulated environments and real-world sensor data recorded from a vehicle.The rest of paper is organized as follows.
Section 2 discusses the threat model.
Section 3 discusses the background on autonomous vehicles and cache side channels.
Section 4 describes the attack implementation.
Section 5 describes our testbeds and evaluates the attack's effectiveness.
Section 6 discusses the implications of the attack, and Section 7 reviews related work.
Finally, we conclude the paper in Section 8.
Route 01 Figure 1: The threat model.
The attack software runs on the same processor with the autonomous-driving software, and learns the route of the vehicle through cache side channels.
The goal of the attacker is to infer the location information of a vehicle based on cache side channels.
In particular, the attacker predicts the route that an autonomous vehicle takes from a set of known routes.
Figure 1 illustrates the threat model discussed in this paper.
While the figure shows a passenger vehicle as an example, we note that the proposed attack method and principle may be applied to other autonomous vehicles such as delivery robots or drones.
We assume that the attacker is an entity that can deploy a software module on the vehicle.
We refer to the software module as "attack software" or "attack process".
In this paper, we use process, program, and software interchangeably.
The victim is an autonomous vehicle (the "victim vehicle") whose route information needs to be protected.
Localization software on the victim vehicle (the "victim software" or "victim process") has direct access to sensors and to its location-related information, and is the target of our cacheside channel attack.
The attacker has no physical access to the victim vehicle, and performs its attack only through the attack software.
We assume that the attack software cannot circumvent the access controls of the operating system and has no direct access to the location information.Assumptions on the attacker.
We assume that the attacker knows details of the victim vehicle including the software and hardware configuration of its computing platform as well as the mechanical system.
We also assume that an attacker has detailed knowledge of the environment in which the victim vehicle operates and knows a set of routes that the victim may take.
For example, the attacker should have the map of the victim's environment, and may use another vehicle to collect detailed sensor measurements of the area in order to train its prediction models.
The aim of the attack is to infer the victim vehicle's route or location in a known environment, rather than to track the victim vehicle in an unknown environment.To make cache side-channel attacks possible, we assume that attack software can run on the same processor where victim software runs.
This co-location may be achieved by compromising less safety-critical software components that are already on the victim or via untrusted applications that is allowed to be installed.
The attack software is also assumed to be able to send the vehicle's location information to a remote attacker once it acquires the information.
On the other hand, we assume that the operating system securely prevents the attack software from directly reading sensors or the location.
Assumptions on the victim.
We consider an autonomous vehicle that is controlled by an onboard computer.
We assume that the autonomous-driving software uses an adaptive algorithm, such as adaptive Monte-Carlo localization (AMCL) [35] for localization or Faster R-CNN [59] for object detection, whose compute requirements change depending on the vehicle's movements or environments.
Our attack exploits the fact that memory access patterns of these adaptive algorithms are affected by the victim vehicle's movements.Assumptions on the environment.
We assume that the environment has unique characteristics that enable identification of the vehicle's position and route.
Analogously, humans can localize themselves in a known city using visual details such as buildings or signage.
Our work exploits variability in possible vehicle paths to guess the route of the vehicle from the turns it takes.Out-of-scope attacks.
We do not consider any physical attacks on a vehicle.
As we assume that the attack software does not have permission to access sensor data, we do not consider any attacks that rely on direct access to the physical measurements of an environment [48,49] (e.g., inferring locations based on local temperature, light intensity, etc.).
Besides, we do not consider traditional attacks that exploit software vulnerabilities to compromise an operating system or the driving software itself.
We assume that the driving software is not malicious or compromised, and do not consider covertchannel attacks where the driving software intentionally leaks the vehicle location.
Autonomous vehicles perform tasks in the physical world without human intervention.
As shown in Figure 2, an autonomous vehicle comprises three main hardware subsystems: sensors/information collectors, an onboard computer, and actuators/command executors.
Sensors are used to collect information from the physical world.
The collected data are then processed by the onboard computer, which generates actuation commands.
The actuation commands are executed by the actuators, which usually have observable and intentional effects on the physical world, such as turning the steering wheel of the vehicle.
Both sensors and actuators are connected to the onboard computer using a bus protocol such as USB, PCIe, GPIO, or CAN bus [31].
The navigation software stack hosted on the onboard computer reads preprocessed sensor data from device drivers and writes commands to the controller driver.
There are two major tasks performed by the navigation software:• Perception/estimation.
This is the process of converting the sensor data (e.g., timestamps returned by a GPS receiver) into the most likely physical state (e.g., location on the earth).
This is needed for two reasons.
First, sensor data contain noise from measurements.
Thus, an estimation algorithm is needed to remove the noise and get a statistically sound state.
Second, the actual physical state (e.g., location of a vehicle on a map) cannot be directly measured from sensors (e.g., LiDAR signal, which is a vector of distances to obstacles in its scanning directions).
An estimation algorithm (e.g., adaptive Monte-Carlo localization [34]) infers the most probable location based on the LiDAR data.
• Control/decision.
This is the process of determining a sequence of control commands that optimize a certain objective function (expected arrival time, distance to travel, etc.) given the estimated state.
For example, given an estimation of the current location and the final destination on a map, the controller should determine a trajectory to the destination and issue a sequence of acceleration, stop, and steering commands so that the vehicle follows the planned path.As shown in Figure 2, the state estimation module in the navigation stack needs to read data from sensors such as GPS, LiDAR, camera, and LTE/5G to make correct state estimations.
Estimated state, such as the vehicle location, is used by the path planning module, which makes decisions on which trajectory to take and sends commands to the controller.
There is also a collision avoidance module, which can override the commands to the controller when there is a safety issue.There is also a utility software stack, which performs vehicle-specific tasks that are not critical to safety.
For example, a passenger vehicle may have an infotainment system providing a music streaming service, while an autonomous video-recording drone may have software to control a highresolution camera.
Because the utility stack is not safetycritical, it should not have unnecessary access to sensors or actuators.
For example, a music streaming app may require access to the LTE/5G network to download music, but should not be able to access or record GPS data.
This can be enforced by OS-level access-control mechanisms.
Localization is a task that determines the locations of objects on a given map based on sensor inputs.
It is needed by many advanced driving assistance systems and required by autonomous vehicles.
Adpative Monte-Carlo Localization (AMCL) is a special case of general MCL [34], and was used by multiple teams [26,43,50] in the DARPA Grand challenge [25].
Many recent research autonomous driving projects [27,40,60,64] have also used AMCL.
For example, the CaRINA intelligent robotic car [32] uses AMCL for its LiDAR-based location [40].
Algorithm 1 shows the pseudocode for general MonteCarlo localization.
Given a map M 0 of a certain area and a probability distribution P : M 0 → R over the map M 0 , at time t, N particles (i.e., hypothetical locations of the vehicle) are randomly generated based on the distribution.
For each particle L i , the sensor measurement S t is combined with the particle to infer the position of the obstacles on the map.
For example, in a 1-D case, if the distance sensor detects an obstacle 10 m from the hypothetical location of the vehicle and the hypothetical location is 20 m from the starting location, it is inferred that that obstacle is 30 m (10 m + 20 m) from the starting location.
Inferred obstacles are plotted on a new empty map M i , which is then compared with the given map M 0 to calculate the fidelity p i of the particle L i , based on the assumed distribution of measurement errors.
For example, the fidelity p i will be high if the inferred map M i closely matches the given map M 0 , and low if the two maps differ significantly.
Finally, k-means clustering [36] is used to determine the most probable geometrical clustering center L est,t of these particles {L i }, weighted by {p i } at time t. Also, the probability distribution P : M 0 → R is updated for the next measurement S t+1 .
The number of particles N in Algorithm 1 is not necessarily fixed.
When the distribution P : M 0 → R converges, a small N is enough for accurate estimation.
When the distribution P : M 0 → R spreads across the map M 0 , the parameter N may need to be increased.
In AMCL, N changes with time t; we denote it by N t .
The exact value of N t at time t is determined by the Kullback-Leibler distance (KLD) [34] between the estimated distribution P : M 0 → R and the underlying groundInput: Map M 0 , a probability distribution over the whole map P : M 0 → R , sensor measurement time series S 1 , S 2 , ...S t , number of particles N, number of clusters K, transient odometryd 1 , d 2 , ...d t .
Result: Estimated states L est,1 , L est,2 , ..., L est,t on map foreach sensor measurement S t at time t do Randomly generate N particles (i.e., hypothetical locations) {L i } on the map based on distributionP : M 0 → R; foreach particle L i (1 ≤ i ≤ N) doOverlay measurement S t on the particles L i ; Generate the extrapolated map M i based on the measurement S t and location L i ; Compare the extrapolated map M i and the given map M 0 , calculate the fidelity p i ; end Determine the most probable cluster centerL est,t = kmeans(K; L 1 , . . . , L N ; p 1 , . . . , p N );Update the probability distribution P :M 0 → R based on particles L 1 , . . . , L N , corresponding fidelity p 1 , . . . , p N as well as transient velocity d t ; end Algorithm 1: General Monte-Carlo localization.truth distribution P 0 : M 0 → R:N t = k − 1 2ε {1 − 2 9(k − 1) + 2 9(k − 1) z 1−δ } 3 (1)Here, z 1−δ is the upper (1 − δ) quantile of standard normal distribution, ε is the upper bound of the KLD, and k is the number of bins occupied during sampling at time t (e.g., if the map is partitioned into 1,024 bins and only 300 bins are occupied, in this case, k = 300).
Theoretically, N t could be any positive integer.
Practically, there is a maximum limit N max and a minimum limit N min to ensure real-time performance and k-means clustering accuracy, respectively.
In our experiments, we found that the AMCL implementation uses either the maximum or the minimum number of particles in most cases.
In modern computing systems, off-chip memory (e.g., DRAM) accesses are much slower than on-chip memory accesses served by a cache.
Also, a cache is usually shared among multiple programs.
For example, a last-level cache (LLC) in a multi-core processor is used by multiple processing cores concurrently.
L1 and L2 caches may be dedicated to a specific core, but are still time-shared among programs that run on the core.
The shared cache implies that one program's memory accesses can affect whether another program can find its data in the cache, or needs to access off-chip memory.
As a result, one program can infer another program's memory accesses by measuring its own memory access latency.
When a victim program accesses its data from memory, it can evict the cached data of other programs in order to bring its own data into cache.
An attack program can infer whether the victim program had a cache miss or not, and which memory address was accessed, by measuring the latency of its memory access, which reveals whether the data was found in the cache or not.
This measured latency leaks the victim program's memory-access pattern to the attack program.
There are many existing cache side-channel attack techniques, including prime+probe [45,54], evict+time [55], flush+reload [44,71], prime+abort [28], flush+flush [37], etc.
In this work, we use the prime+probe attack, but we expect that our attack can also be implemented using other types of cache side-channel attacks.
An autonomous vehicle running AMCL is vulnerable to a cache side-channel attack that aims to infer its kinematics.
This is because the memory access pattern of AMCL depends on the number of particles N t at each time t, which has strong correlation with the real-time vehicle kinematics.First, the number of particles N t affects the memory access pattern of AMCL, which can be inferred through a cache side-channel attack.
The following steps summarize how the memory accesses in AMCL for an iteration at time t are determined, based on Algorithm 1 and a reference implementation in ROS [1].1.
Calculate the number of particles N t using Equation (1); 2.
Create N t particle objects in a fixed-size buffer 1 ; 3.
For each particle, access the memory locations of the particle object and perform necessary computation.If N t increases, more memory locations will be accessed.
The memory accesses can be observed by another program through a cache side channel.Second, the number of particles N t has a strong correlation with the vehicle kinematics at time t.
It is obvious from Equation (1) that N t increases with k, which represents the number of bins occupied by particles.
The value of k depends on the level of uncertainty in the estimation.
As shown in a previous study [35], when the observed environment is unstable 1 Original ROS AMCL implementation dynamically allocates and frees memory space for N t particles in each iteration rather than using a fixed-size buffer.
Instead, we use a statically-allocated buffer to avoid unnecessary overhead for dynamic memory allocation.
While not included in the paper, we also tested our attack with the dynamic memory allocation, and confirmed that the attack works for both static and dynamic allocation.
(e.g., due to signal loss), N t increases to compensate for the increased estimation uncertainty.
Our observation is that N t increases when the vehicle is turning as shown in Figure 3.
Third, the route or the position of a vehicle can be inferred from kinematic information.
In theory, if the curvature κ(t) of the vehicle's trajectory as a function of time t is obtained using the side channel, we can obtain the route that a vehicle is taking by matching the curvature of the trajectory with the candidate routes on the map.
In addition, if we know the initial location of the vehicle, we can predict the location of the vehicle by enumerating routes that connect the initial location and the candidate locations on the map.In practice, instead of using curvature, whose precise value is hard to directly infer, we use the information on the number of particles to predict the route of the vehicle.
Based on the vulnerability described in Section 4.1, it is possible to implement a cache side-channel attack that infers the route or the location of an autonomous vehicle running AMCL.
We implement our attack using the following steps.1.
Prime+Probe: Collect the cache probing time for each cache set over fixed time intervals, forming a sequence of cache-timing vectors in which each vector represents the probing times for cache sets at a specific time interval.2.
Particle Predictor: Use a binary classification model to predict the number of particles for each time interval based on the cache-timing vectors for each interval.3.
Route Predictor: Use a random forest model to predict the route or the position of a vehicle based on the trace of the number of particles.
Figure 4 shows the overall flow of the attack.
We describe each step in more detail in the next three subsections.
In this work, we use a prime+probe attack to infer the memory accesses of victim software.
First, the attack program fills the cache with its own data by sequentially accessing a set of memory addresses.
Then, the victim accesses the cache.
After that, the attack program probes the same memory addresses and records the latency of each access.
If a specific memory address is evicted by the victim program, the probe time will be longer.
Thus, the memory access pattern of the victim program can be inferred.The result of the prime+probe attack is a sequence {T t } in which each element T t at time t is a K-dimension vector(τ 1 t , τ 2 t , ..., τ K t )where K is the number of cache sets.
For example, in Figure 5, each column is a 16-D vector representing the probing time of 16 sets in the L1 data (L1D) cache.
The result is from an Intel i5-3317u dual-core processor whose L1D cache of one core has 64 sets total.
For brevity, we show only 16 sets out of 64.
Many cache side-channel attacks exist.
For example, the evict+time attack [55] has been used to extract cryptographic keys on a system when many measurements can be made using the same key.
The flush+reload attack [44] has been used when shared memory locations, such as a shared library, can be accessed by both attacker and victim software.
We use the prime+probe attack because it can effectively infer the victim's memory accesses even without multiple measurements and without a shared library between the attacker and the victim.
In practice, we found that the AMCL algorithm usually uses either the maximum or the minimum number of particles.Given this observation, we formulate the prediction of the number of particles as a binary classification problem.The input of the model is the vectors from the prime+probe cache attack {T t }.
We take a time window of size 2T + 1 of T t , i.e., (T t−T , ..., T t , ...T t+T ) as the input of the model, and the output particle-number class N t is in one of the two classes, i.e., N t ∈ {L, H}, where L and H denote "Low" and "High", respectively.
Formally, the classification task is defined as follows:• Given: t end tuples of (T t , N t ) (t ∈ {1, 2, ...,t end }),whereT t is a (2T + 1) · K-dimension vector T t = (τ 1 t−T , ..., τ K t−T , ..., τ 1 t+T , ..., τ K t+T )for each t, and N t ∈ {L, H} for each t.• Find: a model f : R (2T +1)·K → {L, H} such that the classification score∑ t end t=1 d( f (T), N t )is maximized, where d : {L, H} × {L, H} → R is defined as follows:d(N 1 , N 2 ) = 1, if N 1 = N 2 .
0, otherwise.
(2)We observe that the two classes are unbalanced, i.e., the number of samples in the "High" class is much smaller than the number of samples in the "Low" class.
This is because when a vehicle is moving on a map with predefined roads, for most of the time, it is moving straight and the trajectory curvature is small.
Due to the correlation between the number of particles and the curvature, as mentioned in Section 4.1, more samples in the "Low" particles-number class are seen.
Traditional binary classifiers such as SVM [36] do not perform well on such unbalanced datasets.
To address the problem, we use RUSBoost [62], a classification algorithm designed to alleviate class imbalance in the dataset.
RUSBoost combines both random undersampling (RUS) and boosting to improve classification accuracy.
Figure 6 shows an example of the prediction of the number of particles in AMCL (max/min number of particles 16,000/500) using RUSBoost on the cache timing channel information collected from the L1D cache of an Intel processor.
The model correctly predicted the timing of events where there exists a spike in the number of particles.
To evaluate prediction quality, we use Dynamic Time Warping (DTW) [61], a popular metric for measuring similarity of two temporal sequences.
DTW allows us to compare two sequences even when the exact locations of spikes are slightly off.
The DTW distance between the predicted and the ground truth is 539,407 Train 2-fold 5-fold RUSBoost 536,013 514,656 510,006 SVM 150,890 543,716 547,580 Given a sequence of the particle classes (N 1 , N 2 , N 3 , ..., N t , ..., N t end ) we need a model that predicts the route or the location of the vehicle.
There are two related tasks:1.
Route prediction: Given a set of known routes, find the route that a vehicle takes.2.
Location prediction: Given the starting location of a vehicle and a set of possible final locations on a known map, determine the final location of the vehicle.The task of predicting the final location can be considered a specific form of route prediction, in which the set of known routes contains all routes on the map that connect the starting location and possible final locations.
In that sense, both the route prediction and location prediction tasks can be formulated in a unified way.Different routes may not necessarily have the same length t end , and for the same route, t end may vary based on the speed of the vehicle.
To handle the variations in the trace length, we pad each sequence N = (N 1 , N 2 , N 3 , ..., N t , ..., N t end ) into a sequence (N 1 , N 2 , N 3 , ..., N t , ..., N t end , ..., N t tmax ) with length t max by assigning a new element P ∈ {L, P, H} (for padding) to all N t for t end < t ≤ t max .
After that, we can formulate the prediction as a standard classification problem:• Given: M tuples (N i , l i ) in which 1 ≤ i ≤ M and N i ∈ {L, P, H} t max is a vector of maximum length t max and l i ∈ {l 1 , l 2 , ..., l n } is the label representing a route or a location.
• Find: g : {L, P, H} t max → {l 1 , l 2 , ..., l n } such that∑ M i=1 c(g(N i ), l i ) is maximized.Here the cost function is defined as follows:c(l 1 , l 2 ) = 1, if l 1 = l 2 .
0, otherwise.
(3) We can identify a route by comparing the sequence of particlenumber classes ("Low" or "High") along the route.
In this case, the label l i represents a distinctive route i.
We can use a classification algorithm, e.g., k-nearest neighbor (kNN) or random forest (RF) [36] to classify different routes.
For example, Figure 7 and Figure 8 show an example of classification results using kNN and RF with 50 trees (RF-50) for five distinct routes in Maze 1 in Figure 14.
This experiment uses a Jackal robot described in Section 5.1.
For each sequence of particle-number classes, we use all other sequences as the training set and find the route label for the sequence.
The overall accuracy is 76% and 96%, respectively.
Given its higher accuracy, we use the random forest (RF) as the route-prediction model.
If an attacker knows the initial location of a vehicle, our route prediction approach can be used to predict the final location of the vehicle from a particle-number class sequence.
In this case, the label l i represents the final location.
For example, we can partition a map into Q x × Q y grid cells and assign each cell (q x , q y ), where 1 ≤ q x ≤ Q x and 1 ≤ q y ≤ Q y , a unique integer labell i = (q y − 1) · Q x + q x .
Usually, if an autonomous vehicle starts from a fixed starting location and takes the shortest path to each destination, the paths will form a shortest-path tree [53] on a given road network graph.
We also use the RF model for this modeling task because in addition to its general pattern-matching capability, it also captures the tree structure of the shortest-path tree.In practice, the total number of possible destinations (Q x × Q y ) can be quite large, and collecting sufficient training (and validation) data from multiple runs to all possible destinations can be difficult.
Instead, in our experiments, we model an attacker who collects data for a subset of possible destinations; we randomly select a subset of destinations for the training runs and the validation runs separately, and include intermediate locations to create a larger training and validation sets.
For each run with a randomly-chosen destination, the intermediate points along the path as well as the final destination are used as target locations for samples in the training and validation sets.
The runs in the training set and the validation set do not necessarily share the same destination.
The model will not be able to predict the target locations in validation samples that never appear in the training samples.
However, as Figure 9 shows, the intermediate positions along paths with different destinations may overlap, and the model will be able to correctly predict the samples that use these intermediate positions as their target locations even though the final destinations of the runs are different.
3 Figure 10 shows an example of the training and validation accuracy of an RF-50 model, which predicts a location label 3 See Appendix A for a more detailed discussion on how destinations of simulation runs in the training and validation sets affect the prediction accuracy.based on a sequence of the particle-number classes.
The maze is partitioned into a 16-by-16 grid.
The experiment is performed using a dataset in which we collected 3,633 samples based on 100 simulation runs in Maze 1 shown in Figure 14, where the starting location of the vehicle is in the center of the maze.
We use the samples collected from 80 runs for training and the remaining 20 runs for validation.
For the destinations of runs in the validation set, only 4 destinations out of the 20 destinations appear in the training set, however, after adding multiple samples using the intermediate locations also as target locations, 131 out of the total 135 target locations in the validation set are covered by the training samples.We calculate the distance between the predicted location and the actual location, and show the distribution in Figure 10.
Over 75% of the predictions fall within 3 cells of the actual target location, indicating the RF model can effectively capture the relation between locations and sequences of the particle-number classes.
We evaluate the attack using two different setups.
First, we use a simulated Jackal robot running in a world created by the Gazebo simulator for a controlled evaluation environment.
We perform both route and location prediction using the simulated environment.
Second, we use the real-world data collected on a Nissan LEAF driving around Oxford, UK to evaluate the attack in a more realistic environment.
Because the Oxford dataset only includes a limited set of routes in the city, we only evaluate route prediction using the data.
Gazebo: As shown in Figure 11, our testbed hardware has two computers connected via Ethernet ports.
The client has a dual-core Intel i5-3317u processor, and the host runs a quad- core Intel i5-3470 processor with 8GB of memory and Nvidia GT710 for graphic rendering.
Both of them run Ubuntu 18.04 [16] and support ROS Melodic [8] for interaction with the physical world.To create a simulated world, we use Gazebo [3], a ROScompatible physics-based simulator.
Figure 12 shows examples of a simulated vehicle and a maze in Gazebo.
To efficiently create complex mazes for our experiments, we use an open-source Gazebo plugin [7] that generates maze models such as the one in Figure 12(b) based on a text description.We run the entire software stack (including Ubuntu, ROS, AMCL and other control software) of a Clearpath Jackal Unmanned Ground Vehicle (UGV) [5] on the client.
The Jackal UGV, shown in Figure 12(a), is a configurable and extensible platform commonly used for autonomous vehicle studies.
In the simulations, we attach SICK [12] LMS1xx series Li-DAR to the Jackal UGV as the sensor for 2D localization.
We use the ROS implementation of AMCL [1] for LiDAR-based localization.
Oxford: For the real-world experiment, we use the Oxford RobotCar dataset [46], which is collected on a Nissan LEAF along a 10 km route around central Oxford, UK, from May 2014 to December 2015.
We converted all the data to rosbag [11] format in order to replay it in the lab environment, and we run AMCL on a platform with an Intel Xeon E3-1270 four-core processor with 16GB memory, which is similar to the configuration used by the Apollo autonomous driving platform [2,9].
For each trace in the dataset, the LiDAR scan data is provided by SICK LD-MRS LiDAR attached in front of the vehicle.
Odometry information is recorded by a NovaTel SPAN-CPT GNSS/INS receiver [13].
The original RobotCar dataset uses CSV files and we preprocess them by converting the LiDAR and odometry data as well as the corresponding timestamps into a single rosbag file for evaluation.
To provide a reference map for AMCL, we use the 3-D pointcloud recorded by the SICK LMS-151 LiDAR on the vehicle.
We project all the points in the pointcloud of heights between 0.5m-2m (that can be captured by LD-MRS LiDAR) onto a 2-D plane, which forms the 2-D map used for AMCL.The RobotCar dataset contains multiple traces along one route.
We divide the route into seven segments, and perform route prediction using the seven segments as different routes.
We describe the implementation details of the prime+probe attack on the client computer.
The cache configurations of the processors used are listed in Table 2.
We perform attacks using the L1D cache and the LLC for both platforms.
The L1D attack explores an idealized scenario while the LLC attack explores less restrictive and more realistic scenario.
We adopt higher sampling rate, smaller steps, and assign attack and victim processes as real-time processes in the L1D attack.
L1D attack: We assign the attack and victim processes on the same core by assigning them the same CPU affinity value.
We set both attack and victim processes as real-time processes with the victim process at higher priority.
In Linux, a real-time process cannot be preempted by a userspace non-real-time process.
Thus, the L1D state left by the victim process will not be destroyed before probing.
In addition, the higher priority of the victim process guarantees that the victim process will not be preempted by the attack process unless it yields control.
For the L1D attack, we probe every set in the cache, and the entire cache is probed every 100 ms. LLC attack: The attack and victim processes may run on different cores for the LLC attack.
We use the MASTIK tookit [6], which implements the algorithm in [45] that finds the eviction sets on a physically-addressed LLC, to perform the prime+probe attack.
We probe only one cache set for each consecutive 64 cache sets, which reduces the CPU utilization of the attacker and the amount of data generated.
The entire cache is probed every 300 ms instead of 100 ms. Despite the reduced cache probing rate, our results show that it is still possible to predict the number of particles with high accuracy.
Here, we describe the procedure that we use to train the particle predictor and the route predictor in our evaluation.
Given the measured cache timing, the particle-number class sequences (i.e., sequence of "High" and "Low" classes), and labels for the routes or the locations, there are two possible procedures for training the two models: (1) sequential training and (2) cascaded training.
As Figure 13(a) shows, in sequential training, we train the particle predictor using the measured cache timing and the measured particle-number class sequences, and then train the route predictor using the measured particle-number class sequences and the measured route/location labels.
However, errors may accumulate in the particle predictor and the route predictor, harming end-to-end prediction accuracy.
We choose the cascaded training procedure as depicted in Figure 13(b).
First, the particle predictor is trained the same way.
Then, we use the predicted particle-number class sequences, rather than the measured particle-number class sequences, together with the measured route/location labels, to train the route predictor.
Finally, the trained particle predictor and the route predictor are used for the end-to-end attack evaluation.
Gazebo: We use two mazes shown in Figure 14 and Figure 15, which are both partitioned into 16-by-16 grids.
The topology of a simple maze ensures that any grid is reachable and there is only one possible path.
Compared to Maze 2, Maze 1 contains more branches and less straight lanes.
Oxford: the map used in the Oxford dataset is shown in Figure 16.
We select 7 routes labeled from "01" to "07" .
Train Table 4: RF route-prediction accuracy with the varying number of trees, for the 7 routes in Oxford.
We examine the impact of the size of the random forest model on the route and location prediction accuracy.
We use the ground-truth particle-number classes rather than predicted particle-number classes in this study, in order to exclude the effects of particle predictor.
We compare the route prediction accuracy of the RFs with a different number of trees.
Table 3 and Table 4 show the result for Maze 1 and Oxford, respectively.
The general trend is that the accuracy increases with the number of trees but the added benefit decreases with the number of trees.
Figure 18: LLC route prediction results for Gazebo.
We compare the prediction accuracy of the random forest (RF) with a different number of trees for the training, 2-fold validation, and 5-fold validation.
Table 5 shows the result.
Silimar to the route prediction, the accuracy increases with the RF size but the added benefit decreases.
We use the RF-100 model for the route prediction task and we use 10-fold validation for evaluating the prediction accuracy.
Gazebo: We randomly generate seven routes on Maze 1, as shown in Figure 14, and collect 20 instances for each route.
Figure 17 and Figure 18 show the classification results.
The overall route prediction accuracy is 81.4% and 75% for the L1D and LLC attacks, respectively.
Oxford: We use 126 sequences collected on the seven routes in the Oxford dataset for the route prediction.
Figure 19 and Figure 20 show the confusion matrices of the prediction based on the L1D side channel and the LLC side channel, respectively.
The route prediction accuracy is 74.6% and 73.0% for the L1D and LLC attacks, respectively.
We use the RF-50 model for the location prediction task.
We evaluate location prediction using the method described in Section 4.5.2.
For each maze, we randomly select 100 grid centers as destinations.
For a simulation run for each destination, we record the source-to-grid trajectory and the corresponding cache timing measurements and generate multiple training or validation samples by using the final destination as well as intermediate grid points on the trajectory as target locations.
We then put all these generated trajectories and corresponding cache timing vectors in the dataset.
Samples generated from the first 80 runs are used for training and the rest are used for validation.
For Maze 1 and Maze 2, there are 3,633 and 2,048 samples in the dataset, respectively.
Figure 21 shows the training and validation accuracy of the models trained using the L1D and LLC attacks on Maze 1.
For the location prediction, a wrong prediction label does not necessarily mean the prediction is far from the actual location.
Thus, we also calculate the Euclidean distance as a validation error.
For the L1D attack, the average validation error is 2.87 grid cells and 74.6% of the predictions fall within 3 cells.
For the LLC attack, the average validation error is 3.17 cells and 70.1% of the predictions fall within 3 cells.
For random guesses, the average error is 6.01 cells and 20.2% of the predictions fall within 3 cells.
For Maze 2, the average validation error is 2.58 grid cells and 75.2% of the predictions fall within 3 cells for the L1D attack, and the average validation error is 3.61 cells and 68.7% of the predictions fall within 3 cells for the LLC attack.
The average error is 7.67 cells and 13.2% of the prediction fall within 3 cells for random guesses.
We summarize the prediction accuracy of the L1D cache and LLC side-channel attacks for both mazes and RobotCar experiments in Table 6.
As mentioned in Section 5.1.2, the sampling periods are 100 ms and 300 ms, respectively.
The table also shows the results of L1D attacks with a sampling period of 300 ms, matching that of the LLC attack.The results show that both L1D and LLC attacks can predict a route or a location.
For the L1D attacks, the prediction accuracy is similar for both sampling periods.
The accuracy is slightly higher for the L1D attack than for the LLC attack.
However, the L1D attack is more difficult to perform as it requires the attack and victim processes to both run on the same core.
Table 6: Comparison of prediction accuracy of the L1D attack with different sampling periods, the LLC attack, and random guess.
We study and demonstrate the proposed side-channel attack on autonomous vehicles using an x86 platform.
The x86 architecture is widely used in autonomous vehicle development including multiple teams during the DARPA Grand Challenge [22,23,25,51,52,67] as well as more recent commercial developments by Baidu [2], Waymo [19,20], and Uber [4].
While we did not investigate the proposed attacks on other architectures such as ARM, we believe that the attack can be generalized to other architectures given that cache timingchannel attacks have been demonstrated in many different platforms.
We rely on the adaptive behavior of AMCL to perform our attack.
In general, we believe that the high-level observation that an adaptive algorithm can leak information about a vehicle's physical state can be generalized to other cyber-physical system (CPS) software whose memory access pattern depends on private physical state.
Obviously, not all control/localization algorithms have such a vulnerability.
For example, the data access pattern of a Kalman filter or a PID control algorithm is largely independent of input values, and does not leak physical state.
However, we believe that the adaptive behaviors will become increasingly common in autonomous system software for two reasons:1.
To ensure safety and improve estimation accuracy, most autonomous vehicles have two or more sources of sensor inputs that are fused for better estimation.
A simple Kalman filter-based estimation method does not work well in this scenario.
Adaptive particle filter-based estimation is more suitable for the state estimation of a non-Gaussian distribution in a high-dimensional space.2.
In addition to estimation, many perception algorithms, such as object detection [59] and recognition [58], are also adaptive and have input-dependent memory access patterns.
The proposed cache side-channel attack may be extended to exploit such perception algorithms to infer private physical information.We note that if multiple software components with adaptive memory access patterns run on the same machine simultaneously, their memory accesses may interfere with each other, exhibiting more complex patterns.
In that case, the machine learning model for prediction will need to either deal with interference as noise or be trained with the combined memory access patterns.
We provide a proof-of-concept end-to-end attack on inferring the route/location of an autonomous vehicle.
To be successful, the proposed attack needs a victim autonomous vehicle to satisfy a few key assumptions:• The autonomous vehicle uses a control software module with adaptive computing behavior (e.g., AMCL) where memory access patterns depend on the vehicle's physical state;• The attacker can control a software module on the vehicle (e.g., via installing a third-party software module or compromising an existing module);• The software module controlled by the attacker shares a cache with the victim control software module.Given these assumptions, an attacker can deploy an attack program on the victim's computer system and spy on the control software module through a cache side channel.
We believe that these assumptions are reasonable for future autonomous vehicles.First, as mentioned in Section 6.2, software modules with adaptive computing behavior (including AMCL) have been widely used in research/industry prototypes.
For efficiency, it makes an intuitive sense to dynamically adjust the amount of computation based on uncertainty or environments at runtime.Second, connected vehicles with an Internet connection and an integrated infotainment system demand an open software architecture that exposes a wider attack surface to remote attackers.
For example, it is likely that an infotainment system will allow third-party applications to be downloaded on the vehicle's computer system.
Studies on connected vehicles also show that a vehicle's onboard computers contain software vulnerabilities similar to traditional computers and may be compromised by remote exploits.Third, most vehicles are cost-sensitive, and there will be pressure to lower hardware costs by having multiple software components share hardware resources.
According to an industry report [10], the automobile electronic cost will increase from 35% to 50% of the total car cost from 2020 to 2030.
In fact, some companies are already adopting shared hardware in their products.
For example, Visteon's SmartCore [17] runs both non-safety-critical infotainment system and safety-critical advanced driving-assistance systems on the same processor.On the other hand, the proposed attack can be prevented by breaking one of the three key assumptions.
For example, for safety, future autonomous vehicle platforms may use two different hardware platforms for safety-critical control tasks and network-connected infotainment functions.
We rely on the number of particles in AMCL for route/location prediction.
Several real-world scenarios may exhibit less distinguishable characteristics in the traces of the number of particles, reducing the prediction accuracy.
• Identifying different routes on long highways: highways are designed for smooth traffic and generally the number of particles remain at minimum between entry and exit.
• Identifying different routes in a grid road network (e.g., downtown area): since our model does not explicitly distinguish left and right turns, the prediction might be pointing to a mirrored route/location.
However, in many scenarios, a vehicle will go through suburban, downtown roads and highways, and a route through a combinations of these roads exhibits a distinctive trace that can be distinguished from other routes.
Side-Channel Attacks for Physical Properties In this paper, we use the cache side-channel attack to infer physical properties such as a vehicle's route or location.
In addition to the cache side channel, there are other side channels that can be used to learn physical properties.
For example, Michalevsky et al. observe that cellular signal strength, which is directly viewable in the smartphone software without privilege, is location-dependent [49].
By recording the time series of the signal strength, they are able to track the location of the smartphone.
Similarly, Han et al. use the accelerometers on smartphones as a data source for location inference [39].
In addition to inferring physical location information, side channels can also be used to identify vehicle drivers.
For example, Enev et al. [30] show that the driver of an automobile can be inferred by looking at the brake pedal and other types of information on the CAN bus while the vehicle is moving.These attacks assume that an attacker has direct access to information on the physical world or behaviors such as the signal strength/accelerometer.
To prevent such attacks, the accesses can be blocked by the OS.
On the other hand, the attack on this paper exploits microarchitecture-level side channels and show that a program's memory access patterns can also leak information on the physical world.Non-Crypto Cache Side Channel Our side channel attack is a non-cryptographic attack.
Previous studies have also used the cache side channel for other types of non-cryptographic attacks.
For example, Yan et al. use the cache side-channel attack to extract the hyperparameters of a neural network [70].
Shusterman et al. propose the cache occupancy channel, which records the number of evictions for each memory address during a fixed time period, to identify the website on a browser [63].
These attacks target relatively static information that does not change during the attack.
There are also attacks on more dynamic assets.
For example, Gruss et al. show that keystrokes can be inferred in real time using a cache sidechannel attack [38].
Brasser et al. use cache access patterns to reveal a DNA sequence streamed into an SGX enclave for analysis at run time [24].
In this attack, the information can be inferred from a transient cache profile without considering the history.
In this paper, we expand the scope of the noncrypto cache side-channel attacks by showing that a vehicle's route/location can also be learned from memory access patterns.
In order to infer the route/location from memory access patterns that change quickly, our attack considers a history of cache profiles using machine-learning models.Side-Channel Attack Protection We leverage cache side channels to extract the physical information of the vehicle.
There are many proposals for defending against cache sidechannel attacks.
They can be classified into two categories, namely isolation and randomization.
We discuss some of the representative papers here.Isolation includes spatial isolation (partition) or temporal isolation (scheduling).
For partition, DAWG [42] adopts waypartitioning to prevent side channel leakage.
NoMo [29] provides dynamic cache reservation to active threads to prevent cache side-channel attacks.
STEALTHMEM [41] partitions the LLC into a non-secure region and a secure region using page coloring.
Temporal isolation leverages the observation that the cache side-channel attacks need coordinated timing between attack and victim programs in order to observe the cache state.
The scheduler can enforce a certain scheduling policy to prevent side channel leakage [33,65,68].
For randomization, Wang et al. proposed the random permutation cache (RPcache) to prevent cache side-channel leakage [69].
More recently, Qureshi et al. proposed encryptedaddress and remapping to prevent cache attack [56,57].
These approaches randomize the memory address.
Additionally, we can also randomize the clock that an attacker needs to use to obtain cache timing measurements.
A randomized clock can prevent an attack program from getting precise timing and inferring correct state of the cache [47,66].
Many protection mechanisms have been developed, but microarchitectural side-channel protection is not widely adopted in today's computing systems.
For strong protection, many of these techniques also require hardware changes, preventing adoption by existing systems.
Our study shows a new threat for autonomous vehicles, motivating stronger side-channel protection in future processor designs.
In this paper, we show that the cache side-channel attack can be used to stealthily infer routes and locations of autonomous vehicles.
Our results show that the location privacy of an autonomous vehicle can be compromised when its perception and control software share hardware resources with less trusted software.
Without a new processor design whose isolation guarantee includes time channels, our findings suggest that separate hardware should be used for trusted autonomous driving software and the rest of the system.
The proposed classification algorithm cannot predict a location that is not in the training set.
Our location prediction experiments are performed using randomly-selected destinations where the training set and the validation set contain different sets of destinations.
Thus, we generate multiple training/validation samples using the intermediate locations along each path.
The intermediate locations help creating more samples in both sets that share the same location label even when the destinations of the entire paths are different.
For example, a simulation run with a length L to one destination has L − 1 intermediate locations, and generates L samples with L different target locations to predict.
Intuitively, if the simulation destinations in the training set and the validation set are spatially close, there will be more intermediate locations that are common between the two sets, which will lead to more validation samples whose target locations exist in the training set.USENIX Association 29th USENIX Security Symposium 875 Here, we study different strategies for selecting destinations of simulation runs for the training set and the validation set and their impacts on prediction accuracy.Identical Destinations In this strategy, the training set and the validation set have an identical set of simulation destinations ( Figure 22).
We select all 256 locations in Maze 1.
For each destination, we use two simulation runs, one for the training set and one for the validation set, for the total 512 runs.Interleaved Destinations In this strategy, the training set and the validation set have interleaved destinations, forming a chessboard pattern ( Figure 23).
There is no overlap between the training and validation sets.
We select the "black" destinations for training and the "white" destinations for validation.
For each destination, we have two runs for the total 512 runs.
The interleaved strategy leads to mutually exclusive destinations in the training and the validation sets, but for each destination in the validation sets, there is a destination in the training set is just one grid away.Separated Destinations In this strategy, the training set and the validation set are spatially separated.
(Figure 24).
We use the bottom part of Maze 1 for the training set and the top part of Maze 1 for the validation set.
For each destination, we have two runs for the total 512 runs.
In this strategy, the destinations in the training set and the validation set are not only mutually exclusive, but also spatially far part in the opposite directions.In Table 7, we compare the number of overlapped target locations between the training set and the validation set for different destination-selection strategies.
The table shows the results for the three strategies discussed above as well as the random-selection scheme described in Section 4.
5 Table 8: Prediction results using different strategies for choosing destinations in the training and the validation sets.locations in each simulation run.
The table shows the total number of unique target locations in the validation set as well as the number of target locations that also appear in at least one sample in the training set.
The samples indicate the individual samples in the validation set that are used to obtain the prediction accuracy; multiple samples may have the same target location.
For the identical-destination strategy, 100% of the target locations in the validation sets are covered by the training set.
For the interleaved strategy, 88.8% of the target locations and 99.4% of the validation samples are covered by the training set.
However, in the separated strategy, only 47.2% of the target locations are covered by the training set.
The uncovered target locations have location labels not found in the training set, thus, they will lead to the same number of prediction errors.
As a consequence, the prediction accuracy for the separated destination will be lower.
We compare the prediction results of the three strategies and the random destination strategy in Table 8.
The prediction accuracy for the interleaved, identical, and random destinations are similar, while the accuracy for separated destinations is significantly lower.
This is consistent with the low percentage of the target locations that are covered by the training set under the separated-destination strategy.
The result shows that the spatial proximity of destinations in the training and validation sets, rather than the exact overlap of the destinations in the training and the validation set, is important for the prediction accuracy.
The random destination strategy, which we used in Section 4 and Section 5, preserves the spatial proximity of the destinations between the training and validation sets.
Thus, the prediction accuracy is similar to that of using identical and interleaved destinations strategies.
We thank our shepherd Yossi Oren and the anonymous reviewers for their helpful feedbacks on this paper.
We thank Jacopo Banfi, Mark Campbell, Mohamed Ismail, Alex Ivanov, and Yizhou Zhang for the insightful discussions.
This work was funded in part by NSF grant CNS-1513797 and ECCS-1932501, NASA grant NNX16AB09G and the Jacobs Fellowship of Cornell University.
